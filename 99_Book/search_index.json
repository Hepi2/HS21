[
["index.html", "Research Methods Kapitel 1 Einleitung", " Research Methods Juergen Dengler 2019-09-02 Kapitel 1 Einleitung Das Modul „Research Methods“ vermittelt vertiefte Methodenkompetenzen für praxisorientiertes und angewandtes wissenschaftliches Arbeiten im Fachbereich „Umwelt und Natürliche Ressourcen“ auf MSc-Niveau. Die Studierenden erarbeiten sich vertiefte Methodenkompetenzen für die analytische Betrachtung der Zusammenhänge im Gesamtsystem „Umwelt und Natürliche Ressourcen“. Die Studierenden erlernen die methodischen Kompetenzen, auf denen die nachfolgenden Module im MSc Programm UNR aufbauen. Das Modul vermittelt einerseits allgemeine, fächerübergreifende methodische Kompetenzen (z.B. Wissenschaftstheorie, computer-gestützte Datenverar-beitung und Statistik). Auf dieser Plattform (RStudio Connect) werden die Unterlagen für die R-Übungsteile bereitgestellt. Es werden sukzessive sowohl Demo-Files, Aufgabenstellungen und Lösungen veröffentlicht. "],
["2-prepro1-14-10-2019.html", "Kapitel 2 PrePro1 (14.10.2019)", " Kapitel 2 PrePro1 (14.10.2019) Die Datenkunde 2.0 gibt den Studierenden das Wissen und die Fertigkeiten an die Hand, selbst erhobene und bezogene Daten für Ihre eigenen Analysen vorzubereiten und anzureichern (preprocessing). Die Einheit vermittelt zentrale Datenverarbeitungskompetenzen und thematisiert bekannte Problemzonen der umweltwissenschaftlichen Datenverarbeitung – immer mit einer „hands-on“ Perspektive auf die begleitenden R-Übungen. Die Studierenden lernen die Eigenschaften ihrer Datensätze in der Fachsprache korrekt zu beschreiben. Sie lernen ausserdem Metadaten zu verstehen und die Implikationen derselben für ihre eigenen Analyseprojekte kritisch zu beurteilen. Zentrale Konzepte der Lerneinheit sind Skalenniveaus, Datentypen, Zeitdaten und Typumwandlungen. "],
["2-1-demo-datentypen-tabellen.html", "2.1 Demo: Datentypen, Tabellen", " 2.1 Demo: Datentypen, Tabellen R-Code als Download 2.1.1 Datentypen 2.1.1.1 Numerics Unter die Kategorie numeric fallen in R zwei Datentypen: double: Gleitkommazahl (z.B. 10.3, 7.3) integer: Ganzzahl (z.B. 10, 7) 2.1.1.1.1 Doubles Folgendermassen wird eine Gleitkommazahl einer Variabel zuweisen: x &lt;- 10.3 x ## [1] 10.3 typeof(x) ## [1] &quot;double&quot; Statt &lt;-kann auch = verwendet werden. Dies funktioniert aber nicht in allen Situationen, und ist zudem leicht mit == zu verwechseln. y = 7.3 y ## [1] 7.3 Ohne explizite Zuweisung nimmt R immer den Datentyp doublean: z &lt;- 42 typeof(z) ## [1] &quot;double&quot; is.integer(z) ## [1] FALSE is.numeric(z) ## [1] TRUE is.double(z) ## [1] TRUE 2.1.1.2 Ganzzahl / Integer Erst wenn man eine Zahl explizit als integer definiert (mit as.integer() oder L), wird sie auch als solches abgespeichert. a &lt;- as.integer(z) is.numeric(a) ## [1] TRUE is.integer(a) ## [1] TRUE c &lt;- 8L is.numeric(c) ## [1] TRUE is.integer(c) ## [1] TRUE typeof(a) ## [1] &quot;integer&quot; is.numeric(a) ## [1] TRUE is.integer(a) ## [1] TRUE Mit c() können eine Reihe von Werten in einer Variabel zugewiesen werden (als vector). Es gibt zudem auch character verctors. vector &lt;- c(10,20,33,42,54,66,77) vector ## [1] 10 20 33 42 54 66 77 vector[5] ## [1] 54 vector[2:4] ## [1] 20 33 42 vector2 &lt;- vector[2:4] Eine Ganzzahl kann explizit mit as.integer() definiert werden. a &lt;- as.integer(7) b &lt;- as.integer(3.14) a ## [1] 7 b ## [1] 3 typeof(a) ## [1] &quot;integer&quot; typeof(b) ## [1] &quot;integer&quot; is.integer(a) ## [1] TRUE is.integer(b) ## [1] TRUE Eine Zeichenkette kann als Zahl eingelesen werden. c &lt;- as.integer(&quot;3.14&quot;) c ## [1] 3 typeof(c) ## [1] &quot;integer&quot; 2.1.1.3 Logische Abfragen Wird auch auch als boolesch (Eng. boolean) bezeichnet. e &lt;- 3 f &lt;- 6 g &lt;- e &gt; f e ## [1] 3 f ## [1] 6 g ## [1] FALSE typeof(g) ## [1] &quot;logical&quot; 2.1.1.4 Logische Operationen sonnig &lt;- TRUE trocken &lt;- FALSE sonnig &amp; !trocken ## [1] TRUE Oft braucht man auch das Gegenteil / die Negation eines Wertes. Dies wird mittels ! erreicht u &lt;- TRUE v &lt;- !u v ## [1] FALSE 2.1.1.5 Zeichenketten Zeichenketten (Eng. character) stellen Text dar s &lt;- as.character(3.14) s ## [1] &quot;3.14&quot; typeof(s) ## [1] &quot;character&quot; Zeichenketten verbinden / zusammenfügen (Eng. concatenate) fname &lt;- &quot;Hans&quot; lname &lt;- &quot;Muster&quot; paste(fname,lname) ## [1] &quot;Hans Muster&quot; fname2 &lt;- &quot;hans&quot; fname == fname2 ## [1] FALSE 2.1.1.6 Factors Mit Factors wird in R eine Sammlung von Zeichenketten bezeichnet, die sich wiederholen, z.B. Wochentage (es gibt nur 7 unterschiedliche Werte für “Wochentage”). wochentage &lt;- c(&quot;Montag&quot;,&quot;Dienstag&quot;,&quot;Mittwoch&quot;,&quot;Donnerstag&quot;,&quot;Freitag&quot;,&quot;Samstag&quot;,&quot;Sonntag&quot;, &quot;Montag&quot;,&quot;Dienstag&quot;,&quot;Mittwoch&quot;,&quot;Donnerstag&quot;,&quot;Freitag&quot;,&quot;Samstag&quot;,&quot;Sonntag&quot;) typeof(wochentage) ## [1] &quot;character&quot; wochentage_fac &lt;- as.factor(wochentage) wochentage ## [1] &quot;Montag&quot; &quot;Dienstag&quot; &quot;Mittwoch&quot; &quot;Donnerstag&quot; &quot;Freitag&quot; ## [6] &quot;Samstag&quot; &quot;Sonntag&quot; &quot;Montag&quot; &quot;Dienstag&quot; &quot;Mittwoch&quot; ## [11] &quot;Donnerstag&quot; &quot;Freitag&quot; &quot;Samstag&quot; &quot;Sonntag&quot; wochentage_fac ## [1] Montag Dienstag Mittwoch Donnerstag Freitag Samstag ## [7] Sonntag Montag Dienstag Mittwoch Donnerstag Freitag ## [13] Samstag Sonntag ## Levels: Dienstag Donnerstag Freitag Mittwoch Montag Samstag Sonntag Wie man oben sieht, unterscheiden sich character vectors und factors v.a. dadurch, dass letztere über sogenannte levels verfügt. Diese levels entsprechen den Eindeutigen (unique) Werten. levels(wochentage_fac) ## [1] &quot;Dienstag&quot; &quot;Donnerstag&quot; &quot;Freitag&quot; &quot;Mittwoch&quot; &quot;Montag&quot; ## [6] &quot;Samstag&quot; &quot;Sonntag&quot; unique(wochentage) ## [1] &quot;Montag&quot; &quot;Dienstag&quot; &quot;Mittwoch&quot; &quot;Donnerstag&quot; &quot;Freitag&quot; ## [6] &quot;Samstag&quot; &quot;Sonntag&quot; 2.1.1.7 Zeit/Datum Um in R mit Datum/Zeit Datentypen umzugehen, müssen sie als POSIXct eingelesen werden (es gibt alternativ noch POSIXlt, aber diese ignorieren wir mal). Anders als Beispielsweise bei Excel, sollten in R Datum und Uhrzeit immer in einer Spalte gespeichert werden. datum &lt;- &quot;2017-10-01 13:45:10&quot; as.POSIXct(datum) ## [1] &quot;2017-10-01 13:45:10 CEST&quot; Wenn das die Zeichenkette in dem obigen Format (Jahr-Monat-Tag Stunde:Minute:Sekunde) daher kommt, braucht as.POSIXctkeine weiteren Informationen. Sollte das Format von dem aber Abweichen, muss man der Funktion das genaue Schema jedoch mitteilen. Der Syntax dafür kann via ?strptime nachgeschlagen werden. datum &lt;- &quot;01.10.2017 13:45&quot; as.POSIXct(datum,format = &quot;%d.%m.%Y %H:%M&quot;) ## [1] &quot;2017-10-01 13:45:00 CEST&quot; Beachtet, dass in den den obigen Beispiel R automatisch eine Zeitzone angenommen hat (CEST). R geht davon aus, dass die Zeitzone der System Timezone (Sys.timezone()) entspricht. 2.1.2 Data Frames und Conveniance Variabeln Eine data.frame ist die gängigste Art, Tabellarische Daten zu speichern. df &lt;- data.frame( Stadt = c(&quot;Zürich&quot;,&quot;Genf&quot;,&quot;Basel&quot;,&quot;Bern&quot;,&quot;Lausanne&quot;), Einwohner = c(396027,194565,175131,140634,135629), Ankunft = c(&quot;1.1.2017 10:00&quot;,&quot;1.1.2017 14:00&quot;, &quot;1.1.2017 13:00&quot;,&quot;1.1.2017 18:00&quot;,&quot;1.1.2017 21:00&quot;) ) str(df) ## &#39;data.frame&#39;: 5 obs. of 3 variables: ## $ Stadt : Factor w/ 5 levels &quot;Basel&quot;,&quot;Bern&quot;,..: 5 3 1 2 4 ## $ Einwohner: num 396027 194565 175131 140634 135629 ## $ Ankunft : Factor w/ 5 levels &quot;1.1.2017 10:00&quot;,..: 1 3 2 4 5 In der obigen data.frame wurde die Spalte Einwohner als Fliesskommazahl abgespeichert. Dies ist zwar nicht tragisch, aber da wir wissen das es sich hier sicher um Ganzzahlen handelt, können wir das korrigieren. Wichtiger ist aber, dass wir die Ankunftszeit (SpalteAnkunft) von einem Factor in ein Zeitformat (POSIXct) umwandeln. df$Einwohner &lt;- as.integer(df$Einwohner) df$Einwohner ## [1] 396027 194565 175131 140634 135629 df$Ankunft &lt;- as.POSIXct(df$Ankunft, format = &quot;%d.%m.%Y %H:%M&quot;) df$Ankunft ## [1] &quot;2017-01-01 10:00:00 CET&quot; &quot;2017-01-01 14:00:00 CET&quot; ## [3] &quot;2017-01-01 13:00:00 CET&quot; &quot;2017-01-01 18:00:00 CET&quot; ## [5] &quot;2017-01-01 21:00:00 CET&quot; Diese Rohdaten können nun helfen, um Hilfsvariablen (convenience variables) zu erstellen. Z.B. können wir die Städte einteilen in gross, mittel und klein. df$Groesse[df$Einwohner &gt; 300000] &lt;- &quot;gross&quot; df$Groesse[df$Einwohner &lt;= 300000 &amp; df$Einwohner &gt; 150000] &lt;- &quot;mittel&quot; df$Groesse[df$Einwohner &lt;= 150000] &lt;- &quot;klein&quot; Oder aber, die Ankunftszeit kann von der Spalte Ankunftabgeleitet werden. Dazu brauchen wir aber das Package lubridate library(lubridate) df$Ankunft_stunde &lt;- hour(df$Ankunft) 2.1.3 Quellen Dieses Kapitel verwendet folgende Libraries: Spinu, Grolemund, and Wickham (2018) References "],
["2-2-ubung-a.html", "2.2 Übung A", " 2.2 Übung A R ist ohne Zusatzpackete nicht mehr denkbar. Die allermeisten Packages werden auf CRAN gehostet und können leicht mittels install.packages() installiert werden. Eine sehr wichtige Sammlung von Packages wird von RStudio entwickelt. Unter dem Namen Tidyverse werden eine Reihe von Packages angeboten, den R-Alltag enorm erleichtert. Wir werden später näher auf das “Tidy”-Universum eingehen, an dieser Stelle können wir die Sammlung einfach mal installieren. install.packages(&quot;tidyverse&quot;) Um ein package in R verwenden zu können, gibt es zwei Möglichkeiten: entweder man lädt es zu Beginn der R-session mittles library(). oder man ruft eine function mit vorangestelltem Packetname sowie zwei Doppelpunkten auf. dplyr::filter() ruft die Funktion filter() des Packets dplyr auf. Letztere Notation ist vor allem dann sinnvoll, wenn sich zwei unterschiedliche Funktionen mit dem gleichen namen in verschiedenen pacakges existieren. filter() existiert als Funktion einersits im package dplyr sowie in stats. Dieses Phänomen nennt man “masking”. Zu beginn laden wir die nötigen Pakete: 2.2.1 Aufgabe 1 Erstelle eine data.frame mit nachstehenden Daten. Tipps: Eine leere data.frame zu erstellen ist schwieriger als wenn erstellen und befüllen der data.frame in einem Schritt erfolgt R ist dafür gedacht, Spalte für Spalte zu arbeiten (warum?), nicht Reihe für Reihe. Versuche dich an dieses Schema zu halten. Tierart Anzahl Gewicht Geschlecht Beschreibung Fuchs 2 4.4 m Rötlich Bär 5 40.3 f Braun, gross Hase 1 1.1 m klein, mit langen Ohren Elch 3 120.0 m Lange Beine, Schaufelgeweih 2.2.2 Aufgabe 2 Was für Datentypen wurden (in Aufgabe 1) von R automatisch angenommen? Sind diese sinnvoll? Tipp: Nutze dazu str() ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 5 variables: ## $ Tierart : chr &quot;Fuchs&quot; &quot;Bär&quot; &quot;Hase&quot; &quot;Elch&quot; ## $ Anzahl : num 2 5 1 3 ## $ Gewicht : num 4.4 40.3 1.1 120 ## $ Geschlecht : chr &quot;m&quot; &quot;f&quot; &quot;m&quot; &quot;m&quot; ## $ Beschreibung: chr &quot;Rötlich&quot; &quot;Braun, gross&quot; &quot;klein, mit langen Ohren&quot; &quot;Lange Beine, Schaufelgeweih&quot; ## [1] &quot;double&quot; 2.2.3 Aufgabe 3 Nutze die Spalte Gewicht um die Tiere in 3 Gewichtskategorien einzuteilen: leicht: &lt; 5kg mittel: 5 - 100 kg schwer: &gt; 100kg Tierart Anzahl Gewicht Geschlecht Beschreibung Gewichtsklasse Fuchs 2 4.4 m Rötlich leicht Bär 5 40.3 f Braun, gross mittel Hase 1 1.1 m klein, mit langen Ohren leicht Elch 3 120.0 m Lange Beine, Schaufelgeweih schwer 2.2.4 Aufgabe 4 Importiere den Datensatz order_52252_data.txt. Es handelt sich dabei um die stündlich gemittelten Temperaturdaten an verschiedenen Standorten in der Schweiz im Zeitraum 2000 - 2005. Wir empfehlen read_table()1 anstelle von read.table(). stn time tre200h0 ABO 2000010100 -2.6 ABO 2000010101 -2.5 ABO 2000010102 -3.1 ABO 2000010103 -2.4 ABO 2000010104 -2.5 ABO 2000010105 -3.0 ABO 2000010106 -3.7 ABO 2000010107 -4.4 ABO 2000010108 -4.1 ABO 2000010109 -4.1 2.2.5 Aufgabe 5 Schau dir die Rückmeldung von read_table()an. Sind die Daten korrekt interpretiert worden? 2.2.6 Aufgabe 6 Die Spalte time ist eine Datum/Zeitangabe im Format JJJJMMTTHH (siehe meta.txt). Damit R dies als Datum-/Zeitangabe erkennt, müssen wir die Spalte in einem R-Format (POSIXct) einlesen und dabei R mitteilen, wie sie aktuell formatiert ist. Lies die Spalte mit as.POSIXct() (oder parse_datetime) ein und spezifiziere sowohl format wie auch tz. Tipps: Wenn keine Zeitzone festgelegt wird, trifft as.POSIXct() eine Annahme (basierend auf Sys.timezone()). In unserem Fall handelt es sich aber um Werte in UTC (siehe meta.txt) as.POSIXcterwartet character ## [1] &quot;2000-01-01 00:00:00 UTC&quot; &quot;2000-01-01 01:00:00 UTC&quot; ## [3] &quot;2000-01-01 02:00:00 UTC&quot; &quot;2000-01-01 03:00:00 UTC&quot; ## [5] &quot;2000-01-01 04:00:00 UTC&quot; &quot;2000-01-01 05:00:00 UTC&quot; ## [7] &quot;2000-01-01 06:00:00 UTC&quot; &quot;2000-01-01 07:00:00 UTC&quot; ## [9] &quot;2000-01-01 08:00:00 UTC&quot; &quot;2000-01-01 09:00:00 UTC&quot; stn time tre200h0 ABO 2000-01-01 00:00:00 -2.6 ABO 2000-01-01 01:00:00 -2.5 ABO 2000-01-01 02:00:00 -3.1 ABO 2000-01-01 03:00:00 -2.4 ABO 2000-01-01 04:00:00 -2.5 ABO 2000-01-01 05:00:00 -3.0 ABO 2000-01-01 06:00:00 -3.7 ABO 2000-01-01 07:00:00 -4.4 ABO 2000-01-01 08:00:00 -4.1 ABO 2000-01-01 09:00:00 -4.1 2.2.7 Aufgabe 7 Erstelle zwei neue Spalten mit Wochentag (Montag, Dienstag, etc) und Kalenderwoche. Verwende dazu die neu erstellte POSIXct-Spalte stn time tre200h0 wochentag kw ABO 2000-01-01 00:00:00 -2.6 Sat 1 ABO 2000-01-01 01:00:00 -2.5 Sat 1 ABO 2000-01-01 02:00:00 -3.1 Sat 1 ABO 2000-01-01 03:00:00 -2.4 Sat 1 ABO 2000-01-01 04:00:00 -2.5 Sat 1 ABO 2000-01-01 05:00:00 -3.0 Sat 1 ABO 2000-01-01 06:00:00 -3.7 Sat 1 ABO 2000-01-01 07:00:00 -4.4 Sat 1 ABO 2000-01-01 08:00:00 -4.1 Sat 1 ABO 2000-01-01 09:00:00 -4.1 Sat 1 2.2.8 Aufgabe 8 Erstelle eine neue Spalte basierend auf die Temperaturwerte mit der Einteilung “kalt” (Unter Null Grad) und “warm” (über Null Grad) stn time tre200h0 wochentag kw temp_kat ABO 2000-01-01 00:00:00 -2.6 Sat 1 kalt ABO 2000-01-01 01:00:00 -2.5 Sat 1 kalt ABO 2000-01-01 02:00:00 -3.1 Sat 1 kalt ABO 2000-01-01 03:00:00 -2.4 Sat 1 kalt ABO 2000-01-01 04:00:00 -2.5 Sat 1 kalt ABO 2000-01-01 05:00:00 -3.0 Sat 1 kalt ABO 2000-01-01 06:00:00 -3.7 Sat 1 kalt ABO 2000-01-01 07:00:00 -4.4 Sat 1 kalt ABO 2000-01-01 08:00:00 -4.1 Sat 1 kalt ABO 2000-01-01 09:00:00 -4.1 Sat 1 kalt Wickham and Grolemund (2017), Kapitel 8 bzw. http://r4ds.had.co.nz/data-import.html)↩ "],
["2-3-ubung-a-losung.html", "2.3 Übung A Lösung", " 2.3 Übung A Lösung R-Script als Download library(tidyverse) # Im Unterschied zu `install.packages()` werden bei `library()` keine Anführungs- # und Schlusszeichen gesetzt. library(lubridate) # Im Unterschied zu install.packages(&quot;tidyverse&quot;) wird bei library(tidyverse) # das package lubridate nicht berücksichtigt # Lösung Aufgabe 1 df &lt;- data_frame( Tierart = c(&quot;Fuchs&quot;,&quot;Bär&quot;,&quot;Hase&quot;,&quot;Elch&quot;), Anzahl = c(2,5,1,3), Gewicht = c(4.4, 40.3,1.1,120), Geschlecht = c(&quot;m&quot;,&quot;f&quot;,&quot;m&quot;,&quot;m&quot;), Beschreibung = c(&quot;Rötlich&quot;,&quot;Braun, gross&quot;, &quot;klein, mit langen Ohren&quot;,&quot;Lange Beine, Schaufelgeweih&quot;) ) # Lösung Aufgabe 2 str(df) # Anzahl wurde als `double` interpretiert, ist aber eigentlich ein `integer`. # Mit data.frame() wurde Beschreibung wurde als `factor` interpretiert, ist # aber eigentlich `character` typeof(df$Anzahl) df$Anzahl &lt;- as.integer(df$Anzahl) df$Beschreibung &lt;- as.character(df$Beschreibung) # Lösung Aufgabe 3 df$Gewichtsklasse[df$Gewicht &gt; 100] &lt;- &quot;schwer&quot; df$Gewichtsklasse[df$Gewicht &lt;= 100 &amp; df$Gewicht &gt; 5] &lt;- &quot;mittel&quot; df$Gewichtsklasse[df$Gewicht &lt;= 5] &lt;- &quot;leicht&quot; # Lösung Aufgabe 4 wetter &lt;- readr::read_table(&quot;09_PrePro1/data/order_52252_data.txt&quot;) # Lösung Aufgabe 5 # Die Spalte &#39;time&#39; wurde als &#39;integer&#39; interpretiert. Dabei handelt es # sich offensichtlich um Zeitangaben. # Lösung Aufgabe 6 # mit readr parse_datetime(as.character(wetter$time[1:10]), format = &quot;%Y%m%d%H&quot;) # mit as.POSIXct() wetter$time &lt;- as.POSIXct(as.character(wetter$time), format = &quot;%Y%m%d%H&quot;,tz = &quot;UTC&quot;) # Lösung Aufgabe 7 wetter$wochentag &lt;- wday(wetter$time,label = T) wetter$kw &lt;- week(wetter$time) # Lösung Aufgabe 8 wetter$temp_kat[wetter$tre200h0&gt;0] &lt;- &quot;warm&quot; wetter$temp_kat[wetter$tre200h0&lt;=0] &lt;- &quot;kalt&quot; "],
["2-4-ubung-b.html", "2.4 Übung B", " 2.4 Übung B Fahre mit dem Datensatz wetter aus Übung A fort. 2.4.1 Aufgabe 1 Nutze plot() um die Temparaturkurve zu visualisieren. Verwende aber vorher filter() um dich auf eine Station (z.B. “ABO”) zu beschränken (es handelt sich sonst um zuviele Datenpunkte). Nun schauen wir uns das plotten mit ggplot2 an. Ein simpler Plot wie der in der vorherigen Aufgabe ist in ggplot2 zugegebenermassen etwas komplizierter. ggplot2 wird aber rasch einfacher, wenn die Grafiken komplexer werden. Wir empfehlen deshalb stark, ggplot2 zu verwenden. Schau dir ein paar online Tutorials zu ggplot2 an (siehe2) und reproduziere den obigen Plot mit ggplot2 2.4.2 Aufgabe 2 Spiele mit Hilfe der erwähnten Tutorials mit dem Plot etwas rum. Versuche die x-/y-Achsen zu beschriften sowie einen Titel hinzu zu fügen. 2.4.3 Aufgabe 3 Reduziere den x-Achsenausschnitt auf einen kleineren Zeitraum, beispielsweise einn beliebigen Monat. Verwende dazu lims() zusammen mit as.POSIXct() oder mache ein Subset von deinem Datensatz mit einer convenience-Variabel und filter(). Wickham and Grolemund (2017), Kapitel 1 bzw. http://r4ds.had.co.nz/data-visualisation.html oder hier ein sehr schönes Video: Learn R: An Introduction to ggplot2↩ "],
["2-5-ubung-b-losung.html", "2.5 Übung B Lösung", " 2.5 Übung B Lösung R-Code als Download library(tidyverse) # Lösung Aufgabe 1 wetter_fil &lt;- dplyr::filter(wetter, stn == &quot;ABO&quot;) plot(wetter_fil$time,wetter_fil$tre200h0, type = &quot;l&quot;) p &lt;- ggplot(wetter_fil, aes(time,tre200h0)) + geom_line() p # Lösung Aufgabe 2 p &lt;- p + labs(x = &quot;Datum&quot;, y = &quot;Temperatur&quot;, title = &quot;Stündlich gemittelte Temperaturwerte&quot;) p # Lösung Aufgabe 3 limits &lt;- as.POSIXct(c(&quot;2002-01-01 00:00:00&quot;,&quot;2002-02-01 00:00:00&quot;),tz = &quot;UTC&quot;) p + lims(x = limits) "],
["3-statistik-2-29-10-2019.html", "Kapitel 3 Statistik 2 (29.10.2019)", " Kapitel 3 Statistik 2 (29.10.2019) In Statistik 2 lernen die Studierenden die Idee, die Voraussetzungen und die praktische Anwendung „einfacher“ linearer Modelle in R (sowie teilweise ihrer “nicht-parametrischen” bzw. “robusten” Äquivalente). Am Beginn stehen Korrelationen, die auf einen linearen Zusammenhang zwischen zwei metrischen Variablen testen, ohne Annahme einer Kausalität. Es folgen einfache lineare Regressionen, die im Prinzip das Gleiche bei klarer Kausalität leisten sowie deren Verallgemeinerung als polynomiale Regressionen, die z. B. auch einen Test auf unimodale Beziehungen erlaubt. Aufbauend auf Statistik 1 werden ANOVAs vertieft, u.a. post-hoc-Test und mehrfaktorielle ANOVAs. Zum Schluss wird noch die ANCOVA als eine Technik vorgestellt, die ANOVA und lineare Regression verbindet. "],
["3-1-ubungen.html", "3.1 Übungen", " 3.1 Übungen 3.1.1 Übung 2.1: Regression (NatWis) Regressionsanalyse mit decay.csv Der Datensatz beschreibt in einem physikalischen Experiment die Zahl der radioaktiven Zerfälle pro Minute in Abhängigkeit vom Zeitpunkt (min nach Start des Experimentes). Ladet den Datensatz in R und macht eine explorative Datenanalyse. Wählt unter den schon gelernten Methoden der Regressionsanalyse ein adäquates Vorgehen zur Analyse dieser Daten und führt diese dann durch. Prüft anhand der Residuen, ob die Modellvoraussetzungen erfüllt waren Stellt die erhaltenen Ergebnisse angemessen dar (Text, Abbildung und/oder Tabelle). Kennt ihr ggf. noch eine andere geeignete Herangehensweise? 3.1.2 Übung 2.2: Einfaktrielle ANOVA (SozOek) ANOVA mit novanimal.csv Führt mit dem Datensatz novanimal.csv eine einfaktorielle ANOVA durch.Gibt es Unterschiede zwischen der Anzahl verkaufter Gerichte (Buffet, Fleisch oder Vegetarisch) pro Woche? Hinweise für die Analysen: Fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit grep()). Danach muss der Datensatz gruppiert und zusammengefasst werden. Unbekannte Menü-Inhalte können vernachlässigt werden. Wie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig? Führt anschliessend Post-hoc-Vergleiche durch. Fasst die Ergebnisse in einem Satz zusammen. 3.1.3 Übung 2.3N: Mehrfaktorielle ANOVA (NatWis) ANOVA mit kormoran.csv Der Datensatz enthält 40 Beobachtungen zu Tauchzeiten zweier Kormoranunterarten (C = Phalocrocorax carbo carbo und S = Phalacrocorax carbo sinensis) aus vier Jahreszeiten (F = Frühling, S = Sommer, H = Herbst, W = Winter). Lest den Datensatz nach R ein und führt eine adäquate Analyse durch, um beantworten zu können, wie Unterart und Jahreszeit die Tauchzeit beeinflussen. Stellt Ihre Ergebnisse dann angemessen dar (Text, Abbildung und/oder Tabelle). Gibt es eine Interaktion? 3.1.4 Übung 2.3S: Mehrfaktorielle ANOVA mit Interaktion (SozOek) ANOVA mit novanimal.csv Können die Unterschiede in den verkauften Gerichten (Buffet, Fleisch oder Vegetarisch) durch die beiden Bedingungen (Basis- oder Interventionswochen) erklärt werden? Hinweise für die Analysen: Fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit grep()). Danach muss der Datensatz gruppiert und zusammengefasst werden. Unbekannte Menü-Inhalte können vernachlässigt werden. Wie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig? Führt anschliessend Post-hoc-Vergleiche durch. Fasst die Ergebnisse in einem Satz zusammen. 3.1.5 Quellen "],
["3-2-musterlosung-aufgabe-2-1-regression.html", "3.2 Musterlösung Aufgabe 2.1: Regression", " 3.2 Musterlösung Aufgabe 2.1: Regression Übungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird) Laden Sie den Datensatz decay.csv. Dieser enthält die Zahl radioaktiver Zerfälle pro Zeiteinheit (amount) für Zeitpunkte (time) nach dem Start des Experimentes. Ermitteln Sie ein statistisches Modell, dass die Zerfallshäufigkeit in Abhängigkeit von der Zeit beschreibt. Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren. Dieser Ablauf sollte insbesondere beinhalten: Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen Explorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten Auswahl und Begründung eines statistischen Verfahrens (es gibt hier mehrere statistisch korrekte Möglichkeiten!) Ermittlung eines Modells Durchführen der Modelldiagnostik für das gewählte Modell Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden. Abzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit). Loesung – Skript Uebung 2.1 - Regressionsanalyse data &lt;-read.csv(&quot;14_Statistik2/data/decay.csv&quot;) data attach(data) summary(data) str(data) Explorative Datenanalyse boxplot(time) boxplot(amount) plot(amount~time) Einfaches lineares Modell model1&lt;-lm(amount~time) summary(model1) Modelldiagnostik par(mfrow=c(2,2)) plot(model1) Ergebnisplot par(mfrow=c(1,1)) plot(time,amount) abline(lm(amount~time),col=&quot;red&quot;) Loesung 1: log-Transformation der abhaengigen Variablen par(mfrow=c(1,2)) boxplot(amount) boxplot(log(amount)) hist(amount) hist(log(amount)) model2&lt;-lm(log(amount)~time) summary(model2) Modelldiagnostik par(mfrow=c(2,2)) plot(model2) Loesung 2: quadratische Regression (kam erst in Statistik 3; koente fuer die Datenverteilung passen, entspricht aber nicht der physikalischen Gesetzmaessigkeit model.quad&lt;-lm(amount~time+I(time^2)) summary(model.quad) Vergleich mit dem einfachen Modell mittels ANOVA (es ginge auch AICc) anova(model1,model.quad) Modelldiagnostik par(mfrow=c(2,2)) plot(model.quad) Loesung 3 (kam erst in Statistik 4; methodisch beste Loesung; mit Startwerten muss man ggf. ausprobieren) model.nls&lt;-nls(amount~a*exp(-b*time),start=(list(a=100,b=1))) summary(model.nls) Modelldiagnostik library(nlstools) residuals.nls &lt;- nlsResiduals(model.nls) plot(residuals.nls) Ergebnisplots par(mfrow=c(1,1)) xv&lt;-seq(0,30,0.1) lineares Modell mit log-transformierter Abhaengiger plot(time,amount) yv1&lt;-exp(predict(model2,list(time=xv))) lines(xv,yv1,col=&quot;red&quot;) quadratisches Modell plot(time,amount) yv2&lt;-predict(model.quad,list(time=xv)) lines(xv,yv2,col=&quot;blue&quot;) nicht-lineares Modell plot(time,amount) yv3&lt;-predict(model.nls,list(time=xv)) lines(xv,yv3,col=&quot;green&quot;) "],
["3-3-musterlosung-aufgabe-2-2-einfaktorielle-anova.html", "3.3 Musterlösung Aufgabe 2.2: einfaktorielle ANOVA", " 3.3 Musterlösung Aufgabe 2.2: einfaktorielle ANOVA df &lt;- nova # klone den originaler Datensatz # fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. df$label_content[grep(&quot;Pflanzlich+&quot;,df$label_content)] &lt;- &quot;Vegetarisch&quot; # gruppiert Daten nach Menü-Inhalt und Woche df_ &lt;- df %&gt;% group_by(label_content, week) %&gt;% summarise(tot_sold = n()) %&gt;% drop_na() # lasst die unbekannten Menü-Inhalte weg # überprüft die Voraussetzungen für eine ANOVA # Histogramm, sagt aber nicht viel aus ggplot(df_, aes(x = tot_sold, y = ..count..)) + geom_histogram() + labs(x = &quot;\\nAnzahl verkaufte Gerichte pro Woche&quot;, y = &quot;Häufigkeit\\n&quot;) + mytheme # Boxplot ggplot(df_, aes(x = label_content, y= tot_sold)) + geom_boxplot(fill=&quot;white&quot;, color = &quot;black&quot;, size = 1) + labs(x = &quot;\\nMenü-Inhalt&quot;, y = &quot;Anzahl verkaufte Gerichte pro Woche\\n&quot;) + mytheme # klare Varianzheterogenität # definiert das Modell model &lt;- aov(tot_sold ~ label_content, data = df_) summary.lm(model) autoplot(model) + mytheme Fazit: Inspektion der Modellvoraussetzung zeigt klare Verletzungen der Homoskedastizität. Nächster Schritt Welch-Test. # überprüft die Voraussetzungen des Welch-Test. # Gibt es eine hohe Varianzheterogenität und # ist die relative Verteilung der Residuen gegeben? # In diesem Fall wäre ein Welch-Test passend w_test &lt;- oneway.test(data=df_, tot_sold ~ label_content, var.equal=F) w_test 3.3.1 Methoden Ziel war es, die Unterschide in den Verkaufszahlen pro Menü-Inhalt aufzuzeigen. Da die Kriteriumsvariable (Verkaufszahlen) metrisch und die Prädiktorvariable kategorial sind, wurde eine einfaktorielle ANOVA gerechnet. Die visuelle Inspektion der Voraussetzungen zeigte insbesondere schwere Verletzungen der Homoskedastizität. Der Boxplot bestätigt diesen Befund. Daher wurde in einem weiteren Schritt den Welch-Test für ungleiche Varianzen gerechnet. 3.3.2 Ergebnisse Die Menü-Inhalte (Fleisch, Vegetarisch und Buffet) unterscheiden sich in den Verkaufszahlen signifikant (F(2,7) = 65, p &lt; .001). Die Figure 1 zeigt die Verkaufszahlen pro Menü-Inhalt. Figure 3.1: Die wöchentlichen Verkaufzahlen unterscheiden sich je nach Menü-Inhalt stark. "],
["3-4-musterlosung-aufgabe-2-3n-mehrfaktorielle-anova.html", "3.4 Musterlösung Aufgabe 2.3N: Mehrfaktorielle ANOVA", " 3.4 Musterlösung Aufgabe 2.3N: Mehrfaktorielle ANOVA Übungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird) Laden Sie den Datensatz kormoran.txt mit read.table. Dieser enthält Tauchzeiten (hier ohne Einheit) von Kormoranen in Abhängigkeit von Jahreszeit und Unterart. Unterarten: Phalacrocorax carbo carbo (C) und Phalacrocorax carbo sinensis (S); Jahreszeiten: F = Frühling, S = Sommer, H = Herbst, W = Winter. Ihre Gesamtaufgabe ist es, aus diesen Daten ein minimal adäquates Modell zu ermitteln, das diese Abhängigkeit beschreibt. Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren. Dieser Ablauf sollte insbesondere beinhalten: Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen, welches statistische Verfahren wenden Sie an? Explorative Datenanalyse, um zu sehen, ob schon vor dem Start der Analysen Transformationen o.ä. vorgenommen werden sollten Definition eines vollen Modelles, das nach statistischen Kritierien zum minimal adäquaten Modell reduziert wird Durchführen der Modelldiagnostik, um zu entscheiden, ob das gewählte Vorgehen korrekt war oder ggf. angepasst werden muss Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden. Abzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit). Loesung – Skript Uebung 2.3N - Mehrfaktorielle ANOVA kormoran &lt;-read.delim(&quot;14_Statistik2/data/kormoran.csv&quot;,sep = &quot;;&quot;) ## Ueberpruefen, ob Einlesen richtig funktioniert hat und welche Datenstruktur vorliegt str(kormoran) ## &#39;data.frame&#39;: 40 obs. of 4 variables: ## $ Obs : int 1 2 3 4 5 6 7 8 9 10 ... ## $ Tauchzeit : num 9.5 11.9 13.4 13.8 15.3 15.5 15.6 16.7 16.8 18.7 ... ## $ Unterart : Factor w/ 2 levels &quot;C&quot;,&quot;S&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ Jahreszeit: Factor w/ 4 levels &quot;F&quot;,&quot;H&quot;,&quot;S&quot;,&quot;W&quot;: 1 1 1 1 1 3 3 3 3 3 ... summary(kormoran) ## Obs Tauchzeit Unterart Jahreszeit ## Min. : 1.00 Min. : 9.50 C:20 F:10 ## 1st Qu.:10.75 1st Qu.:13.38 S:20 H:10 ## Median :20.50 Median :16.75 S:10 ## Mean :20.50 Mean :17.40 W:10 ## 3rd Qu.:30.25 3rd Qu.:20.77 ## Max. :40.00 Max. :30.40 #Um die Variablen im Dataframe im Folgenden direkt (ohne $ bzw. ohne &quot;data = kormoran&quot;) ansprechen zu koennen attach(kormoran) #Umsortieren der Faktoren, damit sie in den Boxplots eine sinnvolle Reihung haben Jahreszeit&lt;-factor(Jahreszeit,levels=c(&quot;F&quot;,&quot;S&quot;,&quot;H&quot;,&quot;W&quot;)) #Explorative Datenanalyse (zeigt uns die Gesamtverteilung) boxplot(Tauchzeit) boxplot(log10(Tauchzeit)) #Explorative Datenanalyse (Check auf Normalverteilung der Residuen und Varianzhomogenitaet) boxplot(Tauchzeit~Jahreszeit*Unterart) boxplot(log10(Tauchzeit)~Jahreszeit*Unterart) #Vollständiges Modell mit Interaktion model &lt;- aov(Tauchzeit~Unterart*Jahreszeit) model ## Call: ## aov(formula = Tauchzeit ~ Unterart * Jahreszeit) ## ## Terms: ## Unterart Jahreszeit Unterart:Jahreszeit Residuals ## Sum of Squares 106.929 756.170 11.009 84.992 ## Deg. of Freedom 1 3 3 32 ## ## Residual standard error: 1.629724 ## Estimated effects may be unbalanced summary(model) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Unterart 1 106.9 106.93 40.259 4.01e-07 *** ## Jahreszeit 3 756.2 252.06 94.901 5.19e-16 *** ## Unterart:Jahreszeit 3 11.0 3.67 1.382 0.266 ## Residuals 32 85.0 2.66 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #p-Wert der Interaktion ist 0.266 #Modellvereinfachung model2 &lt;- aov(Tauchzeit~Unterart+Jahreszeit) model2 ## Call: ## aov(formula = Tauchzeit ~ Unterart + Jahreszeit) ## ## Terms: ## Unterart Jahreszeit Residuals ## Sum of Squares 106.929 756.170 96.001 ## Deg. of Freedom 1 3 35 ## ## Residual standard error: 1.656166 ## Estimated effects may be unbalanced summary(model2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Unterart 1 106.9 106.93 38.98 3.69e-07 *** ## Jahreszeit 3 756.2 252.06 91.89 &lt; 2e-16 *** ## Residuals 35 96.0 2.74 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #Anderer Weg, um zu pruefen, ob man das komplexere Modell mit Interaktion behalten soll anova(model,model2) ## Analysis of Variance Table ## ## Model 1: Tauchzeit ~ Unterart * Jahreszeit ## Model 2: Tauchzeit ~ Unterart + Jahreszeit ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 32 84.992 ## 2 35 96.001 -3 -11.009 1.3817 0.2661 #in diesem Fall bekommen wir den gleichen p-Wert wie oben (0.266) #Modelldiagnostik par(mfrow=c(2,2)) #alle vier Abbildungen in einem 2 x 2 Raster plot(model2) influence.measures(model2) # kann man sich zusaezlich zum &quot;plot&quot; ansehen, um herauszufinden, ob es evtl. sehr einflussreiche Werte mit Cook&#39;s D von 1 oder grösser gibt ## Influence measures of ## aov(formula = Tauchzeit ~ Unterart + Jahreszeit) : ## ## dfb.1_ dfb.UntS dfb.JhrS dfb.JhrH dfb.JhrW dffit cov.r cook.d ## 1 -1.06739 0.47735 6.75e-01 6.75e-01 6.75e-01 -1.06739 0.461 1.90e-01 ## 2 -0.38948 0.17418 2.46e-01 2.46e-01 2.46e-01 -0.38948 1.133 3.03e-02 ## 3 -0.02285 0.01022 1.44e-02 1.44e-02 1.44e-02 -0.02285 1.320 1.07e-04 ## 4 0.07338 -0.03282 -4.64e-02 -4.64e-02 -4.64e-02 0.07338 1.314 1.11e-03 ## 5 0.44271 -0.19798 -2.80e-01 -2.80e-01 -2.80e-01 0.44271 1.084 3.88e-02 ## 6 -0.05945 0.13293 -1.88e-01 8.33e-18 1.67e-17 -0.29723 1.207 1.79e-02 ## 7 -0.05452 0.12190 -1.72e-01 1.39e-17 6.24e-18 -0.27258 1.225 1.51e-02 ## 8 -0.00120 0.00269 -3.80e-03 1.94e-19 3.87e-19 -0.00601 1.321 7.44e-06 ## 9 0.00361 -0.00807 1.14e-02 -9.29e-19 -5.16e-19 0.01804 1.321 6.70e-05 ## 10 0.09727 -0.21750 3.08e-01 3.16e-17 3.38e-17 0.48634 1.042 4.64e-02 ## 11 -0.10715 0.23960 4.16e-17 -3.39e-01 -4.25e-18 -0.53577 0.991 5.58e-02 ## 12 -0.02722 0.06087 -6.76e-18 -8.61e-02 -8.27e-18 -0.13612 1.296 3.80e-03 ## 13 0.03546 -0.07930 -1.22e-16 1.12e-01 -4.14e-17 0.17731 1.279 6.43e-03 ## 14 0.04520 -0.10108 -5.42e-17 1.43e-01 -1.04e-17 0.22601 1.254 1.04e-02 ## 15 0.05501 -0.12300 -1.02e-16 1.74e-01 -3.54e-17 0.27504 1.223 1.53e-02 ## 16 -0.04618 0.10326 -1.99e-18 1.44e-17 -1.46e-01 -0.23090 1.251 1.09e-02 ## 17 -0.04130 0.09235 1.64e-17 2.87e-17 -1.31e-01 -0.20650 1.265 8.70e-03 ## 18 -0.00265 0.00591 5.88e-18 6.26e-18 -8.36e-03 -0.01323 1.321 3.60e-05 ## 19 0.01660 -0.03713 -1.81e-17 -3.58e-18 5.25e-02 0.08302 1.312 1.42e-03 ## 20 0.31644 -0.70758 -2.70e-16 -2.11e-16 1.00e+00 1.58219 0.165 3.40e-01 ## 21 0.01082 0.00807 -1.14e-02 -1.14e-02 -1.14e-02 0.01804 1.321 6.70e-05 ## 22 0.05415 0.04036 -5.71e-02 -5.71e-02 -5.71e-02 0.09025 1.310 1.67e-03 ## 23 0.06862 0.05115 -7.23e-02 -7.23e-02 -7.23e-02 0.11437 1.303 2.69e-03 ## 24 0.15618 0.11641 -1.65e-01 -1.65e-01 -1.65e-01 0.26029 1.233 1.38e-02 ## 25 0.23067 0.17193 -2.43e-01 -2.43e-01 -2.43e-01 0.38445 1.137 2.95e-02 ## 26 0.03643 -0.08147 -1.15e-01 3.07e-18 -1.04e-18 -0.18217 1.277 6.79e-03 ## 27 0.01709 -0.03820 -5.40e-02 -1.24e-17 -1.14e-17 -0.08543 1.311 1.50e-03 ## 28 0.00746 -0.01667 -2.36e-02 3.88e-18 2.84e-18 -0.03728 1.319 2.86e-04 ## 29 -0.01179 0.02636 3.73e-02 -3.20e-18 -1.03e-18 0.05893 1.316 7.15e-04 ## 30 -0.06539 0.14622 2.07e-01 -2.96e-17 -2.30e-17 0.32696 1.185 2.15e-02 ## 31 0.09315 -0.20829 1.52e-16 -2.95e-01 0.00e+00 -0.46574 1.062 4.27e-02 ## 32 0.04814 -0.10764 1.36e-17 -1.52e-01 -1.87e-17 -0.24068 1.245 1.18e-02 ## 33 0.02384 -0.05331 1.69e-17 -7.54e-02 4.14e-18 -0.11920 1.302 2.92e-03 ## 34 -0.06838 0.15290 2.73e-17 2.16e-01 3.34e-17 0.34189 1.173 2.35e-02 ## 35 -0.09366 0.20943 0.00e+00 2.96e-01 2.53e-17 0.46831 1.059 4.32e-02 ## 36 0.10820 -0.24195 8.09e-17 1.18e-16 -3.42e-01 -0.54101 0.986 5.68e-02 ## 37 0.10297 -0.23025 4.06e-18 -2.94e-17 -3.26e-01 -0.51487 1.013 5.18e-02 ## 38 0.06242 -0.13957 3.29e-17 5.78e-17 -1.97e-01 -0.31208 1.196 1.97e-02 ## 39 -0.02964 0.06629 -2.98e-17 -2.87e-17 9.37e-02 0.14822 1.292 4.50e-03 ## 40 -0.05402 0.12080 -2.32e-17 -2.88e-17 1.71e-01 0.27012 1.226 1.48e-02 ## hat inf ## 1 0.125 * ## 2 0.125 ## 3 0.125 ## 4 0.125 ## 5 0.125 ## 6 0.125 ## 7 0.125 ## 8 0.125 ## 9 0.125 ## 10 0.125 ## 11 0.125 ## 12 0.125 ## 13 0.125 ## 14 0.125 ## 15 0.125 ## 16 0.125 ## 17 0.125 ## 18 0.125 ## 19 0.125 ## 20 0.125 * ## 21 0.125 ## 22 0.125 ## 23 0.125 ## 24 0.125 ## 25 0.125 ## 26 0.125 ## 27 0.125 ## 28 0.125 ## 29 0.125 ## 30 0.125 ## 31 0.125 ## 32 0.125 ## 33 0.125 ## 34 0.125 ## 35 0.125 ## 36 0.125 ## 37 0.125 ## 38 0.125 ## 39 0.125 ## 40 0.125 #Alternative mit log10 model3 &lt;-aov(log10(Tauchzeit)~Unterart+Jahreszeit) model3 ## Call: ## aov(formula = log10(Tauchzeit) ~ Unterart + Jahreszeit) ## ## Terms: ## Unterart Jahreszeit Residuals ## Sum of Squares 0.0627004 0.4958434 0.0562031 ## Deg. of Freedom 1 3 35 ## ## Residual standard error: 0.04007247 ## Estimated effects may be unbalanced summary(model3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Unterart 1 0.0627 0.06270 39.05 3.64e-07 *** ## Jahreszeit 3 0.4958 0.16528 102.93 &lt; 2e-16 *** ## Residuals 35 0.0562 0.00161 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 plot(model3) #Ergebnisdarstellung par(mfrow=c(1,1)) #Zurückschalten auf Einzelplots library(multcomp) letters&lt;-cld(glht(model2,linfct=mcp(Unterart=&quot;Tukey&quot;))) boxplot(Tauchzeit~Unterart,xlab=&quot;Unterart&quot;,ylab=&quot;Tauchzeit&quot;) mtext(letters$mcletters$Letters,at=1:2) #genaugenommen braucht man bei nur zwei Kategorien keinen post hoc-Test letters&lt;-cld(glht(model2,linfct=mcp(Jahreszeit=&quot;Tukey&quot;))) boxplot(Tauchzeit~Jahreszeit,xlab=&quot;Jahreszeit&quot;,ylab=&quot;Tauchzeit&quot;) #Achsenbeschriftung nicht vergessen! mtext(letters$mcletters$Letters,at=c(1:4)) #Jetzt brauchen wir noch die Mittelwerte bzw. Effektgroessen summary(lm(Tauchzeit~Jahreszeit)) ## ## Call: ## lm(formula = Tauchzeit ~ Jahreszeit) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.820 -1.617 -0.145 1.587 6.980 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 11.8600 0.7508 15.797 &lt; 2e-16 *** ## JahreszeitS 3.2300 1.0618 3.042 0.00437 ** ## JahreszeitH 7.3700 1.0618 6.941 3.92e-08 *** ## JahreszeitW 11.5600 1.0618 10.887 6.11e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.374 on 36 degrees of freedom ## Multiple R-squared: 0.7884, Adjusted R-squared: 0.7708 ## F-statistic: 44.72 on 3 and 36 DF, p-value: 3.156e-12 summary(lm(Tauchzeit~Unterart)) ## ## Call: ## lm(formula = Tauchzeit ~ Unterart) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.535 -3.585 -0.335 3.760 11.365 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 19.035 1.059 17.976 &lt;2e-16 *** ## UnterartS -3.270 1.498 -2.184 0.0352 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.736 on 38 degrees of freedom ## Multiple R-squared: 0.1115, Adjusted R-squared: 0.08811 ## F-statistic: 4.768 on 1 and 38 DF, p-value: 0.03523 aggregate(kormoran[,1],list(Unterart),mean) ## Group.1 x ## 1 C 10.5 ## 2 S 30.5 aggregate(kormoran[,1],list(Jahreszeit),mean) ## Group.1 x ## 1 F 13 ## 2 S 18 ## 3 H 23 ## 4 W 28 knitr::opts_chunk$set(fig.width = 15, fig.height = 12, warning = F, message = F, fig.pos = &#39;H&#39;) #knitr::opts_chunk$get(&quot;root.dir&quot;) "],
["3-5-musterlosung-aufgabe-2-3s-anova-mit-interaktion.html", "3.5 Musterlösung Aufgabe 2.3S: ANOVA mit Interaktion", " 3.5 Musterlösung Aufgabe 2.3S: ANOVA mit Interaktion # klone den originaler Datensatz df &lt;- nova # fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. df$label_content[grep(&quot;Pflanzlich+&quot;,df$label_content)] &lt;- &quot;Vegetarisch&quot; # gruppiert Daten gemäss Bedingungen, Menü-Inhalt und Wochen df_ &lt;- df %&gt;% group_by(condit, label_content, week) %&gt;% summarise(tot_sold = n()) %&gt;% drop_na() # lasst die unbekannten Menü-Inhalte weg # überprüft Voraussetzungen für eine ANOVA # Boxplots zeigt klare Varianzheterogenität ggplot(df_, aes(x = interaction(label_content, condit), y = tot_sold)) + geom_boxplot(fill=&quot;white&quot;, size = 1) + labs(x = &quot;\\nMenü-Inhalt&quot;, y = &quot;Anzahl verkaufte Gerichte pro Woche\\n&quot;) + mytheme # definiert das Modell mit Interaktion model1 &lt;- aov(tot_sold ~ label_content * condit, data = df_) summary.lm(model1) ## ## Call: ## aov(formula = tot_sold ~ label_content * condit, data = df_) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.0000 -4.0000 -0.1667 1.9167 9.3333 ## ## Coefficients: ## Estimate Std. Error t value ## (Intercept) 27.333 3.127 8.741 ## label_contentFleisch 80.333 4.422 18.166 ## label_contentVegetarisch 24.667 4.422 5.578 ## conditIntervention -3.333 4.422 -0.754 ## label_contentFleisch:conditIntervention -24.000 6.254 -3.838 ## label_contentVegetarisch:conditIntervention 28.333 6.254 4.531 ## Pr(&gt;|t|) ## (Intercept) 1.50e-06 *** ## label_contentFleisch 4.27e-10 *** ## label_contentVegetarisch 0.000120 *** ## conditIntervention 0.465516 ## label_contentFleisch:conditIntervention 0.002363 ** ## label_contentVegetarisch:conditIntervention 0.000689 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.416 on 12 degrees of freedom ## Multiple R-squared: 0.9787, Adjusted R-squared: 0.9698 ## F-statistic: 110.3 on 5 and 12 DF, p-value: 1.334e-09 autoplot(model1) + mytheme # Inspektion der Modellvoraussetzung: ist ok Fazit: Die Inspektion des Modells zeigt keine schwerwiegenden Verletzungen der Modellvoraussetzung. Nächster Schritt post-hoc-Tests nach Tukey. # post-hoc-Tests nach Tukey TukeyHSD(model1) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = tot_sold ~ label_content * condit, data = df_) ## ## $label_content ## diff lwr upr p adj ## Fleisch-Buffet 68.33333 59.99107 76.67559 0.0e+00 ## Vegetarisch-Buffet 38.83333 30.49107 47.17559 1.0e-07 ## Vegetarisch-Fleisch -29.50000 -37.84226 -21.15774 1.9e-06 ## ## $condit ## diff lwr upr p adj ## Intervention-Basis -1.888889 -7.451701 3.673923 0.4736291 ## ## $`label_content:condit` ## diff lwr ## Fleisch:Basis-Buffet:Basis 80.333333 65.47963 ## Vegetarisch:Basis-Buffet:Basis 24.666667 9.81296 ## Buffet:Intervention-Buffet:Basis -3.333333 -18.18704 ## Fleisch:Intervention-Buffet:Basis 53.000000 38.14629 ## Vegetarisch:Intervention-Buffet:Basis 49.666667 34.81296 ## Vegetarisch:Basis-Fleisch:Basis -55.666667 -70.52037 ## Buffet:Intervention-Fleisch:Basis -83.666667 -98.52037 ## Fleisch:Intervention-Fleisch:Basis -27.333333 -42.18704 ## Vegetarisch:Intervention-Fleisch:Basis -30.666667 -45.52037 ## Buffet:Intervention-Vegetarisch:Basis -28.000000 -42.85371 ## Fleisch:Intervention-Vegetarisch:Basis 28.333333 13.47963 ## Vegetarisch:Intervention-Vegetarisch:Basis 25.000000 10.14629 ## Fleisch:Intervention-Buffet:Intervention 56.333333 41.47963 ## Vegetarisch:Intervention-Buffet:Intervention 53.000000 38.14629 ## Vegetarisch:Intervention-Fleisch:Intervention -3.333333 -18.18704 ## upr p adj ## Fleisch:Basis-Buffet:Basis 95.18704 0.0000000 ## Vegetarisch:Basis-Buffet:Basis 39.52037 0.0012966 ## Buffet:Intervention-Buffet:Basis 11.52037 0.9704018 ## Fleisch:Intervention-Buffet:Basis 67.85371 0.0000006 ## Vegetarisch:Intervention-Buffet:Basis 64.52037 0.0000012 ## Vegetarisch:Basis-Fleisch:Basis -40.81296 0.0000003 ## Buffet:Intervention-Fleisch:Basis -68.81296 0.0000000 ## Fleisch:Intervention-Fleisch:Basis -12.47963 0.0005207 ## Vegetarisch:Intervention-Fleisch:Basis -15.81296 0.0001771 ## Buffet:Intervention-Vegetarisch:Basis -13.14629 0.0004174 ## Fleisch:Intervention-Vegetarisch:Basis 43.18704 0.0003741 ## Vegetarisch:Intervention-Vegetarisch:Basis 39.85371 0.0011541 ## Fleisch:Intervention-Buffet:Intervention 71.18704 0.0000003 ## Vegetarisch:Intervention-Buffet:Intervention 67.85371 0.0000006 ## Vegetarisch:Intervention-Fleisch:Intervention 11.52037 0.9704018 3.5.1 Methoden Ziel war es, die Unterschiede in den Verkaufszahlen pro Menü-Inhalt und pro Bedingung aufzuzeigen. Da die Kriteriumsvariable (Verkaufszahlen) metrisch und die beiden Prädiktorvariablen kategorial sind, wurde eine zweifaktorielle ANOVA mit Interaktion gerechnet. Die visuelle Inspektion des Models zeigte keine schwerwiegenden Verletzungen der Voraussetzungen. Um die Einzelvergleiche zu sehen, wurde einen post-hoc-Test nach Tukey durchgeführt. 3.5.2 Ergebnisse Die Menü-Inhalte (Fleisch, Vegetarisch und Buffet) zwischen den Bedingungen Basis oder Interventionswochen unterscheiden sich in den Verkaufszahlen signifikant (F(5, 12) = 110.252, p &lt; .001). Anschliessend durchgeführte post-hoc-Tests (Tukey) zeigen vor allem zwei interessante Ergbenisse: 1) in den Interventionswochen wurden signifikant weniger Fleischgerichte gekauft als in den Basiswochen 2) in den Interventionswochen wurden signifikant mehr vegetarische Gerichte verkauft (siehe Figure 1 oder Figure 2). Figure 3.2: Box-Whisker-Plots der wöchentlichen Verkaufszahlen pro Menü-Inhalte. Kleinbuchstaben bezeichnen homogene Gruppen auf p &lt; .05 nach Tukeys post-hoc-Test. Figure 3.3: Wöchentliche Verkaufszahlen aggregiert für die drei Menü-Inhalte. "]
]
