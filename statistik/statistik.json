[
  {
    "path": "statistik/Statistik1_Assigment/",
    "title": "Aufgabe 1",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nAufgabe 1.1: Assoziationstest\nBitte führt einen Assoziationstest zweier kategorialer Variablen (mit je zwei Ausprägungen) mit Chi-Quadrat und Fishers exaktem Test durch. Ihr habt zwei Möglichkeiten: (1) Ihr erhebt dazu selbst die Daten (wozu ihr euch auch in Teams zusammenschliessen könnt). Dabei könnt ihr sowohl Befragungen/Datenerhebung unter Mitstudierenden durchführen (etwa Nutzung Mac/Windows vs. männlich/weiblich) oder Daten zu anderen Objekten erheben. (2) Ihr nehmt zwei kategoriale Variablen aus einem der Novanimal-Datensätze (Feldexperiment oder Gästebefragung).  Bitte formuliert in beiden Fällen vor der Datenerhebung/Datenextraktion eine Hypothese, d.h. eine Erwartungshaltung, ob und welche Assoziation vorliegt und wenn ja warum. Bitte beachtet, dass ihr für die Form des Assoziationstests aus dem Kurs zwei binäre Variablen benötigt; wenn ihr also kategoriale Variablen mit mehr als zwei Ausprägungen habt, könnt ihr entweder Ausprägungen sinnvoll zusammenfassen oder seltene Ausprägungen im Test unberücksichtigt lassen.\nAufgabe 1.2: t-Test\nWerden in den Basis- und Interventionswochen unterschiedlich viele Gerichte verkauft?\nDefiniere die Null- (\\(H_0\\)) und die Alternativhypothese (\\(H_1\\)).\nFühre einen t-Test durch.\nWelche Form von t-Test musst Du anwenden: einseitig/zweiseitig resp. gepaart/ungepaart?\nWie gut sind die Voraussetzungen für einen t-Test erfüllt (z.B. Normalverteilung der Residuen und Varianzhomogenität)?\nStelle deine Ergebnisse angemessen dar, d.h. Text mit Abbildung und/oder Tabelle\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_Demo/",
    "title": "Demo Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\n\n\nDemoskript als Download\nBinomialtest\n\n\nbinom.test(43, 100) #In Klammern übergibt man die Anzahl der Erfolge und die Stichprobengrösse\n\n\n\n    Exact binomial test\n\ndata:  43 and 100\nnumber of successes = 43, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.3313910 0.5328663\nsample estimates:\nprobability of success \n                  0.43 \n\nbinom.test(57, 100)\n\n\n\n    Exact binomial test\n\ndata:  57 and 100\nnumber of successes = 57, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4671337 0.6686090\nsample estimates:\nprobability of success \n                  0.57 \n\nChi-Quadrat-Test & Fishers Test\nErmitteln des kritischen Wertes\n\n\nqchisq(0.95, 1)\n\n\n[1] 3.841459\n\nDirekter Test in R (dazu Werte als Matrix nötig)\n\n\ncount <- matrix(c(38, 14, 11, 51), nrow = 2)\ncount\n\n\n     [,1] [,2]\n[1,]   38   11\n[2,]   14   51\n\nchisq.test(count)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  count\nX-squared = 33.112, df = 1, p-value = 8.7e-09\n\nfisher.test(count)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  count\np-value = 2.099e-09\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  4.746351 34.118920\nsample estimates:\nodds ratio \n  12.22697 \n\nt-Test\n\n\na <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14)\nb <- c(12, 15, 16,7, 8, 10, 12, 11, 13, 10)\nblume <- data.frame(a,b)\nblume\n\n\n    a  b\n1  20 12\n2  19 15\n3  25 16\n4  10  7\n5   8  8\n6  15 10\n7  13 12\n8  18 11\n9  11 13\n10 14 10\n\nsummary(blume)\n\n\n       a               b        \n Min.   : 8.00   Min.   : 7.00  \n 1st Qu.:11.50   1st Qu.:10.00  \n Median :14.50   Median :11.50  \n Mean   :15.30   Mean   :11.40  \n 3rd Qu.:18.75   3rd Qu.:12.75  \n Max.   :25.00   Max.   :16.00  \n\nboxplot(blume$a, blume$b)\n\n\n\nboxplot(blume)\n\n\n\nhist(blume$a)\n\n\n\nhist(blume$b)\n\n\n\n\nzweiseitiger t-Test\n\n\nt.test(blume$a, blume$b)\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\neinseitiger t-Test\n\n\nt.test(blume$a, blume$b, alternative = \"greater\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.02827\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 0.5954947       Inf\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nt.test(blume$a, blume$b, alternative = \"less\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.9717\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 7.204505\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nklassischer t-Test vs. Welch Test\n\n\n# Varianzen gleich, klassischer t-Test\nt.test(blume$a, blume$b, var.equal = T) \n\n\n\n    Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\n# Varianzen ungleich, Welch's t-Test, ist auch default, d.h. wenn var.equal nicht  definiert wird, wird ein Welch's t-Test ausgeführt. \nt.test(blume$a, blume$b, var.equal = F) \n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\ngepaarter t-Test\n\n\nt.test(blume$a, blume$b, paired = T)\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nt.test(blume$a, blume$b, paired = T, alternative = \"greater\")\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.003458\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 1.846877      Inf\nsample estimates:\nmean of the differences \n                    3.9 \n\nWilcoxon-Vorzeichen-Rang-Test\n\n\nshapiro.test(blume$b)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume$b\nW = 0.97341, p-value = 0.9206\n\nvar.test(blume$a, blume$b)\n\n\n\n    F test to compare two variances\n\ndata:  blume$a and blume$b\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")} # installiert das Zusatzpacket car (wenn nicht bereits installiert)\nlibrary(car)\nleveneTest(blume$a, blume$b, center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume$a, blume$b)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume$a and blume$b\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nDas gleiche mit einem “long table”\n\n\ncultivar <- c(rep(\"a\", 10), rep(\"b\", 10))\nsize <- c(a,b)\nblume.long <- data.frame(cultivar, size)\n\nrm(size) #Befehl rm entfernt die nicht mehr benötitgten Objekte aus dem Workspace\nrm(cultivar)\n\n\n\nDas gleiche in einer Zeile\n\n\nblume.long <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10)), size = c(a, b))\nsummary(blume.long)             \n\n\n   cultivar              size      \n Length:20          Min.   : 7.00  \n Class :character   1st Qu.:10.00  \n Mode  :character   Median :12.50  \n                    Mean   :13.35  \n                    3rd Qu.:15.25  \n                    Max.   :25.00  \n\nhead(blume.long)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\nboxplot(size~cultivar, data = blume.long)\n\n\n\nt.test(size~cultivar, blume.long, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\n# gepaarter t-Test erster Wert von Cultivar a wird mit erstem Wert von Cultivar\n# b gepaart, zweiter Wert von a mit zweitem von b ect.\nt.test(size~cultivar, blume.long, paired = T)\n\n\n\n    Paired t-test\n\ndata:  size by cultivar\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nBase R vs. ggplot2\n\n\nlibrary(tidyverse)\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot()\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot() + theme_classic()\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot(size = 1) + theme_classic()+\ntheme(axis.line = element_line(size=1)) + theme(axis.title = element_text(size = 14))+\ntheme(axis.text = element_text(size=14))\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot(size=1) + theme_classic()+\n  theme(axis.line = element_line(size=1), axis.ticks = element_line(size = 1), \n       axis.text = element_text(size = 20), axis.title = element_text(size = 20))\n\n\n\n\nDefinieren von mytheme mit allen gewünschten Settings, das man zu Beginn einer Sitzung einmal laden und dann immer wieder ausführen kann (statt des langen Codes)\n\n\nmytheme <- theme_classic() + \n  theme(axis.line = element_line(color = \"black\", size=1), \n        axis.text = element_text(size = 20, color = \"black\"), \n        axis.title = element_text(size = 20, color = \"black\"), \n        axis.ticks = element_line(size = 1, color = \"black\"), \n        axis.ticks.length = unit(.5, \"cm\"))\n\n\n\n\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) +\n  mytheme\n\n\n\nt_test <- t.test(size~cultivar, blume.long)\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  annotate(\"text\", x = \"b\", y = 24, label = paste0(\"italic(p) == \", round(t_test$p.value, 3)), parse = TRUE, size = 8)\n\n\n\nggplot (blume.long, aes(cultivar,size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  labs(x=\"Cultivar\",y=\"Size (cm)\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_Demo/distill-preview.png",
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_Assigment/",
    "title": "Aufgabe 2",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik2"
    ],
    "contents": "\nAbzugeben sind am Ende\na. lauffähiges R-Skript\nb. begründeter Lösungsweg (Kombination aus R-Code, R Output \n   und dessen Interpretation)\nc. ausformulierter Methoden- und Ergebnisteil (für eine wiss.Arbeit).\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu eurem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in dem ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentiert.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen etc.\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens\nBestimmung des vollständigen/maximalen Models\nSelektion des/der besten Models/Modelle\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen/Tabellen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (je einen ausformulierten Absatz von ca. 60-100 Worten bzw. 3-8 Sätzen). Alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAufgabe 2.1: Regression\nRegressionsanalyse mit SAR.csv\nDer Datensatz beschreibt die Zunahme der Artenzahlen (richness) von Pflanzen in Trockenrasen der Schweiz in Abhängigkeit von der Probeflächengrösse (area, hier in m²). Diese Beziehung bezeichnet man als Artenzahl-Areal-Kurve (Species-area relationship = SAR).\nLadet den Datensatz in R und macht eine explorative Datenanalyse.\nWählt unter den schon gelernten Methoden der Regressionsanalyse ein adäquates Vorgehen zur Analyse dieser Daten und führt diese dann durch.\nPrüft anhand der Residuen, ob die Modellvoraussetzungen erfüllt waren\nFalls die Modelldiagnostik negativ ausfällt, überlegt, welche Datentransformation helfen könnte, und rechnet neue Modelle mit einer oder ggf. mehreren Datentransformationen, bis ihr eine statistisch zufriedenstellende Lösung gefunden habt.\nStellt die erhaltenen Ergebnisse angemessen dar (Text, Abbildung und/oder Tabelle).\nKennt ihr ggf. noch eine andere geeignete Herangehensweise?\nAufgabe 2.2: Einfaktorielle ANOVA\nANOVA mit novanimal_agg.csv\nFührt mit dem Datensatz novanimal.csv eine einfaktorielle ANOVA durch. Gibt es Unterschiede zwischen der Anzahl verkaufter Gerichte (Buffet, Fleisch oder Vegetarisch) pro Woche?\nHinweise für die Analysen:\nFasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace()).\nDanach muss der Datensatz gruppiert und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nFasst die Ergebnisse in wenigen Sätzen zusammen und stellst die angemessen dar (Text mit Abbildung und/oder Tabelle)\nAufgabe 2.3N: Mehrfaktorielle ANOVA (NatWis)\nANOVA mit kormoran.csv\nDer Datensatz enthält 40 Beobachtungen zu Tauchzeiten zweier Kormoranunterarten (C = Phalocrocorax carbo carbo und S = Phalacrocorax carbo sinensis) aus vier Jahreszeiten (F = Frühling, S = Sommer, H = Herbst, W = Winter).\nLest den Datensatz nach R ein und führt eine adäquate Analyse durch, um beantworten zu können, wie Unterart und Jahreszeit die Tauchzeit beeinflussen.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\nGibt es eine Interaktion?\nUebung 2.3S: Mehrfaktorielle ANOVA mit Interaktion (SozWis)\nANOVA mit novanimal_indiv.csv\nIn der Mensa gibt es zwei unterschiedliche Preisniveaus bzgl. den Gerichten: eine preisgünstigere Menülinie (“World” & “Favorite”) und eine teuere Menülinie (“Kitchen”). Gibt es Unterschiede zwischen dem Kauf von preisgünstigeren resp. teureren Menülinien betreffend Menüinhalt & Hochschulzugehörigkeit?\nHinweise für die Analysen:\nFasst die zwei günstigeren Menülinien “Favorite” & “World” zu einer Menülinie zusammen. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace() oder base::sub()).\nKleiner Hinweis: “Local” Gerichte könnt ihr zu den anderen Gerichten dazu zählen z.B. Local Favorite -> Favorite\nDanach muss der Datensatz gruppiert (nach Menülinie & Hochschulzugehörigkeit) und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik2_Demo/",
    "title": "Demo Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nt-test als ANOVA\nEchte ANOVA\nTukeys Posthoc-Test\nBeispiel Posthoc-Labels in Plot\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n2-faktorielle ANOVA\nKorrelationen\nBeispiele Modelldiagnostik\n\n\n\n\nDemoscript als Download\nt-test als ANOVA\n\n\na <- c(20, 19, 25, 10, 8, 15, 13 ,18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\n\nblume <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\" , 10)), size = c(a, b))\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Bluetengroesse [cm]\", data=blume)\n\n\n\nt.test(size~cultivar, blume, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\naov(size~cultivar, data = blume)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume)\n\nTerms:\n                cultivar Residuals\nSum of Squares     76.05    316.50\nDeg. of Freedom        1        18\n\nResidual standard error: 4.193249\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume))\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ncultivar     1   76.0   76.05   4.325 0.0521 .\nResiduals   18  316.5   17.58                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data = blume))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -2.575 -0.350  2.925  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.326   11.54 9.47e-10 ***\ncultivarb     -3.900      1.875   -2.08   0.0521 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.193 on 18 degrees of freedom\nMultiple R-squared:  0.1937,    Adjusted R-squared:  0.1489 \nF-statistic: 4.325 on 1 and 18 DF,  p-value: 0.05212\n\nEchte ANOVA\n\n\nc <- c(30, 19, 31, 23, 18, 25, 26, 24, 17, 20)\n\nblume2 <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10), rep(\"c\", 10)), size=c(a, b, c))\nblume2$cultivar <- as.factor(blume2$cultivar)\n\nsummary(blume2)             \n\n\n cultivar      size      \n a:10     Min.   : 7.00  \n b:10     1st Qu.:11.25  \n c:10     Median :15.50  \n          Mean   :16.67  \n          3rd Qu.:20.00  \n          Max.   :31.00  \n\nhead(blume2)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Blütengrösse [cm]\", data = blume2)\n\n\n\naov(size~cultivar, data = blume2)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume2)\n\nTerms:\n                cultivar Residuals\nSum of Squares  736.0667  528.6000\nDeg. of Freedom        2        27\n\nResidual standard error: 4.424678\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data=blume2))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\naov.1 <- aov(size~cultivar, data = blume2)\nsummary(aov.1)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov.1)\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\n#Berechnung Mittelwerte usw. zur Charakterisierung der Gruppen\naggregate(size~cultivar, blume2, function(x) c(Mean = mean(x), SD = sd(x), Min = min(x), Max=max(x)))\n\n\n  cultivar size.Mean   size.SD  size.Min  size.Max\n1        a 15.300000  5.207900  8.000000 25.000000\n2        b 11.400000  2.836273  7.000000 16.000000\n3        c 23.300000  4.854551 17.000000 31.000000\n\nlm.1 <- lm(size~cultivar, data = blume2)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\nTukeys Posthoc-Test\n\n\nif(!require(agricolae)){install.packages(\"agricolae\")}\nlibrary(agricolae)\n\nHSD.test(aov.1, \"cultivar\", group = FALSE, console = T)\n\n\n\nStudy: aov.1 ~ \"cultivar\"\n\nHSD Test for size \n\nMean Square Error:  19.57778 \n\ncultivar,  means\n\n  size      std  r Min Max\na 15.3 5.207900 10   8  25\nb 11.4 2.836273 10   7  16\nc 23.3 4.854551 10  17  31\n\nAlpha: 0.05 ; DF Error: 27 \nCritical Value of Studentized Range: 3.506426 \n\nComparison between treatments means\n\n      difference pvalue signif.        LCL       UCL\na - b        3.9 0.1388          -1.006213  8.806213\na - c       -8.0 0.0011      ** -12.906213 -3.093787\nb - c      -11.9 0.0000     *** -16.806213 -6.993787\n\nBeispiel Posthoc-Labels in Plot\n\n\naov.2 <- aov(Sepal.Width ~ Species, data = iris)\nHSD.test(aov.2, \"Species\", console = T)\n\n\n\nStudy: aov.2 ~ \"Species\"\n\nHSD Test for Sepal.Width \n\nMean Square Error:  0.1153878 \n\nSpecies,  means\n\n           Sepal.Width       std  r Min Max\nsetosa           3.428 0.3790644 50 2.3 4.4\nversicolor       2.770 0.3137983 50 2.0 3.4\nvirginica        2.974 0.3224966 50 2.2 3.8\n\nAlpha: 0.05 ; DF Error: 147 \nCritical Value of Studentized Range: 3.348424 \n\nMinimun Significant Difference: 0.1608553 \n\nTreatments with the same letter are not significantly different.\n\n           Sepal.Width groups\nsetosa           3.428      a\nvirginica        2.974      b\nversicolor       2.770      c\n\nboxplot(Sepal.Width ~ Species, data = iris)\n\n\n\nboxplot(Sepal.Width ~ Species, ylim=c(2, 5), data = iris)\ntext(1, 4.8, \"a\")\ntext(2, 4.8, \"c\")\ntext(3, 4.8, \"b\")\n\n\n\nlibrary(tidyverse)\nggplot(iris, aes(Species, Sepal.Width)) + geom_boxplot(size = 1) +\n  annotate(\"text\", y = 5, x = 1:3, label = c(\"a\", \"c\", \"b\"))\n\n\n\n\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\n\n\nshapiro.test(blume2$size[blume2$cultivar == \"a\"])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume2$size[blume2$cultivar == \"a\"]\nW = 0.97304, p-value = 0.9175\n\nvar.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    F test to compare two variances\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")}\nlibrary(car)\nleveneTest(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"], center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\n\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\n\n\nkruskal.test(size~cultivar, data = blume2)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  size by cultivar\nKruskal-Wallis chi-squared = 16.686, df = 2, p-value =\n0.0002381\n\nif(!require(FSA)){install.packages(\"FSA\")} \nlibrary(FSA)\ndunnTest(size~cultivar, method = \"bh\", data = blume2) #korrigierte p-Werte nach Bejamini-Hochberg\n\n\n  Comparison         Z      P.unadj        P.adj\n1      a - b  1.526210 1.269575e-01 0.1269575490\n2      a - c -2.518247 1.179407e-02 0.0176911039\n3      b - c -4.044457 5.244459e-05 0.0001573338\n\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n\n\noneway.test(size~cultivar, var.equal = F, data = blume2)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  size and cultivar\nF = 21.642, num df = 2.000, denom df = 16.564, p-value =\n2.397e-05\n\n2-faktorielle ANOVA\n\n\nd <- c(10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\ne <- c(15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nblume3 <- data.frame(cultivar=c(rep(\"a\", 20), rep(\"b\", 20), rep(\"c\", 20)),\n                   house = c(rep(c(rep(\"yes\", 10), rep(\"no\", 10)), 3)),\n                  size = c(a, b, c, d, e, f))\n\n\n\n\n\nblume3\n\n\n   cultivar house size\n1         a   yes   20\n2         a   yes   19\n3         a   yes   25\n4         a   yes   10\n5         a   yes    8\n6         a   yes   15\n7         a   yes   13\n8         a   yes   18\n9         a   yes   11\n10        a   yes   14\n11        a    no   12\n12        a    no   15\n13        a    no   16\n14        a    no    7\n15        a    no    8\n16        a    no   10\n17        a    no   12\n18        a    no   11\n19        a    no   13\n20        a    no   10\n21        b   yes   30\n22        b   yes   19\n23        b   yes   31\n24        b   yes   23\n25        b   yes   18\n26        b   yes   25\n27        b   yes   26\n28        b   yes   24\n29        b   yes   17\n30        b   yes   20\n31        b    no   10\n32        b    no   12\n33        b    no   11\n34        b    no   13\n35        b    no   10\n36        b    no   25\n37        b    no   12\n38        b    no   30\n39        b    no   26\n40        b    no   13\n41        c   yes   15\n42        c   yes   13\n43        c   yes   18\n44        c   yes   11\n45        c   yes   14\n46        c   yes   25\n47        c   yes   39\n48        c   yes   38\n49        c   yes   28\n50        c   yes   24\n51        c    no   10\n52        c    no   12\n53        c    no   11\n54        c    no   13\n55        c    no   10\n56        c    no    9\n57        c    no    2\n58        c    no    4\n59        c    no    7\n60        c    no   13\n\n\n\nboxplot(size~cultivar+house, data = blume3)\n\n\n\nsummary(aov(size~cultivar+house, data = blume3))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  417.1   208.5   5.005     0.01 *  \nhouse        1  992.3   992.3  23.815 9.19e-06 ***\nResiduals   56 2333.2    41.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar+house+cultivar:house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar*house, data = blume3)) #Kurzschreibweise: \"*\" bedeutet, dass Interaktion zwischen cultivar und house eingeschlossen wird\n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar+house, data = blume3))\n\n\n\nCall:\naov(formula = size ~ cultivar + house, data = blume3)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.733 -4.696 -1.050  2.717 19.133 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.283      1.667   5.570 7.52e-07 ***\ncultivarb      6.400      2.041   3.135  0.00273 ** \ncultivarc      2.450      2.041   1.200  0.23509    \nhouseyes       8.133      1.667   4.880 9.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.455 on 56 degrees of freedom\nMultiple R-squared:  0.3766,    Adjusted R-squared:  0.3432 \nF-statistic: 11.28 on 3 and 56 DF,  p-value: 6.848e-06\n\ninteraction.plot(blume3$cultivar, blume3$house, blume3$size)\n\n\n\ninteraction.plot(blume3$house, blume3$cultivar, blume3$size)\n\n\n\nanova(lm(blume3$size~blume3$cultivar*blume3$house), lm(blume3$size~blume3$cultivar+blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$cultivar * blume3$house\nModel 2: blume3$size ~ blume3$cultivar + blume3$house\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     54 2099.6                              \n2     56 2333.2 -2   -233.63 3.0044 0.05792 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(lm(blume3$size~blume3$house), lm(blume3$size~blume3$cultivar*blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$house\nModel 2: blume3$size ~ blume3$cultivar * blume3$house\n  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n1     58 2750.3                                \n2     54 2099.6  4    650.73 4.1841 0.005045 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nKorrelationen\n\n\nlibrary(car)\n\nblume <- data.frame(a, b)\nscatterplot(a~b, blume)\n\n\n\ncor.test(a, b, method = \"pearson\", data = blume)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  a and b\nt = 3.3678, df = 8, p-value = 0.009818\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2628864 0.9414665\nsample estimates:\n      cor \n0.7657634 \n\ncor.test(a, b, method = \"spearman\", data = blume)\n\n\n\n    Spearman's rank correlation rho\n\ndata:  a and b\nS = 53.321, p-value = 0.03159\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6768419 \n\ncor.test(a, b, method = \"kendall\", data = blume) \n\n\n\n    Kendall's rank correlation tau\n\ndata:  a and b\nz = 2.0738, p-value = 0.03809\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5228623 \n\n#Jetzt als Regression\nlm.2 <- lm(b~a)\nanova(lm.2)\n\n\nAnalysis of Variance Table\n\nResponse: b\n          Df Sum Sq Mean Sq F value   Pr(>F)   \na          1 42.455  42.455  11.342 0.009818 **\nResiduals  8 29.945   3.743                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = b ~ a)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1897 -1.3388 -0.6067  1.3081  3.3933 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   5.0193     1.9910   2.521  0.03575 * \na             0.4170     0.1238   3.368  0.00982 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.935 on 8 degrees of freedom\nMultiple R-squared:  0.5864,    Adjusted R-squared:  0.5347 \nF-statistic: 11.34 on 1 and 8 DF,  p-value: 0.009818\n\n#Model II-Regression\nif(!require(lmodel2)){install.packages(\"lmodel2\")} \nlibrary(lmodel2)\nlmodel2(b~a)\n\n\n\nModel II regression\n\nCall: lmodel2(formula = b ~ a)\n\nn = 10   r = 0.7657634   r-square = 0.5863936 \nParametric P-values:   2-tailed = 0.009817588    1-tailed = 0.004908794 \nAngle between the two OLS regression lines = 12.78218 degrees\n\nRegression results\n  Method Intercept     Slope Angle (degrees) P-perm (1-tailed)\n1    OLS  5.019254 0.4170422        22.63820                NA\n2     MA  4.288499 0.4648040        24.92919                NA\n3    SMA  3.067471 0.5446097        28.57314                NA\n\nConfidence intervals\n  Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope\n1    OLS      0.4280737        9.610435  0.1314843   0.7026001\n2     MA     -1.4843783        8.769024  0.1719592   0.8421162\n3    SMA     -2.3775157        6.360555  0.3293755   0.9004912\n\nEigenvalues: 32.37967 2.786995 \n\nH statistic used for computing C.I. of MA: 0.0684968 \n\nBeispiele Modelldiagnostik\n\n\npar(mfrow=c(2, 2)) #4 Plots in einem Fenster\nplot(lm(b~a))\n\n\n\nif(!require(ggfortify)){install.packages(\"ggfortify\")}\nlibrary(ggfortify)\nautoplot(lm(b~a))\n\n\n\n#Modellstatistik nicht OK\ng <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nh <- c(12, 15, 10, 7, 8, 10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\npar(mfrow=c(1, 1))\n\nplot(h~g,xlim = c(0,40), ylim = c(0, 30))\nabline(lm(h~g))\n\n\n\npar(mfrow=c(2,2))\nplot(lm(h~g))\n\n\n\n#Modelldiagnostik mit ggplot\ndf <- data.frame(g, h)\nggplot(df, aes(x = g, y = h)) + \n    # scale_x_continuous(limits = c(0,25)) +\n    # scale_y_continuous(limits = c(0,25)) +\n    geom_point() +\n    geom_smooth( method = \"lm\", color = \"black\", size = .5, se = F) + \n    theme_classic()\n\n\n\npar(mfrow=c(2,2))\nautoplot(lm(h~g))\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_Demo/distill-preview.png",
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_assigment/",
    "title": "Aufgabe 3",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik3"
    ],
    "contents": "\nAufgabe 3: Multiple Regression\nBereiten Sie den Datensatz Ukraine.xlsx für das Einlesen in R vor und lesen Sie ihn dann ein. Dieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von 199 10 m² grossen Plots (Vegetationsaufnahmen) von Steppenrasen in der Ukraine sowie zahlreiche Umweltvariablen, deren Bedeutung und Einheiten im Kopf der ExcelTabelle angegeben sind.\nErmitteln Sie ein minimal adäquates Modell, das den Artenreichtum in den Plots durch die Umweltvariablen erklärt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen: welches sind die abhängige(n) und welches die unabängige(n) Variablen, sind alle Variablen für die Analyse geeignet?\nExplorative Datenanalyse, um zu sehen, ob die abhängige Variable in der vorliegenden Form für die Analyse geeignet ist\nDefinition eines globalen Modelles und dessen Reduktion zu einem minimal adäquaten Modell\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\n",
    "preview": {},
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik4_assigment/",
    "title": "Aufgabe 4",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nAufgabe 4.1: Nicht-lineare Regression\nAufgabe 4.2N: Logistische Regression (NatWis)\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\n\nAufgabe 4.1: Nicht-lineare Regression\nDatensatz Curonian_Spit.xlsx\nDieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von geschachtelten Plots (Vegetationsaufnahmen) der Pflanzengesellschaft LolioCynosuretum im Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis 900 m².\nErmittelt den funktionellen Zusammenhang (das beste Modell), der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt.Berücksichtigt dabei mindestens die Potenzfunktion (power function, die logarithmische Funktion (logarithmic function,und eine Funktion mit Sättigung (saturation, asymptote) eurer Wahl.\nAufgabe 4.2N: Logistische Regression (NatWis)\nDatensatz polis.csv\nDer Datensatz polis.csv beschreibt für 19 Inseln im Golf von Kalifornien, ob Eidechsen der Gattung Uta vorkommen (presence/absence: PA) in Abhängigkeit von der Form der Inseln (Verhältnis Umfang zu Fläche: RATIO).\nBitte prüft mit einer logistischen Regression, ob und ggf. wie die Inselform die Präsenz der Eidechsen beinflusst\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\nFührt mit dem Datensatz der Gästebefragung eine logistische Regression durch. Kann der Mensabesuch druch die sozioökonomischen Variablen (Alter, Geschlecht, Hochschulzugehörigkeit), wahrgenommener Fleischkonsum und Einstellung zu ?? vorhergesagt werden?\nHinweise:\nDas Item tho_2 (“Ich mache mir allgemein Gedanken über die Folgen meiner Ernährungsgewohnheiten für die Umwelt.”) müsst ihr in einem ersten Schritt zu einer Dummy-Variable umcodieren: die Antwortkategorien «stimme eher zu» (=3) und «stimme zu» (=4) müsst ihr eine 1 zuweisen, den anderen zwei Kategorien eine 0. Hinweis dafür könnt ihr die Funktion dpylr::case_when() oder dpylr::if_else() verwenden.\nFehlende Werten könnt ihr weglassen (z.B. dpylr::drop_na())\nDefiniert das Modell und wendet es auf den Datensatz an\nBerechnet eine Vorhersage des Modells mit predict()\nEruiert den Modellfit und die Modellgenauigkeit\nFür Motivierte: Berechnet eine Konfusionsmatrix und zieht euer Fazit daraus\nStellt eure Ergebnisse angemessen dar (Text und/oder Tabelle)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-25T13:37:30+00:00",
    "input_file": {}
  }
]
