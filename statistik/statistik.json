[
  {
    "path": "statistik/Statistik1_Assigment/",
    "title": "Übungen Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nAufgabe 1.1: Assoziationstest\nBitte führt einen Assoziationstest zweier kategorialer Variablen (mit je zwei Ausprägungen) mit Chi-Quadrat und Fishers exaktem Test durch. Ihr habt zwei Möglichkeiten: (1) Ihr erhebt dazu selbst die Daten (wozu ihr euch auch in Teams zusammenschliessen könnt). Dabei könnt ihr sowohl Befragungen/Datenerhebung unter Mitstudierenden durchführen (etwa Nutzung Mac/Windows vs. männlich/weiblich) oder Daten zu anderen Objekten erheben. (2) Ihr nehmt zwei kategoriale Variablen aus einem der Novanimal-Datensätze (Feldexperiment oder Gästebefragung).  Bitte formuliert in beiden Fällen vor der Datenerhebung/Datenextraktion eine Hypothese, d.h. eine Erwartungshaltung, ob und welche Assoziation vorliegt und wenn ja warum. Bitte beachtet, dass ihr für die Form des Assoziationstests aus dem Kurs zwei binäre Variablen benötigt; wenn ihr also kategoriale Variablen mit mehr als zwei Ausprägungen habt, könnt ihr entweder Ausprägungen sinnvoll zusammenfassen oder seltene Ausprägungen im Test unberücksichtigt lassen.\nAufgabe 1.2: t-Test\nWerden in den Basis- und Interventionswochen unterschiedlich viele Gerichte verkauft?\nDefiniere die Null- (\\(H_0\\)) und die Alternativhypothese (\\(H_1\\)).\nFühre einen t-Test durch.\nWelche Form von t-Test musst Du anwenden: einseitig/zweiseitig resp. gepaart/ungepaart?\nWie gut sind die Voraussetzungen für einen t-Test erfüllt (z.B. Normalverteilung der Residuen und Varianzhomogenität)?\nStelle deine Ergebnisse angemessen dar, d.h. Text mit Abbildung und/oder Tabelle\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_Demo/",
    "title": "Demo Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\n\n\nDemoskript als Download\nBinomialtest\n\n\nbinom.test(43, 100) #In Klammern übergibt man die Anzahl der Erfolge und die Stichprobengrösse\n\n\n\n    Exact binomial test\n\ndata:  43 and 100\nnumber of successes = 43, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.3313910 0.5328663\nsample estimates:\nprobability of success \n                  0.43 \n\nbinom.test(57, 100)\n\n\n\n    Exact binomial test\n\ndata:  57 and 100\nnumber of successes = 57, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4671337 0.6686090\nsample estimates:\nprobability of success \n                  0.57 \n\nChi-Quadrat-Test & Fishers Test\nErmitteln des kritischen Wertes\n\n\nqchisq(0.95, 1)\n\n\n[1] 3.841459\n\nDirekter Test in R (dazu Werte als Matrix nötig)\n\n\ncount <- matrix(c(38, 14, 11, 51), nrow = 2)\ncount\n\n\n     [,1] [,2]\n[1,]   38   11\n[2,]   14   51\n\nchisq.test(count)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  count\nX-squared = 33.112, df = 1, p-value = 8.7e-09\n\nfisher.test(count)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  count\np-value = 2.099e-09\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  4.746351 34.118920\nsample estimates:\nodds ratio \n  12.22697 \n\nt-Test\n\n\na <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14)\nb <- c(12, 15, 16,7, 8, 10, 12, 11, 13, 10)\nblume <- data.frame(a,b)\nblume\n\n\n    a  b\n1  20 12\n2  19 15\n3  25 16\n4  10  7\n5   8  8\n6  15 10\n7  13 12\n8  18 11\n9  11 13\n10 14 10\n\nsummary(blume)\n\n\n       a               b        \n Min.   : 8.00   Min.   : 7.00  \n 1st Qu.:11.50   1st Qu.:10.00  \n Median :14.50   Median :11.50  \n Mean   :15.30   Mean   :11.40  \n 3rd Qu.:18.75   3rd Qu.:12.75  \n Max.   :25.00   Max.   :16.00  \n\nboxplot(blume$a, blume$b)\n\n\n\nboxplot(blume)\n\n\n\nhist(blume$a)\n\n\n\nhist(blume$b)\n\n\n\n\nzweiseitiger t-Test\n\n\nt.test(blume$a, blume$b)\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\neinseitiger t-Test\n\n\nt.test(blume$a, blume$b, alternative = \"greater\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.02827\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 0.5954947       Inf\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nt.test(blume$a, blume$b, alternative = \"less\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.9717\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 7.204505\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nklassischer t-Test vs. Welch Test\n\n\n# Varianzen gleich, klassischer t-Test\nt.test(blume$a, blume$b, var.equal = T) \n\n\n\n    Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\n# Varianzen ungleich, Welch's t-Test, ist auch default, d.h. wenn var.equal nicht  definiert wird, wird ein Welch's t-Test ausgeführt. \nt.test(blume$a, blume$b, var.equal = F) \n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\ngepaarter t-Test\n\n\nt.test(blume$a, blume$b, paired = T)\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nt.test(blume$a, blume$b, paired = T, alternative = \"greater\")\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.003458\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 1.846877      Inf\nsample estimates:\nmean of the differences \n                    3.9 \n\nWilcoxon-Vorzeichen-Rang-Test\n\n\nshapiro.test(blume$b)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume$b\nW = 0.97341, p-value = 0.9206\n\nvar.test(blume$a, blume$b)\n\n\n\n    F test to compare two variances\n\ndata:  blume$a and blume$b\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")} # installiert das Zusatzpacket car (wenn nicht bereits installiert)\nlibrary(car)\nleveneTest(blume$a, blume$b, center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume$a, blume$b)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume$a and blume$b\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nDas gleiche mit einem “long table”\n\n\ncultivar <- c(rep(\"a\", 10), rep(\"b\", 10))\nsize <- c(a,b)\nblume.long <- data.frame(cultivar, size)\n\nrm(size) #Befehl rm entfernt die nicht mehr benötitgten Objekte aus dem Workspace\nrm(cultivar)\n\n\n\nDas gleiche in einer Zeile\n\n\nblume.long <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10)), size = c(a, b))\nsummary(blume.long)             \n\n\n   cultivar              size      \n Length:20          Min.   : 7.00  \n Class :character   1st Qu.:10.00  \n Mode  :character   Median :12.50  \n                    Mean   :13.35  \n                    3rd Qu.:15.25  \n                    Max.   :25.00  \n\nhead(blume.long)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\nboxplot(size~cultivar, data = blume.long)\n\n\n\nt.test(size~cultivar, blume.long, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\n# gepaarter t-Test erster Wert von Cultivar a wird mit erstem Wert von Cultivar\n# b gepaart, zweiter Wert von a mit zweitem von b ect.\nt.test(size~cultivar, blume.long, paired = T)\n\n\n\n    Paired t-test\n\ndata:  size by cultivar\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nBase R vs. ggplot2\n\n\nlibrary(tidyverse)\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot()\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot() + theme_classic()\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot(size = 1) + theme_classic()+\ntheme(axis.line = element_line(size=1)) + theme(axis.title = element_text(size = 14))+\ntheme(axis.text = element_text(size=14))\n\n\n\nggplot(blume.long, aes(cultivar,size)) + geom_boxplot(size=1) + theme_classic()+\n  theme(axis.line = element_line(size=1), axis.ticks = element_line(size = 1), \n       axis.text = element_text(size = 20), axis.title = element_text(size = 20))\n\n\n\n\nDefinieren von mytheme mit allen gewünschten Settings, das man zu Beginn einer Sitzung einmal laden und dann immer wieder ausführen kann (statt des langen Codes)\n\n\nmytheme <- theme_classic() + \n  theme(axis.line = element_line(color = \"black\", size=1), \n        axis.text = element_text(size = 20, color = \"black\"), \n        axis.title = element_text(size = 20, color = \"black\"), \n        axis.ticks = element_line(size = 1, color = \"black\"), \n        axis.ticks.length = unit(.5, \"cm\"))\n\n\n\n\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) +\n  mytheme\n\n\n\nt_test <- t.test(size~cultivar, blume.long)\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  annotate(\"text\", x = \"b\", y = 24, label = paste0(\"italic(p) == \", round(t_test$p.value, 3)), parse = TRUE, size = 8)\n\n\n\nggplot (blume.long, aes(cultivar,size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  labs(x=\"Cultivar\",y=\"Size (cm)\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_Demo/distill-preview.png",
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik1_Intro_Daten_egel/",
    "title": "Beschreibung Forschungsprojekt NOVANIMAL (NFP69)",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nIm Forschungsprojekt NOVANIMAL wird u.a. der Frage nachgegangen, was es braucht, damit Menschen freiwillig weniger tierische Produkte konsumieren? Ein interessanter Ansatzpunkt ist die Ausser-Haus-Verpflegung. Gemäss der ersten in den Jahren 2014/2015 durchgeführten nationalen Ernährungserhebung menuCH essen 70 % der Bevölkerung zwischen 18 und 75 Jahren am Mittag auswärts (Bochud et al. 2017). Daher rückt die Gastronomie als zentraler Akteur einer innovativen und nachhaltigen Ernährungswirtschaft ins Blickfeld. Welche Innovationen in der Gastronomie könnten dazu beitragen, den Pro-Kopf-Verbrauch an tierischen Nahrungsmitteln zu senken?\nDazu wurde u.a. ein Experiment in zwei Hochschulmensen durchgeführt. Forschungsleitend war die Frage, wie die Gäste dazu bewogen werden können, häufiger vegetarische oder vegane Gerichte zu wählen. Konkret wurde untersucht, wie die Gäste auf ein verändertes Menü-Angebot mit einem höheren Anteil an vegetarischen und veganen Gerichten reagieren. Das Experiment fand während 12 Wochen statt und bestand aus zwei Mensazyklen à 6 Wochen. Über den gesamten Untersuchungszeitraum werden insgesamt 90 verschiedene Gerichte angeboten. In den 6 Referenz- bzw. Basiswochen wurden zwei fleisch- oder fischhaltige Menüs und ein vegetarisches Menü angeboten. In den 6 Interventionswochen wurde das Verhältnis umgekehrt und es wurden ein veganes, ein vegetarisches und ein fleisch- oder fischhaltiges Gericht angeboten. Basis- und Interventionsangebote wechselten wöchentlich ab. Während der gesamten 12 Wochen konnten die Gäste jeweils auf ein Buffet ausweichen und ihre Mahlzeit aus warmen und kalten Komponenten selber zusammenstellen. Die Gerichte wurden über drei vorgegebene Menülinien (F, K, W) randomisiert angeboten.\nDie Abbildung zeigt das Versuchsdesign der ersten 6 Experimentwochen (Kalenderwoche 40 bis 45).Mehr Informationen über das Forschungsprojekt NOVANIMAL findet ihr auf der Webpage\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik2_Assigment/",
    "title": "Übungen Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik2"
    ],
    "contents": "\nAbzugeben sind am Ende\na. lauffähiges R-Skript\nb. begründeter Lösungsweg (Kombination aus R-Code, R Output \n   und dessen Interpretation)\nc. ausformulierter Methoden- und Ergebnisteil (für eine wiss.Arbeit).\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu eurem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in dem ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentiert.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen etc.\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens\nBestimmung des vollständigen/maximalen Models\nSelektion des/der besten Models/Modelle\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen/Tabellen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (je einen ausformulierten Absatz von ca. 60-100 Worten bzw. 3-8 Sätzen). Alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAufgabe 2.1: Regression\nRegressionsanalyse mit SAR.csv\nDer Datensatz beschreibt die Zunahme der Artenzahlen (richness) von Pflanzen in Trockenrasen der Schweiz in Abhängigkeit von der Probeflächengrösse (area, hier in m²). Diese Beziehung bezeichnet man als Artenzahl-Areal-Kurve (Species-area relationship = SAR).\nLadet den Datensatz in R und macht eine explorative Datenanalyse.\nWählt unter den schon gelernten Methoden der Regressionsanalyse ein adäquates Vorgehen zur Analyse dieser Daten und führt diese dann durch.\nPrüft anhand der Residuen, ob die Modellvoraussetzungen erfüllt waren\nFalls die Modelldiagnostik negativ ausfällt, überlegt, welche Datentransformation helfen könnte, und rechnet neue Modelle mit einer oder ggf. mehreren Datentransformationen, bis ihr eine statistisch zufriedenstellende Lösung gefunden habt.\nStellt die erhaltenen Ergebnisse angemessen dar (Text, Abbildung und/oder Tabelle).\nKennt ihr ggf. noch eine andere geeignete Herangehensweise?\nAufgabe 2.2: Einfaktorielle ANOVA\nANOVA mit novanimal_agg.csv\nFührt mit dem Datensatz novanimal.csv eine einfaktorielle ANOVA durch. Gibt es Unterschiede zwischen der Anzahl verkaufter Gerichte (Buffet, Fleisch oder Vegetarisch) pro Woche?\nHinweise für die Analysen:\nFasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace()).\nDanach muss der Datensatz gruppiert und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nFasst die Ergebnisse in wenigen Sätzen zusammen und stellst die angemessen dar (Text mit Abbildung und/oder Tabelle)\nAufgabe 2.3N: Mehrfaktorielle ANOVA (NatWis)\nANOVA mit kormoran.csv\nDer Datensatz enthält 40 Beobachtungen zu Tauchzeiten zweier Kormoranunterarten (C = Phalocrocorax carbo carbo und S = Phalacrocorax carbo sinensis) aus vier Jahreszeiten (F = Frühling, S = Sommer, H = Herbst, W = Winter).\nLest den Datensatz nach R ein und führt eine adäquate Analyse durch, um beantworten zu können, wie Unterart und Jahreszeit die Tauchzeit beeinflussen.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\nGibt es eine Interaktion?\nUebung 2.3S: Mehrfaktorielle ANOVA mit Interaktion (SozWis)\nANOVA mit novanimal_indiv.csv\nIn der Mensa gibt es zwei unterschiedliche Preisniveaus bzgl. den Gerichten: eine preisgünstigere Menülinie (“World” & “Favorite”) und eine teuere Menülinie (“Kitchen”). Gibt es Unterschiede zwischen dem Kauf von preisgünstigeren resp. teureren Menülinien betreffend Menüinhalt & Hochschulzugehörigkeit?\nHinweise für die Analysen:\nFasst die zwei günstigeren Menülinien “Favorite” & “World” zu einer Menülinie zusammen. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace() oder base::sub()).\nKleiner Hinweis: “Local” Gerichte könnt ihr zu den anderen Gerichten dazu zählen z.B. Local Favorite -> Favorite\nDanach muss der Datensatz gruppiert (nach Menülinie & Hochschulzugehörigkeit) und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik2_Demo/",
    "title": "Demo Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nt-test als ANOVA\nEchte ANOVA\nTukeys Posthoc-Test\nBeispiel Posthoc-Labels in Plot\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n2-faktorielle ANOVA\nKorrelationen\nBeispiele Modelldiagnostik\n\n\n\n\nDemoscript als Download\nt-test als ANOVA\n\n\na <- c(20, 19, 25, 10, 8, 15, 13 ,18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\n\nblume <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\" , 10)), size = c(a, b))\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Bluetengroesse [cm]\", data=blume)\n\n\n\nt.test(size~cultivar, blume, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\naov(size~cultivar, data = blume)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume)\n\nTerms:\n                cultivar Residuals\nSum of Squares     76.05    316.50\nDeg. of Freedom        1        18\n\nResidual standard error: 4.193249\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume))\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ncultivar     1   76.0   76.05   4.325 0.0521 .\nResiduals   18  316.5   17.58                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data = blume))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -2.575 -0.350  2.925  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.326   11.54 9.47e-10 ***\ncultivarb     -3.900      1.875   -2.08   0.0521 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.193 on 18 degrees of freedom\nMultiple R-squared:  0.1937,    Adjusted R-squared:  0.1489 \nF-statistic: 4.325 on 1 and 18 DF,  p-value: 0.05212\n\nEchte ANOVA\n\n\nc <- c(30, 19, 31, 23, 18, 25, 26, 24, 17, 20)\n\nblume2 <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10), rep(\"c\", 10)), size=c(a, b, c))\nblume2$cultivar <- as.factor(blume2$cultivar)\n\nsummary(blume2)             \n\n\n cultivar      size      \n a:10     Min.   : 7.00  \n b:10     1st Qu.:11.25  \n c:10     Median :15.50  \n          Mean   :16.67  \n          3rd Qu.:20.00  \n          Max.   :31.00  \n\nhead(blume2)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Blütengrösse [cm]\", data = blume2)\n\n\n\naov(size~cultivar, data = blume2)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume2)\n\nTerms:\n                cultivar Residuals\nSum of Squares  736.0667  528.6000\nDeg. of Freedom        2        27\n\nResidual standard error: 4.424678\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data=blume2))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\naov.1 <- aov(size~cultivar, data = blume2)\nsummary(aov.1)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov.1)\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\n#Berechnung Mittelwerte usw. zur Charakterisierung der Gruppen\naggregate(size~cultivar, blume2, function(x) c(Mean = mean(x), SD = sd(x), Min = min(x), Max = max(x)))\n\n\n  cultivar size.Mean   size.SD  size.Min  size.Max\n1        a 15.300000  5.207900  8.000000 25.000000\n2        b 11.400000  2.836273  7.000000 16.000000\n3        c 23.300000  4.854551 17.000000 31.000000\n\nlm.1 <- lm(size~cultivar, data = blume2)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\nTukeys Posthoc-Test\n\n\nif(!require(agricolae)){install.packages(\"agricolae\")}\nlibrary(agricolae)\n\nHSD.test(aov.1, \"cultivar\", group = FALSE, console = T)\n\n\n\nStudy: aov.1 ~ \"cultivar\"\n\nHSD Test for size \n\nMean Square Error:  19.57778 \n\ncultivar,  means\n\n  size      std  r Min Max\na 15.3 5.207900 10   8  25\nb 11.4 2.836273 10   7  16\nc 23.3 4.854551 10  17  31\n\nAlpha: 0.05 ; DF Error: 27 \nCritical Value of Studentized Range: 3.506426 \n\nComparison between treatments means\n\n      difference pvalue signif.        LCL       UCL\na - b        3.9 0.1388          -1.006213  8.806213\na - c       -8.0 0.0011      ** -12.906213 -3.093787\nb - c      -11.9 0.0000     *** -16.806213 -6.993787\n\nBeispiel Posthoc-Labels in Plot\n\n\naov.2 <- aov(Sepal.Width ~ Species, data = iris)\nHSD.test(aov.2, \"Species\", console = T)\n\n\n\nStudy: aov.2 ~ \"Species\"\n\nHSD Test for Sepal.Width \n\nMean Square Error:  0.1153878 \n\nSpecies,  means\n\n           Sepal.Width       std  r Min Max\nsetosa           3.428 0.3790644 50 2.3 4.4\nversicolor       2.770 0.3137983 50 2.0 3.4\nvirginica        2.974 0.3224966 50 2.2 3.8\n\nAlpha: 0.05 ; DF Error: 147 \nCritical Value of Studentized Range: 3.348424 \n\nMinimun Significant Difference: 0.1608553 \n\nTreatments with the same letter are not significantly different.\n\n           Sepal.Width groups\nsetosa           3.428      a\nvirginica        2.974      b\nversicolor       2.770      c\n\nboxplot(Sepal.Width ~ Species, data = iris)\n\n\n\nboxplot(Sepal.Width ~ Species, ylim = c(2, 5), data = iris)\ntext(1, 4.8, \"a\")\ntext(2, 4.8, \"c\")\ntext(3, 4.8, \"b\")\n\n\n\nlibrary(tidyverse)\nggplot(iris, aes(Species, Sepal.Width)) + geom_boxplot(size = 1) +\n  annotate(\"text\", y = 5, x = 1:3, label = c(\"a\", \"c\", \"b\"))\n\n\n\n\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\n\n\nshapiro.test(blume2$size[blume2$cultivar == \"a\"])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume2$size[blume2$cultivar == \"a\"]\nW = 0.97304, p-value = 0.9175\n\nvar.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    F test to compare two variances\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")}\nlibrary(car)\nleveneTest(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"], center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\n\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\n\n\nkruskal.test(size~cultivar, data = blume2)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  size by cultivar\nKruskal-Wallis chi-squared = 16.686, df = 2, p-value =\n0.0002381\n\nif(!require(FSA)){install.packages(\"FSA\")} \nlibrary(FSA)\ndunnTest(size~cultivar, method = \"bh\", data = blume2) #korrigierte p-Werte nach Bejamini-Hochberg\n\n\n  Comparison         Z      P.unadj        P.adj\n1      a - b  1.526210 1.269575e-01 0.1269575490\n2      a - c -2.518247 1.179407e-02 0.0176911039\n3      b - c -4.044457 5.244459e-05 0.0001573338\n\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n\n\noneway.test(size~cultivar, var.equal = F, data = blume2)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  size and cultivar\nF = 21.642, num df = 2.000, denom df = 16.564, p-value =\n2.397e-05\n\n2-faktorielle ANOVA\n\n\nd <- c(10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\ne <- c(15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nblume3 <- data.frame(cultivar=c(rep(\"a\", 20), rep(\"b\", 20), rep(\"c\", 20)),\n                   house = c(rep(c(rep(\"yes\", 10), rep(\"no\", 10)), 3)),\n                  size = c(a, b, c, d, e, f))\n\n\n\n\n\nblume3\n\n\n   cultivar house size\n1         a   yes   20\n2         a   yes   19\n3         a   yes   25\n4         a   yes   10\n5         a   yes    8\n6         a   yes   15\n7         a   yes   13\n8         a   yes   18\n9         a   yes   11\n10        a   yes   14\n11        a    no   12\n12        a    no   15\n13        a    no   16\n14        a    no    7\n15        a    no    8\n16        a    no   10\n17        a    no   12\n18        a    no   11\n19        a    no   13\n20        a    no   10\n21        b   yes   30\n22        b   yes   19\n23        b   yes   31\n24        b   yes   23\n25        b   yes   18\n26        b   yes   25\n27        b   yes   26\n28        b   yes   24\n29        b   yes   17\n30        b   yes   20\n31        b    no   10\n32        b    no   12\n33        b    no   11\n34        b    no   13\n35        b    no   10\n36        b    no   25\n37        b    no   12\n38        b    no   30\n39        b    no   26\n40        b    no   13\n41        c   yes   15\n42        c   yes   13\n43        c   yes   18\n44        c   yes   11\n45        c   yes   14\n46        c   yes   25\n47        c   yes   39\n48        c   yes   38\n49        c   yes   28\n50        c   yes   24\n51        c    no   10\n52        c    no   12\n53        c    no   11\n54        c    no   13\n55        c    no   10\n56        c    no    9\n57        c    no    2\n58        c    no    4\n59        c    no    7\n60        c    no   13\n\n\n\nboxplot(size~cultivar + house, data = blume3)\n\n\n\nsummary(aov(size~cultivar + house, data = blume3))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  417.1   208.5   5.005     0.01 *  \nhouse        1  992.3   992.3  23.815 9.19e-06 ***\nResiduals   56 2333.2    41.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar + house+cultivar:house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar * house, data = blume3)) #Kurzschreibweise: \"*\" bedeutet, dass Interaktion zwischen cultivar und house eingeschlossen wird\n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar+house, data = blume3))\n\n\n\nCall:\naov(formula = size ~ cultivar + house, data = blume3)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.733 -4.696 -1.050  2.717 19.133 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.283      1.667   5.570 7.52e-07 ***\ncultivarb      6.400      2.041   3.135  0.00273 ** \ncultivarc      2.450      2.041   1.200  0.23509    \nhouseyes       8.133      1.667   4.880 9.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.455 on 56 degrees of freedom\nMultiple R-squared:  0.3766,    Adjusted R-squared:  0.3432 \nF-statistic: 11.28 on 3 and 56 DF,  p-value: 6.848e-06\n\ninteraction.plot(blume3$cultivar, blume3$house, blume3$size)\n\n\n\ninteraction.plot(blume3$house, blume3$cultivar, blume3$size)\n\n\n\nanova(lm(blume3$size~blume3$cultivar*blume3$house), lm(blume3$size~blume3$cultivar+blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$cultivar * blume3$house\nModel 2: blume3$size ~ blume3$cultivar + blume3$house\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     54 2099.6                              \n2     56 2333.2 -2   -233.63 3.0044 0.05792 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(lm(blume3$size~blume3$house), lm(blume3$size~blume3$cultivar * blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$house\nModel 2: blume3$size ~ blume3$cultivar * blume3$house\n  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n1     58 2750.3                                \n2     54 2099.6  4    650.73 4.1841 0.005045 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nKorrelationen\n\n\nlibrary(car)\n\nblume <- data.frame(a, b)\nscatterplot(a~b, blume)\n\n\n\ncor.test(a, b, method = \"pearson\", data = blume)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  a and b\nt = 3.3678, df = 8, p-value = 0.009818\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2628864 0.9414665\nsample estimates:\n      cor \n0.7657634 \n\ncor.test(a, b, method = \"spearman\", data = blume)\n\n\n\n    Spearman's rank correlation rho\n\ndata:  a and b\nS = 53.321, p-value = 0.03159\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6768419 \n\ncor.test(a, b, method = \"kendall\", data = blume) \n\n\n\n    Kendall's rank correlation tau\n\ndata:  a and b\nz = 2.0738, p-value = 0.03809\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5228623 \n\n#Jetzt als Regression\nlm.2 <- lm(b~a)\nanova(lm.2)\n\n\nAnalysis of Variance Table\n\nResponse: b\n          Df Sum Sq Mean Sq F value   Pr(>F)   \na          1 42.455  42.455  11.342 0.009818 **\nResiduals  8 29.945   3.743                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = b ~ a)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1897 -1.3388 -0.6067  1.3081  3.3933 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   5.0193     1.9910   2.521  0.03575 * \na             0.4170     0.1238   3.368  0.00982 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.935 on 8 degrees of freedom\nMultiple R-squared:  0.5864,    Adjusted R-squared:  0.5347 \nF-statistic: 11.34 on 1 and 8 DF,  p-value: 0.009818\n\n#Model II-Regression\nif(!require(lmodel2)){install.packages(\"lmodel2\")} \nlibrary(lmodel2)\nlmodel2(b~a)\n\n\n\nModel II regression\n\nCall: lmodel2(formula = b ~ a)\n\nn = 10   r = 0.7657634   r-square = 0.5863936 \nParametric P-values:   2-tailed = 0.009817588    1-tailed = 0.004908794 \nAngle between the two OLS regression lines = 12.78218 degrees\n\nRegression results\n  Method Intercept     Slope Angle (degrees) P-perm (1-tailed)\n1    OLS  5.019254 0.4170422        22.63820                NA\n2     MA  4.288499 0.4648040        24.92919                NA\n3    SMA  3.067471 0.5446097        28.57314                NA\n\nConfidence intervals\n  Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope\n1    OLS      0.4280737        9.610435  0.1314843   0.7026001\n2     MA     -1.4843783        8.769024  0.1719592   0.8421162\n3    SMA     -2.3775157        6.360555  0.3293755   0.9004912\n\nEigenvalues: 32.37967 2.786995 \n\nH statistic used for computing C.I. of MA: 0.0684968 \n\nBeispiele Modelldiagnostik\n\n\npar(mfrow=c(2, 2)) #4 Plots in einem Fenster\nplot(lm(b~a))\n\n\n\nif(!require(ggfortify)){install.packages(\"ggfortify\")}\nlibrary(ggfortify)\nautoplot(lm(b~a))\n\n\n\n# Modellstatistik nicht OK\ng <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nh <- c(12, 15, 10, 7, 8, 10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\npar(mfrow = c(1, 1))\n\nplot(h~g,xlim = c(0, 40), ylim = c(0, 30))\nabline(lm(h~g))\n\n\n\npar(mfrow = c(2, 2))\nplot(lm(h~g))\n\n\n\n# Modelldiagnostik mit ggplot\ndf <- data.frame(g, h)\nggplot(df, aes(x = g, y = h)) + \n    # scale_x_continuous(limits = c(0,25)) +\n    # scale_y_continuous(limits = c(0,25)) +\n    geom_point() +\n    geom_smooth( method = \"lm\", color = \"black\", size = .5, se = F) + \n    theme_classic()\n\n\n\npar(mfrow=c(2, 2))\nautoplot(lm(h~g))\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_Demo/distill-preview.png",
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_assigment/",
    "title": "Übung Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik3"
    ],
    "contents": "\nDatensatz Ukraine_bearbeitet.xlsx Ukraine_bearbeitet.xlsx Datensatz Ukraine_bearbeitet.csv Ukraine_bearbeitet.csv\nAufgabe 3: Multiple Regression\nBereiten Sie den Datensatz Ukraine.xlsx für das Einlesen in R vor und lesen Sie ihn dann ein. Dieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von 199 10 m² grossen Plots (Vegetationsaufnahmen) von Steppenrasen in der Ukraine sowie zahlreiche Umweltvariablen, deren Bedeutung und Einheiten im Kopf der ExcelTabelle angegeben sind.\nErmitteln Sie ein minimal adäquates Modell, das den Artenreichtum in den Plots durch die Umweltvariablen erklärt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen: welches sind die abhängige(n) und welches die unabängige(n) Variablen, sind alle Variablen für die Analyse geeignet?\nExplorative Datenanalyse, um zu sehen, ob die abhängige Variable in der vorliegenden Form für die Analyse geeignet ist\nDefinition eines globalen Modelles und dessen Reduktion zu einem minimal adäquaten Modell\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\n",
    "preview": {},
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik3_Demo/",
    "title": "Demo Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-10-25",
    "categories": [
      "Statistik3"
    ],
    "contents": "\n\nContents\nANCOVA\n\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\nSimulation Overfitting\nModellvereinfachung (mit Loyn-Datensatz)\nHierarchical partitioning\nPartial regressions\nMultimodel inference\n\n\n\n\nDemoscript als Download\nDatensatz ipomopsis.csv\nDatensatz loyn.csv\nANCOVA\nExperiment zur Fruchtproduktion (“Fruit”) von Ipomopsis sp. (“Fruit”) in Abhängigkeit Ungrazedvon der Beweidung (Grazing mit 2 Levels: Grazed, Ungrazed) und korrigiert für die Pflanzengrösse vor der Beweidung (hier ausgedrückt als Durchmesser an der Spitze des Wurzelstock: “Root”)\n\n\ncompensation <- read.table(\"ipomopsis.csv\", header = T, sep = \",\")\n\n\n\n\n\nsummary(compensation)\n\n\n      Root            Fruit          Grazing         \n Min.   : 4.426   Min.   : 14.73   Length:40         \n 1st Qu.: 6.083   1st Qu.: 41.15   Class :character  \n Median : 7.123   Median : 60.88   Mode  :character  \n Mean   : 7.181   Mean   : 59.41                     \n 3rd Qu.: 8.510   3rd Qu.: 76.19                     \n Max.   :10.253   Max.   :116.05                     \n\ncompensation$Grazing <- as.factor(compensation$Grazing)\n\nplot(Fruit~Root, data = compensation)\n\n\n\nboxplot(Fruit~Grazing, data = compensation)\n\ntapply(compensation$Fruit, compensation$Grazing, mean)\n\n\n  Grazed Ungrazed \n 67.9405  50.8805 \n\naoc.1 <- lm(Fruit~Root * Grazing, data = compensation)\nsummary.aov(aoc.1)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot          1  16795   16795 359.968  < 2e-16 ***\nGrazing       1   5264    5264 112.832 1.21e-12 ***\nRoot:Grazing  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.2 <- lm(Fruit~Grazing * Root, data = compensation)\nsummary.aov(aoc.2)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nGrazing       1   2910    2910  62.380 2.26e-09 ***\nRoot          1  19149   19149 410.420  < 2e-16 ***\nGrazing:Root  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.3 <- lm(Fruit~Grazing + Root, data = compensation)\nsummary.lm(aoc.3)\n\n\n\nCall:\nlm(formula = Fruit ~ Grazing + Root, data = compensation)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1920  -2.8224   0.3223   3.9144  17.3290 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -127.829      9.664  -13.23 1.35e-15 ***\nGrazingUngrazed   36.103      3.357   10.75 6.11e-13 ***\nRoot              23.560      1.149   20.51  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.747 on 37 degrees of freedom\nMultiple R-squared:  0.9291,    Adjusted R-squared:  0.9252 \nF-statistic: 242.3 on 2 and 37 DF,  p-value: < 2.2e-16\n\n# Plotten der Ergebnisse\nlibrary(tidyverse)\n\n\n\nggplot(compensation, aes(Fruit, Root, color = Grazing)) +\n  geom_point()\n\n\n\n# Ploten mit base R\nplot(Fruit~Root, pch = 16, col = Grazing, data = compensation)\nlegend(\"topleft\", c(\"grazed\", \"ungrazed\"), col = c(\"black\",\"red\"), pch = 16) \n\n\n\n\n\n\n\ne <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(12, 15, 10, 7, 2, 10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nlm.1 <- lm(f~e)\nlm.quad <- lm(f~e + I(e^2))\n\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = f ~ e)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.0549 -1.7015  0.5654  2.0617  5.6406 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  12.2879     2.4472   5.021 0.000234 ***\ne            -0.1541     0.1092  -1.412 0.181538    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.863 on 13 degrees of freedom\nMultiple R-squared:  0.1329,    Adjusted R-squared:  0.06622 \nF-statistic: 1.993 on 1 and 13 DF,  p-value: 0.1815\n\nsummary(lm.quad)\n\n\n\nCall:\nlm(formula = f ~ e + I(e^2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3866 -1.1018 -0.2027  1.3831  4.4211 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -2.239308   3.811746  -0.587  0.56777   \ne            1.330933   0.360105   3.696  0.00306 **\nI(e^2)      -0.031587   0.007504  -4.209  0.00121 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.555 on 12 degrees of freedom\nMultiple R-squared:  0.6499,    Adjusted R-squared:  0.5915 \nF-statistic: 11.14 on 2 and 12 DF,  p-value: 0.001842\n\npar(mfrow = c(1, 1))\n\n# 1. lineares Modell\nplot(f~e, xlim = c(0, 40), ylim = c(0, 20))\nabline(lm(f~e), col = \"blue\")\n\n\n\n# 2. quadratisches Modell\nxv <- seq(0,40,0.1)\nplot(f~e, xlim = c(0,40), ylim = c(0,20))\nyv2 <- predict(lm.quad, list(e = xv))\nlines(xv, yv2, col = \"red\")\n\n\n\n# Residualplots\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n#plot(lm.2)\n\n\n\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\n\n\nloyn <- read.table(\"loyn.csv\", header = T, sep = \",\")\n\n\n\n\n\nloyn\n\n\n   ABUND   AREA YR.ISOL DIST LDIST GRAZE ALT\n1    5.3    0.1    1968   39    39     2 160\n2    2.0    0.5    1920  234   234     5  60\n3    1.5    0.5    1900  104   311     5 140\n4   17.1    1.0    1966   66    66     3 160\n5   13.8    1.0    1918  246   246     5 140\n6   14.1    1.0    1965  234   285     3 130\n7    3.8    1.0    1955  467   467     5  90\n8    2.2    1.0    1920  284  1829     5  60\n9    3.3    1.0    1965  156   156     4 130\n10   3.0    1.0    1900  311   571     5 130\n11  27.6    2.0    1926   66   332     3 210\n12   1.8    2.0    1890   93    93     5 160\n13  21.2    2.0    1973   39    39     2 210\n14  14.6    2.0    1972  402   402     1 210\n15   8.0    2.0    1900  259   259     5 120\n16   3.5    2.0    1900  130   623     5 145\n17  29.0    3.0    1962   26    26     3 110\n18   2.9    3.0    1965   26    26     3 140\n19  24.3    4.0    1960   40    40     3 190\n20  19.4    4.0    1953  259   259     2  90\n21  24.4    4.0    1973  234   519     2 220\n22   5.0    4.0    1923   26  2205     5 120\n23  15.8    5.0    1965   39    39     3 130\n24  25.3    5.0    1967  372   372     1 100\n25  19.5    6.0    1890   93   226     3 170\n26  20.9    6.0    1960  159  1009     3 150\n27  16.3    7.0    1965  285   882     3 130\n28  18.8    7.0    1960  133   133     4 210\n29  19.9    8.0    1973  266   266     4 120\n30  13.0    9.0    1910  350  1868     5  90\n31   6.8   10.0    1962  337   519     3 110\n32  21.7   11.0    1960   27    27     4 175\n33  27.8   12.0    1963  159   159     4 110\n34  26.8   12.0    1960  133   133     4 200\n35  16.6   13.0    1968  146   146     2 190\n36  30.4   15.0    1966  146   398     3 120\n37  11.5   17.0    1920  389  2595     5 100\n38  26.0   18.0    1966   40  3188     2 190\n39  25.7   19.0    1973  266  1302     4 150\n40  12.7   22.0    1918  311  2672     5  90\n41  23.5   26.0    1963  597   597     1 140\n42  24.9   29.0    1965  545   770     3 130\n43  29.0   32.0    1974  208   208     1 190\n44  28.3   34.0    1965   66   345     1 110\n45  28.3   40.0    1962  285   178     2 120\n46  32.0   44.0    1960   93    93     3 190\n47  37.7   48.0    1928  259  1297     3 120\n48  39.6   49.0    1972 1427  1557     1 180\n49  29.6   50.0    1967  398  1461     1 140\n50  31.0   57.0    1963  467   467     1 165\n51  34.4   96.0    1976   39   519     2 175\n52  27.3  108.0    1964  402  4426     1  70\n53  30.5  134.0    1964  467  2213     1 160\n54  33.0  144.0    1940  146   319     1 190\n55  29.5  973.0    1970  337  1323     1 190\n56  30.9 1771.0    1933  332   332     1 260\n\n\n\nsummary(loyn)\n\n\n     ABUND            AREA            YR.ISOL          DIST       \n Min.   : 1.50   Min.   :   0.10   Min.   :1890   Min.   :  26.0  \n 1st Qu.:12.40   1st Qu.:   2.00   1st Qu.:1928   1st Qu.:  93.0  \n Median :21.05   Median :   7.50   Median :1962   Median : 234.0  \n Mean   :19.51   Mean   :  69.27   Mean   :1950   Mean   : 240.4  \n 3rd Qu.:28.30   3rd Qu.:  29.75   3rd Qu.:1966   3rd Qu.: 333.2  \n Max.   :39.60   Max.   :1771.00   Max.   :1976   Max.   :1427.0  \n     LDIST            GRAZE            ALT       \n Min.   :  26.0   Min.   :1.000   Min.   : 60.0  \n 1st Qu.: 158.2   1st Qu.:2.000   1st Qu.:120.0  \n Median : 338.5   Median :3.000   Median :140.0  \n Mean   : 733.3   Mean   :2.982   Mean   :146.2  \n 3rd Qu.: 913.8   3rd Qu.:4.000   3rd Qu.:182.5  \n Max.   :4426.0   Max.   :5.000   Max.   :260.0  \n\nlm.1 <- lm (ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \nALT           0.03285    0.02679   1.226 0.225618    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\naov(lm.1)\n\n\nCall:\n   aov(formula = lm.1)\n\nTerms:\n                 YR.ISOL      ALT    GRAZE Residuals\nSum of Squares  1605.835  483.787 1007.904  3240.403\nDeg. of Freedom        1        1        1        52\n\nResidual standard error: 7.894013\nEstimated effects may be unbalanced\n\npar(mfrow = c(2,2))\nplot(lm.1)\n\n\n\ninfluence.measures(lm.1)\n\n\nInfluence measures of\n     lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn) :\n\n      dfb.1_  dfb.YR.I   dfb.ALT  dfb.GRAZ     dffit cov.r   cook.d\n1   0.128900 -0.136701 -2.25e-02  8.68e-02 -0.455383 0.663 4.64e-02\n2  -0.046388  0.041396  1.50e-01 -2.15e-02 -0.222873 1.159 1.26e-02\n3  -0.178685  0.184085 -5.40e-02 -4.08e-02 -0.298379 1.108 2.23e-02\n4   0.054207 -0.053864 -2.43e-02 -4.06e-02 -0.085906 1.099 1.87e-03\n5   0.032249 -0.035235  3.34e-02  6.56e-02  0.138294 1.123 4.85e-03\n6   0.072550 -0.075381  3.68e-02 -3.40e-02 -0.129304 1.072 4.22e-03\n7   0.153153 -0.155477  8.56e-02 -1.78e-01 -0.263831 1.139 1.75e-02\n8  -0.044533  0.039741  1.44e-01 -2.07e-02 -0.213965 1.162 1.16e-02\n9   0.305330 -0.305810  1.16e-02 -2.93e-01 -0.412610 0.935 4.12e-02\n10 -0.134119  0.136978 -1.50e-02 -2.15e-02 -0.217402 1.140 1.19e-02\n11  0.145761 -0.154644  2.14e-01 -2.21e-02  0.300565 1.103 2.26e-02\n12 -0.246939  0.255702 -1.22e-01 -2.33e-02 -0.369735 1.161 3.42e-02\n13  0.071832 -0.068266 -1.34e-01 -3.53e-02 -0.191283 1.110 9.23e-03\n14  0.019281 -0.016626 -3.08e-01  1.90e-01 -0.597735 0.810 8.32e-02\n15  0.000311 -0.000315 -2.26e-05  2.96e-05  0.000496 1.184 6.27e-08\n16 -0.131537  0.136111 -5.26e-02 -3.46e-02 -0.223973 1.146 1.27e-02\n17 -0.098856  0.108184 -1.60e-01  1.44e-02  0.266285 0.984 1.75e-02\n18  0.238014 -0.243468  3.85e-02 -1.36e-01 -0.397451 0.753 3.65e-02\n19 -0.031350  0.029292  5.78e-02  3.66e-02  0.081711 1.121 1.70e-03\n20 -0.024122  0.019709  7.59e-02  5.75e-02 -0.093805 1.170 2.24e-03\n21  0.036050 -0.033748 -7.79e-02 -2.15e-02 -0.102357 1.162 2.66e-03\n22 -0.015768  0.016959  4.26e-03 -6.28e-02 -0.127636 1.116 4.13e-03\n23  0.050368 -0.052333  2.55e-02 -2.36e-02 -0.089769 1.095 2.04e-03\n24 -0.012264  0.008841  5.20e-02  5.07e-02 -0.071851 1.209 1.31e-03\n25  0.145637 -0.146703  2.41e-02 -7.94e-02  0.157322 1.319 6.30e-03\n26 -0.007372  0.007451  1.67e-03  5.11e-03  0.015793 1.106 6.36e-05\n27  0.043873 -0.045585  2.22e-02 -2.05e-02 -0.078194 1.100 1.55e-03\n28 -0.018037  0.016743  2.82e-02  2.63e-02  0.036688 1.224 3.43e-04\n29 -0.131935  0.133012 -2.20e-02  1.11e-01  0.164334 1.152 6.84e-03\n30  0.094249 -0.092478 -8.47e-02  1.81e-02  0.210983 1.127 1.12e-02\n31  0.118899 -0.130120  1.93e-01 -1.73e-02 -0.320276 0.928 2.49e-02\n32 -0.103130  0.098781  9.40e-02  1.33e-01  0.170699 1.126 7.37e-03\n33 -0.284839  0.290760 -1.33e-01  2.50e-01  0.433995 0.919 4.54e-02\n34 -0.213008  0.199453  2.95e-01  3.01e-01  0.408017 1.071 4.12e-02\n35  0.068874 -0.066760 -1.35e-01 -3.57e-03 -0.246916 1.008 1.51e-02\n36 -0.151383  0.159324 -1.23e-01  5.71e-02  0.283014 0.959 1.96e-02\n37  0.022901 -0.022520 -3.21e-02  3.25e-02  0.103312 1.136 2.71e-03\n38 -0.001488  0.001427  3.83e-03 -1.89e-04  0.006929 1.125 1.22e-05\n39 -0.299662  0.296262  7.86e-02  2.86e-01  0.365529 1.060 3.31e-02\n40  0.045779 -0.044212 -7.15e-02  3.70e-02  0.168859 1.126 7.21e-03\n41 -0.043463  0.037744  6.26e-02  1.22e-01 -0.153196 1.126 5.94e-03\n42 -0.067499  0.070133 -3.42e-02  3.16e-02  0.120302 1.078 3.66e-03\n43  0.002552 -0.002850 -1.05e-02  1.52e-02 -0.036428 1.143 3.38e-04\n44  0.011473 -0.009053 -3.51e-02 -3.92e-02  0.052676 1.192 7.07e-04\n45  0.002848  0.003165 -8.61e-02 -6.95e-02  0.137899 1.092 4.81e-03\n46 -0.116776  0.109111  2.15e-01  1.36e-01  0.304366 0.977 2.28e-02\n47  0.445830 -0.431209 -2.69e-01 -3.41e-01  0.629701 0.642 8.76e-02\n48 -0.000133  0.004718  4.46e-02 -1.58e-01  0.302736 1.002 2.26e-02\n49  0.008724 -0.006876 -2.00e-02 -3.60e-02  0.048292 1.150 5.94e-04\n50  0.019369 -0.017688 -5.80e-03 -5.14e-02  0.069197 1.136 1.22e-03\n51 -0.122055  0.122805  7.02e-02  2.13e-02  0.231107 1.022 1.33e-02\n52  0.020580 -0.015671 -8.25e-02 -6.78e-02  0.099679 1.298 2.53e-03\n53  0.014674 -0.013095 -8.87e-03 -4.28e-02  0.057249 1.139 8.35e-04\n54  0.138452 -0.137403  3.82e-02 -1.54e-01  0.204365 1.168 1.06e-02\n55 -0.000650  0.000535 -4.05e-03  6.97e-03 -0.014242 1.144 5.17e-05\n56  0.021139 -0.021938  2.56e-02 -1.62e-02  0.039541 1.363 3.98e-04\n      hat inf\n1  0.0286   *\n2  0.0996    \n3  0.0901    \n4  0.0331    \n5  0.0597    \n6  0.0315    \n7  0.0978    \n8  0.0996    \n9  0.0593    \n10 0.0876    \n11 0.0883    \n12 0.1318    \n13 0.0653    \n14 0.0692    \n15 0.0874    \n16 0.0923    \n17 0.0393    \n18 0.0293   *\n19 0.0460    \n20 0.0829    \n21 0.0786    \n22 0.0531    \n23 0.0315    \n24 0.1091    \n25 0.1876   *\n26 0.0232    \n27 0.0315    \n28 0.1175    \n29 0.0836    \n30 0.0790    \n31 0.0393    \n32 0.0690    \n33 0.0602    \n34 0.1008    \n35 0.0407    \n36 0.0376    \n37 0.0605    \n38 0.0393    \n39 0.0860    \n40 0.0685    \n41 0.0653    \n42 0.0315    \n43 0.0558    \n44 0.0953    \n45 0.0427    \n46 0.0460    \n47 0.0483   *\n48 0.0520    \n49 0.0626    \n50 0.0548    \n51 0.0408    \n52 0.1704   *\n53 0.0549    \n54 0.1011    \n55 0.0555    \n56 0.2077   *\n\ncor <- cor(loyn[, 2:7])\nprint(cor, digits = 2)\n\n\n           AREA YR.ISOL  DIST  LDIST  GRAZE   ALT\nAREA     1.0000 -0.0015  0.11  0.035 -0.310  0.39\nYR.ISOL -0.0015  1.0000  0.11 -0.083 -0.636  0.23\nDIST     0.1083  0.1132  1.00  0.317 -0.256 -0.11\nLDIST    0.0346 -0.0833  0.32  1.000 -0.028 -0.31\nGRAZE   -0.3104 -0.6356 -0.26 -0.028  1.000 -0.41\nALT      0.3878  0.2327 -0.11 -0.306 -0.407  1.00\n\ncor[abs(cor)<0.6] <- 0\ncor\n\n\n        AREA    YR.ISOL DIST LDIST      GRAZE ALT\nAREA       1  0.0000000    0     0  0.0000000   0\nYR.ISOL    0  1.0000000    0     0 -0.6355671   0\nDIST       0  0.0000000    1     0  0.0000000   0\nLDIST      0  0.0000000    0     1  0.0000000   0\nGRAZE      0 -0.6355671    0     0  1.0000000   0\nALT        0  0.0000000    0     0  0.0000000   1\n\nprint(cor, digits = 3)\n\n\n        AREA YR.ISOL DIST LDIST  GRAZE ALT\nAREA       1   0.000    0     0  0.000   0\nYR.ISOL    0   1.000    0     0 -0.636   0\nDIST       0   0.000    1     0  0.000   0\nLDIST      0   0.000    0     1  0.000   0\nGRAZE      0  -0.636    0     0  1.000   0\nALT        0   0.000    0     0  0.000   1\n\nif(!require(car)){install.packages(\"car\")} \nlibrary(car)\n\n\n\nSimulation Overfitting\n\n\ntest <- data.frame(\"x\" = c(1, 2, 3, 4, 5, 6), \"y\" = c(34, 21, 70, 47, 23, 45))\n\npar(mfrow=c(1,1))\nplot(y~x, data = test)\n\nlm.0 <- lm(y~1, data = test)\nlm.1 <- lm(y~x, data = test)\nlm.2 <- lm(y~x+ I(x^2), data = test)\nlm.3 <- lm(y~x+ I(x^2) + I(x^3), data = test)\nlm.4 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4), data = test)\nlm.5 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5), data = test)\nlm.6 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6), data = test)\nsummary(lm.0)\nsummary(lm.1)\nsummary(lm.2)\nsummary(lm.3)\nsummary(lm.4)\nsummary(lm.5)\n\nxv <- seq(from = 0, to = 10, by = 0.1)\n\nplot(y~x,cex = 2, col = \"black\", lwd = 3, data = test)\nyv <- predict(lm.1, list(x=xv))\nlines(xv, yv, col = \"red\", lwd = 3)\nyv <- predict(lm.2, list(x = xv))\nlines(xv, yv, col = \"blue\", lwd = 3)\nyv<-predict(lm.3, list(x = xv))\nlines(xv, yv, col = \"green\", lwd =3)\nyv <- predict(lm.4, list(x=xv))\nlines(xv, yv, col = \"orange\", lwd = 3)\nyv <- predict(lm.5, list(x=xv))\nlines(xv, yv, col = \"black\", lwd = 3)\n\n\n\nModellvereinfachung (mit Loyn-Datensatz)\n\n\nlm.1 <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \nALT           0.03285    0.02679   1.226 0.225618    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\nlm.2 <- update(lm.1,~.-YR.ISOL)\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = ABUND ~ ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.1677  -4.8261   0.0266   4.6944  19.1054 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 28.55582    5.43245   5.257 2.67e-06 ***\nALT          0.03191    0.02675   1.193    0.238    \nGRAZE       -4.59679    0.79167  -5.806 3.67e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.887 on 53 degrees of freedom\nMultiple R-squared:  0.4798,    Adjusted R-squared:  0.4602 \nF-statistic: 24.44 on 2 and 53 DF,  p-value: 3.011e-08\n\nanova(lm.1, lm.2)\n\n\nAnalysis of Variance Table\n\nModel 1: ABUND ~ YR.ISOL + ALT + GRAZE\nModel 2: ABUND ~ ALT + GRAZE\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     52 3240.4                           \n2     53 3297.1 -1   -56.662 0.9093 0.3447\n\nHierarchical partitioning\n\n\nif(!require(hier.part)){install.packages(\"hier.part\")}\nlibrary(hier.part)\n\nloyn.preds <-with(loyn, data.frame(YR.ISOL, ALT, GRAZE))\nhier.part(loyn$ABUND,loyn.preds, gof = \"Rsqu\")\n\n\n\n$gfs\n[1] 0.0000000 0.2533690 0.1488696 0.4658218 0.3297010 0.4739432\n[7] 0.4797883 0.4887284\n\n$IJ\n                 I          J     Total\nYR.ISOL 0.11892853 0.13444049 0.2533690\nALT     0.06960132 0.07926823 0.1488696\nGRAZE   0.30019854 0.16562324 0.4658218\n\n$I.perc\n        ind.exp.var\nYR.ISOL    24.33428\nALT        14.24131\nGRAZE      61.42441\n\n$params\n$params$full.model\n[1] \"y ~ YR.ISOL + ALT + GRAZE\"\n\n$params$family\n[1] \"gaussian\"\n\n$params$link\n[1] \"default\"\n\n$params$gof\n[1] \"Rsqu\"\n\nPartial regressions\n\n\navPlots(lm.1, ask=F)\n\n\n\n\nMultimodel inference\n\n\nif(!require(MuMIn)){install.packages(\"MuMIn\")}\nlibrary(MuMIn)\n\nglobal.model <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\noptions(na.action = \"na.fail\")\n\nallmodels <- dredge(global.model)\nallmodels\n\n\nGlobal model call: lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n---\nModel selection table \n     (Int)     ALT    GRA  YR.ISO df   logLik  AICc delta weight\n3   34.370         -4.981          3 -194.315 395.1  0.00  0.407\n4   28.560 0.03191 -4.597          4 -193.573 395.9  0.84  0.267\n7  -62.750         -4.440 0.04898  4 -193.886 396.6  1.46  0.196\n8  -73.580 0.03285 -4.017 0.05143  5 -193.087 397.4  2.28  0.130\n6 -348.500 0.07006        0.18350  4 -200.670 410.1 15.03  0.000\n5 -392.300                0.21120  3 -203.690 413.8 18.75  0.000\n2    5.598 0.09515                 3 -207.358 421.2 26.09  0.000\n1   19.510                         2 -211.871 428.0 32.88  0.000\nModels ranked by AICc(x) \n\nimportance(allmodels)\n\n\n                     GRAZE ALT  YR.ISOL\nSum of weights:      1.00  0.40 0.33   \nN containing models:    4     4    4   \n\navgmodel <- model.avg(allmodels, subset = TRUE)\nsummary(avgmodel)\n\n\n\nCall:\nmodel.avg(object = allmodels, subset = TRUE)\n\nComponent model call: \nlm(formula = ABUND ~ <8 unique rhs>, data = loyn)\n\nComponent models: \n       df  logLik   AICc delta weight\n2       3 -194.31 395.09  0.00   0.41\n12      4 -193.57 395.93  0.84   0.27\n23      4 -193.89 396.56  1.46   0.20\n123     5 -193.09 397.37  2.28   0.13\n13      4 -200.67 410.13 15.03   0.00\n3       3 -203.69 413.84 18.75   0.00\n1       3 -207.36 421.18 26.09   0.00\n(Null)  2 -211.87 427.97 32.88   0.00\n\nTerm codes: \n    ALT   GRAZE YR.ISOL \n      1       2       3 \n\nModel-averaged coefficients:  \n(full average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64605    0.89257     0.91048   5.103    3e-07 ***\nALT          0.01282    0.02311     0.02340   0.548    0.584    \nYR.ISOL      0.01631    0.03883     0.03941   0.414    0.679    \n \n(conditional average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64724    0.88957     0.90755   5.121    3e-07 ***\nALT          0.03224    0.02678     0.02741   1.176    0.240    \nYR.ISOL      0.05007    0.05421     0.05548   0.902    0.367    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n",
    "preview": "statistik/Statistik3_Demo/distill-preview.png",
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_Demo/",
    "title": "Demo Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nvon LMs zu GLMs\nLogistische Regression\nNicht-lineare Regression\nSmoother\nGAMs\n\n\n\n\nDemoscript als Download\nDatensatz loyn.csv\nvon LMs zu GLMs\n\n\ntemp <- c(10, 12 ,16, 20, 24, 25, 30, 33, 37)\nbesucher <- c(40,12, 50, 500, 400, 900, 1500, 900, 2000)\nstrand <- data.frame(\"Temperatur\" = temp, \"Besucher\" = besucher)\n\nplot(besucher~temp, data = strand)\n\n\n\nlm.strand <- lm(Besucher~Temperatur, data = strand)\nsummary(lm.strand)\n\n\n\nCall:\nlm(formula = Besucher ~ Temperatur, data = strand)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-476.41 -176.89   55.59  218.82  353.11 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 7 degrees of freedom\nMultiple R-squared:  0.8244,    Adjusted R-squared:  0.7993 \nF-statistic: 32.86 on 1 and 7 DF,  p-value: 0.0007115\n\npar(mfrow = c(2, 2))\nplot(lm.strand)\n\n\n\npar(mfrow = c(1 ,1))\nxv <- rep(0:40, by = .1)\nyv <- predict(lm.strand, list(Temperatur = xv), data = strand)\nplot(strand$Temperatur, strand$Besucher, xlim = c(0,40))\nlines(xv, yv, lwd = 3, col=  \"blue\")\n\nglm.gaussian <- glm(Besucher~Temperatur, family = gaussian, data = strand)\nglm.poisson <- glm(Besucher~Temperatur, family = poisson, data = strand)\n\nsummary(glm.gaussian)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = gaussian, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-476.41  -176.89    55.59   218.82   353.11  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 97138.03)\n\n    Null deviance: 3871444  on 8  degrees of freedom\nResidual deviance:  679966  on 7  degrees of freedom\nAIC: 132.63\n\nNumber of Fisher Scoring iterations: 2\n\nsummary(glm.poisson)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = poisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 3.500301   0.056920   61.49   <2e-16 ***\nTemperatur  0.112817   0.001821   61.97   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: 1185.1\n\nNumber of Fisher Scoring iterations: 5\n\n#Rücktranformation der Werte auf die orginale Skale (Hier Exponentialfunktion da family=possion als Link-Funktion den natürlichen Logarithmus (log) verwendet)\n#Besucher = exp(3.50 + 0.11 Temperatur/°C)\nexp(3.500301) #Anzahl besucher bei 0°C\n\n\n[1] 33.12542\n\nexp(3.500301 + 30*0.112817) #Anzahl besucher bei 30°C\n\n\n[1] 977.3169\n\n# Test Overdispersion\nif(!require(AER)){install.packages(\"AER\")}\n\n\n\nlibrary(AER)\ndispersiontest(glm.poisson)\n\n\n\n    Overdispersion test\n\ndata:  glm.poisson\nz = 3.8576, p-value = 5.726e-05\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  116.5467 \n\nglm.quasi <- glm(Besucher~Temperatur, family = quasipoisson, data = strand)\nsummary(glm.quasi)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = quasipoisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  3.50030    0.69639   5.026  0.00152 **\nTemperatur   0.11282    0.02227   5.065  0.00146 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 149.6826)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\npar(mfrow = c(2,2))\nplot(glm.gaussian)\n\n\n\nplot(glm.poisson)\n\n\n\nplot(glm.quasi)\n\n\n\npar(mfrow = c(1, 1))\nplot(strand$Temperatur, strand$Besucher, xlim=c(0, 40))\nxv <- rep(0:40, by = .1)\n\nyv <- predict(lm.strand, list(Temperatur = xv))\nlines(xv, yv, lwd = 3, col = \"blue\")\n\nyv2 <- predict(glm.poisson, list(Temperatur = xv))\nlines(xv, exp(yv2), lwd = 3, col = \"red\")\n\nyv3 <- predict(glm.quasi, list(Temperatur = xv))\nlines(xv, exp(yv3), lwd = 3, col = \"green\")\n\n\n\n\nLogistische Regression\n\n\nbathing <- data.frame(\"temperature\"=c(1, 2, 5, 9, 14, 14, 15, 19, 22, 24, 25, 26, 27, 28, 29), \"bathing\"=c(0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1))\nplot(bathing~temperature, data = bathing)\n\n\n\nglm.1<-glm(bathing~temperature, family = \"binomial\", data = bathing)\nsummary(glm.1)\n\n\n\nCall:\nglm(formula = bathing ~ temperature, family = \"binomial\", data = bathing)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7408  -0.4723  -0.1057   0.5123   1.8615  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)  -5.4652     2.8501  -1.918   0.0552 .\ntemperature   0.2805     0.1350   2.077   0.0378 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 20.728  on 14  degrees of freedom\nResidual deviance: 10.829  on 13  degrees of freedom\nAIC: 14.829\n\nNumber of Fisher Scoring iterations: 6\n\n#Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq (glm.1$deviance,glm.1$df.resid)\n\n\n[1] 0.6251679\n\n#Modellgüte (pseudo-R²)\n1 - (glm.1$dev / glm.1$null)\n\n\n[1] 0.4775749\n\n#Steilheit der Beziehung (relative Änderung der odds bei x + 1 vs. x)\nexp(glm.1$coefficients[2])\n\n\ntemperature \n   1.323807 \n\n#LD50 (also hier: Temperatur, bei der 50% der Touristen baden)\n-glm.1$coefficients[1]/glm.1$coefficients[2]\n\n\n(Intercept) \n   19.48311 \n\n#Vorhersagen\npredicted <- predict(glm.1, type = \"response\")\n\n#Konfusionsmatrix\nkm <- table(bathing$bathing, predicted > 0.5)\nkm\n\n\n   \n    FALSE TRUE\n  0     7    1\n  1     1    6\n\n#Missklassifizierungsrate\n1-sum(diag(km)/sum(km))\n\n\n[1] 0.1333333\n\n#Plotting\nxs <- seq(0,30,l=1000)\nmodel.predict <- predict(glm.1, type = \"response\", se = T, newdata = data.frame(temperature = xs))\nplot(bathing~temperature, data = bathing, xlab = \"Temperature (°C)\", ylab = \"% Bathing\", pch = 16, col = \"red\")\npoints(model.predict$fit ~ xs, type=\"l\")\nlines(model.predict$fit+model.predict$se.fit ~ xs, type = \"l\", lty = 2)\nlines(model.predict$fit-model.predict$se.fit ~ xs, type = \"l\", lty = 2)\n\n\n\n\nNicht-lineare Regression\n\n\nif(!require(AICcmodavg)){install.packages(\"AICcmodavg\")}\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(AICcmodavg)\nlibrary(nlstools)\n\nloyn <- read.delim(\"loyn.csv\", sep = \",\") # Achtung Verzeichnis muss dort gesetzt sein wo Daten sind\n\n#Selbstdefinierte Funktion, hier Potenzfunktion\npower.model <- nls(ABUND~c*AREA^z, start = (list(c = 1, z = 0)), data = loyn)\nsummary(power.model)\n\n\n\nFormula: ABUND ~ c * AREA^z\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \nc 13.39418    1.30721  10.246 2.87e-14 ***\nz  0.16010    0.02438   6.566 2.09e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.995 on 54 degrees of freedom\n\nNumber of iterations to convergence: 12 \nAchieved convergence tolerance: 7.124e-06\n\nAICc(power.model)\n\n\n[1] 396.1723\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(power.model))\n\n\n\n#Vordefinierte \"Selbststartfunktionen\"#\n?selfStart\nlogistic.model <- nls(ABUND~SSlogis(AREA, Asym, xmid, scal), data = loyn)\nsummary(logistic.model)\n\n\n\nFormula: ABUND ~ SSlogis(AREA, Asym, xmid, scal)\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nAsym   31.306      2.207  14.182  < 2e-16 ***\nxmid    6.501      2.278   2.854  0.00614 ** \nscal    9.880      3.152   3.135  0.00280 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.274 on 53 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 4.371e-06\n\nAICc(logistic.model)\n\n\n[1] 386.8643\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(logistic.model))\n\n\n\n#Visualisierung\nplot(ABUND~AREA, data = loyn)\npar(mfrow = c(1, 1))\nxv <- seq(0, 2000, 0.01)\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(xv, yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(xv, yv2, col = \"blue\")\n\n\n\n#Visualisierung II\nplot(ABUND~log10(AREA), data = loyn)\npar(mfrow = c(1, 1))\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(log10(xv), yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(log10(xv), yv2, col = \"blue\")\n\n\n\n#Model seletkion zwischen den nicht-lineraen Modelen\ncand.models<-list()\ncand.models[[1]] <- power.model\ncand.models[[2]] <- logistic.model\n\nModnames <- c(\"Power\", \"Logistic\")\n\naictab(cand.set = cand.models, modnames = Modnames)\n\n\n\nModel selection based on AICc:\n\n         K   AICc Delta_AICc AICcWt Cum.Wt      LL\nLogistic 4 386.86       0.00   0.99   0.99 -189.04\nPower    3 396.17       9.31   0.01   1.00 -194.86\n\nSmoother\n\n\nloyn$log_AREA<-log10(loyn$AREA)       \nplot(ABUND~log_AREA, data = loyn)\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.25), lwd=2, col = \"red\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.5), lwd=2, col = \"blue\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 1), lwd=2, col = \"green\")\n\n\n\n\nGAMs\n\n\nif(!require(mgcv)){install.packages(\"mgcv\")}\nlibrary(mgcv)\n\ngam.1 <- gam(ABUND~s(log_AREA), data = loyn)\ngam.1\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nEstimated degrees of freedom:\n2.88  total = 3.88 \n\nGCV score: 52.145     \n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\nplot(loyn$log_AREA, loyn$ABUND, pch = 16)\nxv <- seq(-1,4, by = 0.1)\nyv <- predict(gam.1, list(log_AREA = xv))\nlines(xv, yv, lwd = 2, col = \"red\")\n\n\n\nAICc(gam.1)\n\n\n[1] 383.2109\n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\n\n\n\n",
    "preview": "statistik/Statistik4_Demo/distill-preview.png",
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_Uebung/",
    "title": "Übungen Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nAufgabe 4.1: Nicht-lineare Regression\nAufgabe 4.2N: Logistische Regression (NatWis)\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\n\nAufgabe 4.1: Nicht-lineare Regression\nDatensatz Curonian_Spit.csv\nDieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von geschachtelten Plots (Vegetationsaufnahmen) der Pflanzengesellschaft LolioCynosuretum im Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis 900 m².\nErmittelt den funktionellen Zusammenhang (das beste Modell), der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt.Berücksichtigt dabei mindestens die Potenzfunktion (power function, die logarithmische Funktion (logarithmic function,und eine Funktion mit Sättigung (saturation, asymptote) eurer Wahl.\nAufgabe 4.2N: Logistische Regression (NatWis)\nDatensatz polis.csv\nDer Datensatz polis.csv beschreibt für 19 Inseln im Golf von Kalifornien, ob Eidechsen der Gattung Uta vorkommen (presence/absence: PA) in Abhängigkeit von der Form der Inseln (Verhältnis Umfang zu Fläche: RATIO).\nBitte prüft mit einer logistischen Regression, ob und ggf. wie die Inselform die Präsenz der Eidechsen beinflusst\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\nFührt mit dem Datensatz der Gästebefragung eine logistische Regression durch. Kann der Mensabesuch druch die sozioökonomischen Variablen (Alter, Geschlecht, Hochschulzugehörigkeit), wahrgenommener Fleischkonsum und Einstellung zu ?? vorhergesagt werden?\nHinweise:\nDas Item tho_2 (“Ich mache mir allgemein Gedanken über die Folgen meiner Ernährungsgewohnheiten für die Umwelt.”) müsst ihr in einem ersten Schritt zu einer Dummy-Variable umcodieren: die Antwortkategorien «stimme eher zu» (=3) und «stimme zu» (=4) müsst ihr eine 1 zuweisen, den anderen zwei Kategorien eine 0. Hinweis dafür könnt ihr die Funktion dpylr::case_when() oder dpylr::if_else() verwenden.\nFehlende Werten könnt ihr weglassen (z.B. dpylr::drop_na())\nDefiniert das Modell und wendet es auf den Datensatz an\nBerechnet eine Vorhersage des Modells mit predict()\nEruiert den Modellfit und die Modellgenauigkeit\nFür Motivierte: Berechnet eine Konfusionsmatrix und zieht euer Fazit daraus\nStellt eure Ergebnisse angemessen dar (Text und/oder Tabelle)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-01T16:00:04+00:00",
    "input_file": {}
  }
]
