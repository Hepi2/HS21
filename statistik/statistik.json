[
  {
    "path": "statistik/Statistik1_01_Demo/",
    "title": "Demo Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-11-02",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\n\n\nDemoskript als Download\nBinomialtest\n\n\n# In Klammern übergibt man die Anzahl der Erfolge und die Stichprobengrösse\nbinom.test(43, 100)\n\n\n\n    Exact binomial test\n\ndata:  43 and 100\nnumber of successes = 43, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.3313910 0.5328663\nsample estimates:\nprobability of success \n                  0.43 \n\nbinom.test(57, 100)\n\n\n\n    Exact binomial test\n\ndata:  57 and 100\nnumber of successes = 57, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4671337 0.6686090\nsample estimates:\nprobability of success \n                  0.57 \n\nChi-Quadrat-Test & Fishers Test\nErmitteln des kritischen Wertes\n\n\nqchisq(0.95, 1)\n\n\n[1] 3.841459\n\nDirekter Test in R (dazu Werte als Matrix nötig)\n\n\ncount <- matrix(c(38, 14, 11, 51), nrow = 2)\ncount\n\n\n     [,1] [,2]\n[1,]   38   11\n[2,]   14   51\n\nchisq.test(count)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  count\nX-squared = 33.112, df = 1, p-value = 8.7e-09\n\nfisher.test(count)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  count\np-value = 2.099e-09\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  4.746351 34.118920\nsample estimates:\nodds ratio \n  12.22697 \n\nt-Test\n\n\na <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\nblume <- data.frame(a,b)\nblume\n\n\n    a  b\n1  20 12\n2  19 15\n3  25 16\n4  10  7\n5   8  8\n6  15 10\n7  13 12\n8  18 11\n9  11 13\n10 14 10\n\nsummary(blume)\n\n\n       a               b        \n Min.   : 8.00   Min.   : 7.00  \n 1st Qu.:11.50   1st Qu.:10.00  \n Median :14.50   Median :11.50  \n Mean   :15.30   Mean   :11.40  \n 3rd Qu.:18.75   3rd Qu.:12.75  \n Max.   :25.00   Max.   :16.00  \n\nboxplot(blume$a, blume$b)\n\n\n\nboxplot(blume)\n\n\n\nhist(blume$a)\n\n\n\nhist(blume$b)\n\n\n\n\nzweiseitiger t-Test\n\n\nt.test(blume$a, blume$b)\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\neinseitiger t-Test\n\n\nt.test(blume$a, blume$b, alternative = \"greater\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.02827\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 0.5954947       Inf\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nt.test(blume$a, blume$b, alternative = \"less\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.9717\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 7.204505\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nklassischer t-Test vs. Welch Test\n\n\n# Varianzen gleich, klassischer t-Test\nt.test(blume$a, blume$b, var.equal = T) \n\n\n\n    Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\n# Varianzen ungleich, Welch's t-Test, ist auch default, d.h. wenn var.equal \n# nicht  definiert wird, wird ein Welch's t-Test ausgeführt. \nt.test(blume$a, blume$b, var.equal = F) \n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\ngepaarter t-Test\n\n\nt.test(blume$a, blume$b, paired = T)\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nt.test(blume$a, blume$b, paired = T, alternative = \"greater\")\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.003458\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 1.846877      Inf\nsample estimates:\nmean of the differences \n                    3.9 \n\nDas gleiche mit einem “long table”\n\n\ncultivar <- c(rep(\"a\", 10), rep(\"b\", 10))\nsize <- c(a, b)\nblume.long <- data.frame(cultivar, size)\n\nrm(size) #Befehl rm entfernt die nicht mehr benötitgten Objekte aus dem Workspace\nrm(cultivar)\n\n\n\nDas gleiche in einer Zeile\n\n\nblume.long <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10)), size = c(a, b))\nsummary(blume.long)             \n\n\n   cultivar              size      \n Length:20          Min.   : 7.00  \n Class :character   1st Qu.:10.00  \n Mode  :character   Median :12.50  \n                    Mean   :13.35  \n                    3rd Qu.:15.25  \n                    Max.   :25.00  \n\nhead(blume.long)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\nboxplot(size~cultivar, data = blume.long)\n\n\n\nt.test(size~cultivar, blume.long, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\n# gepaarter t-Test erster Wert von Cultivar a wird mit erstem Wert von Cultivar\n# b gepaart, zweiter Wert von a mit zweitem von b ect.\nt.test(size~cultivar, blume.long, paired = T)\n\n\n\n    Paired t-test\n\ndata:  size by cultivar\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nBase R vs. ggplot2\n\n\nlibrary(tidyverse)\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot()\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot() + theme_classic()\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot(size = 1) + theme_classic()+\ntheme(axis.line = element_line(size = 1)) + theme(axis.title = element_text(size = 14))+\ntheme(axis.text = element_text(size = 14))\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot(size=1) + theme_classic()+\n  theme(axis.line = element_line(size = 1), axis.ticks = element_line(size = 1), \n       axis.text = element_text(size = 20), axis.title = element_text(size = 20))\n\n\n\n\nDefinieren von mytheme mit allen gewünschten Settings, das man zu Beginn einer Sitzung einmal laden und dann immer wieder ausführen kann (statt des langen Codes)\n\n\nmytheme <- theme_classic() + \n  theme(axis.line = element_line(color = \"black\", size=1), \n        axis.text = element_text(size = 20, color = \"black\"), \n        axis.title = element_text(size = 20, color = \"black\"), \n        axis.ticks = element_line(size = 1, color = \"black\"), \n        axis.ticks.length = unit(.5, \"cm\"))\n\n\n\n\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) +\n  mytheme\n\n\n\nt_test <- t.test(size~cultivar, blume.long)\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  annotate(\"text\", x = \"b\", y = 24, \n  label = paste0(\"italic(p) == \", round(t_test$p.value, 3)), parse = TRUE, size = 8)\n\n\n\nggplot (blume.long, aes(cultivar,size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  labs(x=\"Cultivar\",y=\"Size (cm)\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_01_Demo/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik1_02_Intro_Daten_egel/",
    "title": "Beschreibung Forschungsprojekt NOVANIMAL (NFP69)",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nIm Forschungsprojekt NOVANIMAL wird u.a. der Frage nachgegangen, was es braucht, damit Menschen freiwillig weniger tierische Produkte konsumieren? Ein interessanter Ansatzpunkt ist die Ausser-Haus-Verpflegung. Gemäss der ersten in den Jahren 2014/2015 durchgeführten nationalen Ernährungserhebung menuCH essen 70 % der Bevölkerung zwischen 18 und 75 Jahren am Mittag auswärts (Bochud et al. 2017). Daher rückt die Gastronomie als zentraler Akteur einer innovativen und nachhaltigen Ernährungswirtschaft ins Blickfeld. Welche Innovationen in der Gastronomie könnten dazu beitragen, den Pro-Kopf-Verbrauch an tierischen Nahrungsmitteln zu senken?\nDazu wurde u.a. ein Experiment in zwei Hochschulmensen durchgeführt. Forschungsleitend war die Frage, wie die Gäste dazu bewogen werden können, häufiger vegetarische oder vegane Gerichte zu wählen. Konkret wurde untersucht, wie die Gäste auf ein verändertes Menü-Angebot mit einem höheren Anteil an vegetarischen und veganen Gerichten reagieren. Das Experiment fand während 12 Wochen statt und bestand aus zwei Mensazyklen à 6 Wochen. Über den gesamten Untersuchungszeitraum werden insgesamt 90 verschiedene Gerichte angeboten. In den 6 Referenz- bzw. Basiswochen wurden zwei fleisch- oder fischhaltige Menüs und ein vegetarisches Menü angeboten. In den 6 Interventionswochen wurde das Verhältnis umgekehrt und es wurden ein veganes, ein vegetarisches und ein fleisch- oder fischhaltiges Gericht angeboten. Basis- und Interventionsangebote wechselten wöchentlich ab. Während der gesamten 12 Wochen konnten die Gäste jeweils auf ein Buffet ausweichen und ihre Mahlzeit aus warmen und kalten Komponenten selber zusammenstellen. Die Gerichte wurden über drei vorgegebene Menülinien (F, K, W) randomisiert angeboten.\nDie Abbildung zeigt das Versuchsdesign der ersten 6 Experimentwochen (Kalenderwoche 40 bis 45).Mehr Informationen über das Forschungsprojekt NOVANIMAL findet ihr auf der Webpage\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_03_Assigment/",
    "title": "Übungen Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nAufgabe 1.1: Assoziationstest\nBitte führt einen Assoziationstest zweier kategorialer Variablen (mit je zwei Ausprägungen) mit Chi-Quadrat und Fishers exaktem Test durch. Ihr habt zwei Möglichkeiten: (1) Ihr erhebt dazu selbst die Daten (wozu ihr euch auch in Teams zusammenschliessen könnt). Dabei könnt ihr sowohl Befragungen/Datenerhebung unter Mitstudierenden durchführen (etwa Nutzung Mac/Windows vs. männlich/weiblich) oder Daten zu anderen Objekten erheben. (2) Ihr nehmt zwei kategoriale Variablen aus einem der Novanimal-Datensätze (Feldexperiment oder Gästebefragung).  Bitte formuliert in beiden Fällen vor der Datenerhebung/Datenextraktion eine Hypothese, d.h. eine Erwartungshaltung, ob und welche Assoziation vorliegt und wenn ja warum. Bitte beachtet, dass ihr für die Form des Assoziationstests aus dem Kurs zwei binäre Variablen benötigt; wenn ihr also kategoriale Variablen mit mehr als zwei Ausprägungen habt, könnt ihr entweder Ausprägungen sinnvoll zusammenfassen oder seltene Ausprägungen im Test unberücksichtigt lassen.\nAufgabe 1.2: t-Test\nWerden in den Basis- und Interventionswochen unterschiedlich viele Gerichte verkauft?\nDefiniere die Null- (\\(H_0\\)) und die Alternativhypothese (\\(H_1\\)).\nFühre einen t-Test durch.\nWelche Form von t-Test musst Du anwenden: einseitig/zweiseitig resp. gepaart/ungepaart?\nWie gut sind die Voraussetzungen für einen t-Test erfüllt (z.B. Normalverteilung der Residuen und Varianzhomogenität)?\nStelle deine Ergebnisse angemessen dar, d.h. Text mit Abbildung und/oder Tabelle\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_04_Solution/",
    "title": "Lösung Aufgabe 1",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-08",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 1.1\nkommentierter Weg\nErgebnisse\n\nMusterlösung Übung 1.2: t-Test\nMethoden\nErgebnisse\n\n\n\n\n\nMusterlösung Übung 1.1\n\nDownload R-Skript\n\nkommentierter Weg\n\n\n# Als eine Möglichkeit, die Aufgabe 1.1 zu bearbeiten, nehmen wir hier den \n# Datensatz  der Gästebefragung NOVANIMAL und gehen der folgenden Frage nach: \n# Gibt es einen Zusammenhang zwischen Geschlecht und dem wahrgenommenen \n# Milchkonsum (viel vs. wenig Milch/-produkte)\n\n# die Variable wahrgenommener Milchkonsum muss \n# noch in 2 Kategorien zusammengefasst werden: geringer vs. hoher Milchkonsum\n\n\n# Variable  milk == wahrgenommener Milchkonsum \n# alles kleiner als 4 (3 inklusive) == geringer wahrgenommener Milchkonsum, \n#alles grösser als 3 (4 inklusive) == hoher wahrgenommener Milchkonsum\nnova2 <- nova_survey %>% \n  filter(gender != \"x\") %>% # x aus der Variable Geschlecht entfernen \n  mutate(milkcon = if_else(milk >= 3, \"wenig\", \"viel\")) %>% \n  select(gender, milkcon) %>% \n  drop_na() # alle Missings können gestrichen werden\n \n    \n# mal anschauen\ntable(nova2)\n\n\n      milkcon\ngender viel wenig\n  Frau   23   469\n  Mann   25   623\n\n#achtung chi_squre erwartet matrix\nnova_mtx <- xtabs(~ gender + milkcon ,data = nova2) \n# da es in diesem fall keine kriteriumsvariable gibt, fehlt das y sozusagen\n\n\n\n#Chi-squared Test\nchi_sq <- chisq.test(nova_mtx)\nchi_sq\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nova_mtx\nX-squared = 0.28223, df = 1, p-value = 0.5952\n\n#visualisierung\nOP <- par(mfrow=c(1,2), \"mar\"=c(1,1,3,1))\nmosaicplot(chi_sq$observed, cex.axis =1 , main = \"Observed counts\")\nmosaicplot(chi_sq$expected, cex.axis =1 , main = \"Expected counts\\n(wenn geschlecht keinen einfluss hat)\")\n\n\n\npar(OP)\n\n#Fisher's Test nur mit 2X2 Kontingenztabelle möglich\nfisher.test(nova_mtx)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  nova_mtx\np-value = 0.5523\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.6536644 2.2746745\nsample estimates:\nodds ratio \n  1.221866 \n\nErgebnisse\nDer \\(\\chi^2\\)-Test sagt uns, dass das Geschlecht und der wahrgenommene Milchkonsum nicht zusammenhängen. Es gibt keine signifikante Unterscheide zwischen dem Geschlecht und dem wahrgenommenen Milchkonsum (\\(\\chi^2\\)(1) = 0.282, p = 0.595. Es sieht so aus, dass Männer leicht mehr angeben weniger Milch zu konsumieren (Tabelle 1). Die Ergebnisse müssen jedoch mit Vorsicht interpretiert werden, denn der \\(\\chi^2\\)-Test gibt uns nur an, dass ein signifikanter Unterschied zwischen Geschlecht und wahrgenommener Milchkonsum vorliegt. Um die Unterschiede innerhalb einer Gruppen (z.B. Geschlecht nach Alter) festzustellen bedarf es weiterer Analysen z. B. mit einer mehrfaktorieller ANOVA mit anschliessenden Post-hoc Tests (siehe Statistik 3).\n\nTable 1: Wahrgenommener Milchkonsum nach Geschlecht\nGeschlecht\nwahr. Milchkonsum\nabsolute Werte\nwahr. Milchkonsum (%)\nFrau\nviel\n23\n4.7\nFrau\nwenig\n469\n95.3\nMann\nviel\n25\n3.9\nMann\nwenig\n623\n96.1\n\nMusterlösung Übung 1.2: t-Test\n\nLeseempfehlung Kapitel 2 von Manny Gimond\n\nNull- und Alternativhypothese \\(H_0\\): Es gibt keine Unterschiede in den Verkaufszahlen zwischen Basis- und Interventionswochen.\n\\(H_1\\): Es gibt Unterschiede in den Verkaufszahlen zwischen Basis- und Interventionswochen.\n\n\n# Gemäss Aufgabenstellung müsset die Daten zuerst nach Kalenderwochen \"week\" \n# und Bedingungen \"condition\" zusammengefasst werden\n\ndf <- nova %>%\n    group_by(week, condit) %>%  \n    summarise(tot_sold = n()) \n\n# überprüft die Voraussetzungen für einen t-Test\nggplot2::ggplot(df, aes(x = condit, y= tot_sold)) + # achtung 0 Punkt fehlt\n    geom_boxplot(fill = \"white\", color = \"black\", size = 1) + \n    labs(x=\"\\nBedingungen\", y=\"Durchschnittlich verkaufte Gerichte pro Woche\\n\") + \n    mytheme\n\n\n\n# Auf den ersten Blick scheint es keine starken Abweichungen zu einer \n#Normalverteilung zu geben resp. es sind keine extremen schiefen Verteilungen\n# ersichtlich (vgl. Skript Statistik 2)\n\n\n\n\n\n# führt einen t-Tests durch; \n# es wird angenommen, dass die Verkaufszahlen zwischen den Bedingungen \n# unabhängig sind\n\nt_test <- t.test(tot_sold ~ condit, data=df, var.equl = T)\n\n#alternative Formulierung\nt.test(df[df$condit == \"Basis\", ]$tot_sold, \n                 df[df$condit == \"Intervention\", ]$tot_sold) \n\n\n\n    Welch Two Sample t-test\n\ndata:  df[df$condit == \"Basis\", ]$tot_sold and df[df$condit == \"Intervention\", ]$tot_sold\nt = 0.27168, df = 9.9707, p-value = 0.7914\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -115.2743  147.2743\nsample estimates:\nmean of x mean of y \n     2203      2187 \n\nMethoden\nZiel war es die aggregierten Verkaufszahlen zwischen den Interventions- und Basiswochen zu vergleichen. Die Annahme ist, dass die wöchentlichen Verkaufszahlen unabhängig sind. Daher können die Unterschiede zwischen den Verkaufszahlen pro Woche zwischen den beiden Bedingungen mittels t-Test geprüft werden. Obwohl die visuelle Inspektion keine schwerwiegenden Verletzungen der Modelvoraussetzung zeigte, wurde einen Welch t-Test gerechnet. Zudem muss gesagt werden, dass die Gruppengrösse hier jeweils mit n = 6 (Anzahl Wochen) eher klein ist. T-test liefern dennoch relativ reliable Resultate. Für mehr Infos dazu hier eine Studie.\nErgebnisse\nIn den Basiswochen werden mehr Gerichte pro Woche verkauft als in den Interventionsowochen (siehe Abbildung 1). Die wöchentlichen Verkaufszahlen zwischen den Bedigungen (Basis oder Intervention) unterscheiden sich gemäss Welch t-Test jedoch nicht signifikant (t(10) = 0.272 , p = 0.791). Die Ergebnisse könnten mit einem \\(Chi/{2}\\)-Test nochmals validiert werden, da die Gruppengrösse mit n = 6 doch eher klein ist.\n\n\n\nFigure 1: Die wöchentlichen Verkaufszahlen für die Interventions- und Basiswochen unterscheiden sich nicht signifikant.\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_04_Solution/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_01_Demo/",
    "title": "Demo Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-11-02",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nt-test als ANOVA\nEchte ANOVA\nTukeys Posthoc-Test\nBeispiel Posthoc-Labels in Plot\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n2-faktorielle ANOVA\nKorrelationen\nBeispiele Modelldiagnostik\n\n\n\n\nDemoscript als Download\nt-test als ANOVA\n\n\na <- c(20, 19, 25, 10, 8, 15, 13 ,18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\n\nblume <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\" , 10)), size = c(a, b))\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Bluetengroesse [cm]\", data = blume)\n\n\n\nt.test(size~cultivar, blume, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\naov(size~cultivar, data = blume)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume)\n\nTerms:\n                cultivar Residuals\nSum of Squares     76.05    316.50\nDeg. of Freedom        1        18\n\nResidual standard error: 4.193249\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume))\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ncultivar     1   76.0   76.05   4.325 0.0521 .\nResiduals   18  316.5   17.58                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data = blume))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -2.575 -0.350  2.925  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.326   11.54 9.47e-10 ***\ncultivarb     -3.900      1.875   -2.08   0.0521 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.193 on 18 degrees of freedom\nMultiple R-squared:  0.1937,    Adjusted R-squared:  0.1489 \nF-statistic: 4.325 on 1 and 18 DF,  p-value: 0.05212\n\nEchte ANOVA\n\n\nc <- c(30, 19, 31, 23, 18, 25, 26, 24, 17, 20)\n\nblume2 <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10), rep(\"c\", 10)), size = c(a, b, c))\nblume2$cultivar <- as.factor(blume2$cultivar)\n\nsummary(blume2)             \n\n\n cultivar      size      \n a:10     Min.   : 7.00  \n b:10     1st Qu.:11.25  \n c:10     Median :15.50  \n          Mean   :16.67  \n          3rd Qu.:20.00  \n          Max.   :31.00  \n\nhead(blume2)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Blütengrösse [cm]\", data = blume2)\n\n\n\naov(size~cultivar, data = blume2)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume2)\n\nTerms:\n                cultivar Residuals\nSum of Squares  736.0667  528.6000\nDeg. of Freedom        2        27\n\nResidual standard error: 4.424678\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data=blume2))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\naov.1 <- aov(size~cultivar, data = blume2)\nsummary(aov.1)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov.1)\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\n#Berechnung Mittelwerte usw. zur Charakterisierung der Gruppen\naggregate(size~cultivar, blume2, function(x) c(Mean = mean(x), SD = sd(x), Min = min(x), Max = max(x)))\n\n\n  cultivar size.Mean   size.SD  size.Min  size.Max\n1        a 15.300000  5.207900  8.000000 25.000000\n2        b 11.400000  2.836273  7.000000 16.000000\n3        c 23.300000  4.854551 17.000000 31.000000\n\nlm.1 <- lm(size~cultivar, data = blume2)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\nTukeys Posthoc-Test\n\n\nif(!require(agricolae)){install.packages(\"agricolae\")}\nlibrary(agricolae)\n\nHSD.test(aov.1, \"cultivar\", group = FALSE, console = T)\n\n\n\nStudy: aov.1 ~ \"cultivar\"\n\nHSD Test for size \n\nMean Square Error:  19.57778 \n\ncultivar,  means\n\n  size      std  r Min Max\na 15.3 5.207900 10   8  25\nb 11.4 2.836273 10   7  16\nc 23.3 4.854551 10  17  31\n\nAlpha: 0.05 ; DF Error: 27 \nCritical Value of Studentized Range: 3.506426 \n\nComparison between treatments means\n\n      difference pvalue signif.        LCL       UCL\na - b        3.9 0.1388          -1.006213  8.806213\na - c       -8.0 0.0011      ** -12.906213 -3.093787\nb - c      -11.9 0.0000     *** -16.806213 -6.993787\n\nBeispiel Posthoc-Labels in Plot\n\n\naov.2 <- aov(Sepal.Width ~ Species, data = iris)\nHSD.test(aov.2, \"Species\", console = T)\n\n\n\nStudy: aov.2 ~ \"Species\"\n\nHSD Test for Sepal.Width \n\nMean Square Error:  0.1153878 \n\nSpecies,  means\n\n           Sepal.Width       std  r Min Max\nsetosa           3.428 0.3790644 50 2.3 4.4\nversicolor       2.770 0.3137983 50 2.0 3.4\nvirginica        2.974 0.3224966 50 2.2 3.8\n\nAlpha: 0.05 ; DF Error: 147 \nCritical Value of Studentized Range: 3.348424 \n\nMinimun Significant Difference: 0.1608553 \n\nTreatments with the same letter are not significantly different.\n\n           Sepal.Width groups\nsetosa           3.428      a\nvirginica        2.974      b\nversicolor       2.770      c\n\nboxplot(Sepal.Width ~ Species, data = iris)\n\n\n\nboxplot(Sepal.Width ~ Species, ylim = c(2, 5), data = iris)\ntext(1, 4.8, \"a\")\ntext(2, 4.8, \"c\")\ntext(3, 4.8, \"b\")\n\n\n\nlibrary(tidyverse)\nggplot(iris, aes(Species, Sepal.Width)) + geom_boxplot(size = 1) +\n  annotate(\"text\", y = 5, x = 1:3, label = c(\"a\", \"c\", \"b\"))\n\n\n\n\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\n\n\nshapiro.test(blume2$size[blume2$cultivar == \"a\"])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume2$size[blume2$cultivar == \"a\"]\nW = 0.97304, p-value = 0.9175\n\nvar.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    F test to compare two variances\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")}\nlibrary(car)\nleveneTest(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"], center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\n\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\n\n\nkruskal.test(size~cultivar, data = blume2)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  size by cultivar\nKruskal-Wallis chi-squared = 16.686, df = 2, p-value =\n0.0002381\n\nif(!require(FSA)){install.packages(\"FSA\")} \nlibrary(FSA)\n#korrigierte p-Werte nach Bejamini-Hochberg\ndunnTest(size~cultivar, method = \"bh\", data = blume2) \n\n\n  Comparison         Z      P.unadj        P.adj\n1      a - b  1.526210 1.269575e-01 0.1269575490\n2      a - c -2.518247 1.179407e-02 0.0176911039\n3      b - c -4.044457 5.244459e-05 0.0001573338\n\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n\n\noneway.test(size~cultivar, var.equal = F, data = blume2)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  size and cultivar\nF = 21.642, num df = 2.000, denom df = 16.564, p-value =\n2.397e-05\n\n2-faktorielle ANOVA\n\n\nd <- c(10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\ne <- c(15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nblume3 <- data.frame(cultivar=c(rep(\"a\", 20), rep(\"b\", 20), rep(\"c\", 20)),\n                   house = c(rep(c(rep(\"yes\", 10), rep(\"no\", 10)), 3)),\n                  size = c(a, b, c, d, e, f))\n\n\n\n\n\nblume3\n\n\n\n\n\nboxplot(size~cultivar + house, data = blume3)\n\n\n\nsummary(aov(size~cultivar + house, data = blume3))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  417.1   208.5   5.005     0.01 *  \nhouse        1  992.3   992.3  23.815 9.19e-06 ***\nResiduals   56 2333.2    41.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar + house + cultivar:house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Kurzschreibweise: \"*\" bedeutet, dass Interaktion zwischen cultivar und house eingeschlossen wird\nsummary(aov(size~cultivar * house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar+house, data = blume3))\n\n\n\nCall:\naov(formula = size ~ cultivar + house, data = blume3)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.733 -4.696 -1.050  2.717 19.133 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.283      1.667   5.570 7.52e-07 ***\ncultivarb      6.400      2.041   3.135  0.00273 ** \ncultivarc      2.450      2.041   1.200  0.23509    \nhouseyes       8.133      1.667   4.880 9.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.455 on 56 degrees of freedom\nMultiple R-squared:  0.3766,    Adjusted R-squared:  0.3432 \nF-statistic: 11.28 on 3 and 56 DF,  p-value: 6.848e-06\n\ninteraction.plot(blume3$cultivar, blume3$house, blume3$size)\n\n\n\ninteraction.plot(blume3$house, blume3$cultivar, blume3$size)\n\n\n\nanova(lm(blume3$size~blume3$cultivar*blume3$house), lm(blume3$size~blume3$cultivar+blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$cultivar * blume3$house\nModel 2: blume3$size ~ blume3$cultivar + blume3$house\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     54 2099.6                              \n2     56 2333.2 -2   -233.63 3.0044 0.05792 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(lm(blume3$size~blume3$house), lm(blume3$size~blume3$cultivar * blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$house\nModel 2: blume3$size ~ blume3$cultivar * blume3$house\n  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n1     58 2750.3                                \n2     54 2099.6  4    650.73 4.1841 0.005045 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nKorrelationen\n\n\nlibrary(car)\n\nblume <- data.frame(a, b)\nscatterplot(a~b, blume)\n\n\n\ncor.test(a, b, method = \"pearson\", data = blume)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  a and b\nt = 3.3678, df = 8, p-value = 0.009818\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2628864 0.9414665\nsample estimates:\n      cor \n0.7657634 \n\ncor.test(a, b, method = \"spearman\", data = blume)\n\n\n\n    Spearman's rank correlation rho\n\ndata:  a and b\nS = 53.321, p-value = 0.03159\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6768419 \n\ncor.test(a, b, method = \"kendall\", data = blume) \n\n\n\n    Kendall's rank correlation tau\n\ndata:  a and b\nz = 2.0738, p-value = 0.03809\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5228623 \n\n#Jetzt als Regression\nlm.2 <- lm(b~a)\nanova(lm.2)\n\n\nAnalysis of Variance Table\n\nResponse: b\n          Df Sum Sq Mean Sq F value   Pr(>F)   \na          1 42.455  42.455  11.342 0.009818 **\nResiduals  8 29.945   3.743                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = b ~ a)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1897 -1.3388 -0.6067  1.3081  3.3933 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   5.0193     1.9910   2.521  0.03575 * \na             0.4170     0.1238   3.368  0.00982 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.935 on 8 degrees of freedom\nMultiple R-squared:  0.5864,    Adjusted R-squared:  0.5347 \nF-statistic: 11.34 on 1 and 8 DF,  p-value: 0.009818\n\n#Model II-Regression\nif(!require(lmodel2)){install.packages(\"lmodel2\")} \nlibrary(lmodel2)\nlmodel2(b~a)\n\n\n\nModel II regression\n\nCall: lmodel2(formula = b ~ a)\n\nn = 10   r = 0.7657634   r-square = 0.5863936 \nParametric P-values:   2-tailed = 0.009817588    1-tailed = 0.004908794 \nAngle between the two OLS regression lines = 12.78218 degrees\n\nRegression results\n  Method Intercept     Slope Angle (degrees) P-perm (1-tailed)\n1    OLS  5.019254 0.4170422        22.63820                NA\n2     MA  4.288499 0.4648040        24.92919                NA\n3    SMA  3.067471 0.5446097        28.57314                NA\n\nConfidence intervals\n  Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope\n1    OLS      0.4280737        9.610435  0.1314843   0.7026001\n2     MA     -1.4843783        8.769024  0.1719592   0.8421162\n3    SMA     -2.3775157        6.360555  0.3293755   0.9004912\n\nEigenvalues: 32.37967 2.786995 \n\nH statistic used for computing C.I. of MA: 0.0684968 \n\nBeispiele Modelldiagnostik\n\n\npar(mfrow=c(2, 2)) #4 Plots in einem Fenster\nplot(lm(b~a))\n\n\n\nif(!require(ggfortify)){install.packages(\"ggfortify\")}\nlibrary(ggfortify)\nautoplot(lm(b~a))\n\n\n\n# Modellstatistik nicht OK\ng <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nh <- c(12, 15, 10, 7, 8, 10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\npar(mfrow = c(1, 1))\n\nplot(h~g,xlim = c(0, 40), ylim = c(0, 30))\nabline(lm(h~g))\n\n\n\npar(mfrow = c(2, 2))\nplot(lm(h~g))\n\n\n\n# Modelldiagnostik mit ggplot\ndf <- data.frame(g, h)\nggplot(df, aes(x = g, y = h)) + \n    # scale_x_continuous(limits = c(0,25)) +\n    # scale_y_continuous(limits = c(0,25)) +\n    geom_point() +\n    geom_smooth( method = \"lm\", color = \"black\", size = .5, se = F) + \n    theme_classic()\n\n\n\npar(mfrow=c(2, 2))\nautoplot(lm(h~g))\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_01_Demo/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_02_Assigment/",
    "title": "Übungen Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-11-07",
    "categories": [
      "Statistik2"
    ],
    "contents": "\nAbzugeben sind am Ende\na. lauffähiges R-Skript\nb. begründeter Lösungsweg (Kombination aus R-Code, R Output \n   und dessen Interpretation)\nc. ausformulierter Methoden- und Ergebnisteil (für eine wiss.Arbeit).\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu eurem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in dem ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentiert.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen etc.\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens\nBestimmung des vollständigen/maximalen Models\nSelektion des/der besten Models/Modelle\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen/Tabellen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (je einen ausformulierten Absatz von ca. 60-100 Worten bzw. 3-8 Sätzen). Alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAufgabe 2.1: Regression\nRegressionsanalyse mit SAR.csv\nDer Datensatz beschreibt die Zunahme der Artenzahlen (richness) von Pflanzen in Trockenrasen der Schweiz in Abhängigkeit von der Probeflächengrösse (area, hier in m²). Diese Beziehung bezeichnet man als Artenzahl-Areal-Kurve (Species-area relationship = SAR).\nLadet den Datensatz in R und macht eine explorative Datenanalyse.\nWählt unter den schon gelernten Methoden der Regressionsanalyse ein adäquates Vorgehen zur Analyse dieser Daten und führt diese dann durch.\nPrüft anhand der Residuen, ob die Modellvoraussetzungen erfüllt waren\nFalls die Modelldiagnostik negativ ausfällt, überlegt, welche Datentransformation helfen könnte, und rechnet neue Modelle mit einer oder ggf. mehreren Datentransformationen, bis ihr eine statistisch zufriedenstellende Lösung gefunden habt.\nStellt die erhaltenen Ergebnisse angemessen dar (Text, Abbildung und/oder Tabelle).\nKennt ihr ggf. noch eine andere geeignete Herangehensweise?\nAufgabe 2.2: Einfaktorielle ANOVA\nANOVA mit novanimal_agg.csv\nFührt mit dem Datensatz novanimal.csv eine einfaktorielle ANOVA durch. Gibt es Unterschiede zwischen der Anzahl verkaufter Gerichte (Buffet, Fleisch oder Vegetarisch) pro Woche?\nHinweise für die Analysen:\nFasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace()).\nDanach muss der Datensatz gruppiert und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nFasst die Ergebnisse in wenigen Sätzen zusammen und stellst die angemessen dar (Text mit Abbildung und/oder Tabelle)\nAufgabe 2.3N: Mehrfaktorielle ANOVA (NatWis)\nANOVA mit kormoran.csv\nDer Datensatz enthält 40 Beobachtungen zu Tauchzeiten zweier Kormoranunterarten (C = Phalocrocorax carbo carbo und S = Phalacrocorax carbo sinensis) aus vier Jahreszeiten (F = Frühling, S = Sommer, H = Herbst, W = Winter).\nLest den Datensatz nach R ein und führt eine adäquate Analyse durch, um beantworten zu können, wie Unterart und Jahreszeit die Tauchzeit beeinflussen.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\nGibt es eine Interaktion?\nUebung 2.3S: Mehrfaktorielle ANOVA mit Interaktion (SozWis)\nANOVA mit novanimal_indiv.csv\nIn der Mensa gibt es zwei unterschiedliche Preisniveaus bzgl. den Gerichten: eine preisgünstigere Menülinie (“World” & “Favorite”) und eine teuere Menülinie (“Kitchen”). Gibt es Unterschiede zwischen dem Kauf von preisgünstigeren resp. teureren Menülinien betreffend Menüinhalt & Hochschulzugehörigkeit?\nHinweise für die Analysen:\nFasst die zwei günstigeren Menülinien “Favorite” & “World” zu einer Menülinie zusammen. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace() oder base::sub()).\nKleiner Hinweis: “Local” Gerichte könnt ihr zu den anderen Gerichten dazu zählen z.B. Local Favorite -> Favorite\nDanach muss der Datensatz gruppiert (nach Menülinie & Hochschulzugehörigkeit) und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik2_03_Solution_Stat_Beispiel/",
    "title": "Musterloesung Beispiel",
    "description": {},
    "author": [],
    "date": "2021-11-02",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\n\n\nMusterloesung Beispiel\nDatensatz decy.csv\nRCode als Download\nLoesungstext Beispiel\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLaden Sie den Datensatz decay.csv. Dieser enthält die Zahl radioaktiver Zerfälle pro Zeiteinheit (amount) für Zeitpunkte (time) nach dem Start des Experimentes.\nErmitteln Sie ein statistisches Modell, dass die Zerfallshäufigkeit in Abhängigkeit von der Zeit beschreibt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens (es gibt hier mehrere statistisch korrekte Möglichkeiten!)\nErmittlung eines Modells\nDurchführen der Modelldiagnostik für das gewählte Modell\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\nkommentierter Loesungsweg\n\n\nsummary(decay)\n\n\n      time          amount       \n Min.   : 0.0   Min.   :  8.196  \n 1st Qu.: 7.5   1st Qu.: 21.522  \n Median :15.0   Median : 35.015  \n Mean   :15.0   Mean   : 42.146  \n 3rd Qu.:22.5   3rd Qu.: 57.460  \n Max.   :30.0   Max.   :125.000  \n\nstr(decay)\n\n\n'data.frame':   31 obs. of  2 variables:\n $ time  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ amount: num  125 100.2 70 83.5 100 ...\n\nMan erkennt, dass es 31 Beobachtungen für die Zeit als Integer von Zerfällen gibt, die als rationale Zahlen angegeben werden (dass die Zahl der Zerfälle nicht ganzzahlig ist, deutet darauf hin, dass sie möglicherweise nur in einem Teil des Zeitintervalls oder für einen Teil des betrachteten Raumes gemessen und dann hochgerechnet wurde.\nExplorative Datenanalyse\n\n\nboxplot(decay$time)\n\n\n\nboxplot(decay$amount)\n\n\n\nplot(amount~time, data=decay)\n\n\n\n\nWährend der Boxplot für time wunderbar symmetrisch ohne Ausreisser ist, zeigt amount eine stark rechtsschiefe (linkssteile) Verteilung mit einem Ausreiser. Das deutet schon an, dass ein einfaches lineares Modell vermutlich die Modellannahmen verletzen wird. Auch der einfache Scatterplot zeigt, dass ein lineares Modell wohl nicht adäquat ist. Wir rechnen aber erst einmal weiter.\nEinfaches lineares Modell\n\n\nlm.1 <- lm(amount~time, data = decay)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = amount ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.065 -10.029  -2.058   5.107  40.447 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  84.5534     5.0277   16.82  < 2e-16 ***\ntime         -2.8272     0.2879   -9.82 9.94e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.34 on 29 degrees of freedom\nMultiple R-squared:  0.7688,    Adjusted R-squared:  0.7608 \nF-statistic: 96.44 on 1 and 29 DF,  p-value: 9.939e-11\n\nDas sieht erst einmal nach einem Supermodell aus, höchstsignifikant und mit einem hohen R² von fast 77%. ABER: wir müssen uns noch die Modelldiagnostik ansehen…\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n\nHier zeigen die wichtigen oberen Plots beide massive Abweichungen vom „Soll“. Der Plot oben links zeigt eine „Banane“ und beim Q-Q-Plot oben rechts weichen die Punkte rechts der Mitte alle stark nach oben von der Solllinie ab. Wir haben unser Modell also offensichtlich falsch spezifiziert. Um eine Idee zu bekommen, was falsch ist, plotten wir noch, wie das Ergebnis dieses Modells aussähe:\nErgebnisplot\n\n\npar(mfrow = c(1, 1))\nplot(decay$time, decay$amount)\nabline(lm.1, col = \"red\")\n\n\n\n\nDie Punkte links liegen alle über der Regressionslinie, die in der Mitte darunter und die ganz rechts wieder systematisch darüber (darum im Diagnostikplot oben die „Banane“). Es liegt also offensichtlich keine lineare Beziehung vor, sondern eine curvilineare.\nUm diese korrekt zu analysieren, gibt es im Prinzip drei Möglichkeiten, wovon am zweiten Kurstag nur eine hatten, während die zweite und dritte in Statistik 3 und 4 folgten. Im Folgenden sind alle drei nacheinander dargestellt (in der Klausur würde es aber genügen, eine davon darzustellen, wenn die Aufgabenstellung wie oben lautet).\nVariante (1): Lineares Modell nach Transformation der abhängigen Variablen\nDass die Verteilung der abhängigen Variable nicht normal ist, haben wir ja schon bei der explorativen Datenanalyse am Anfang gesehen. Da sie stark linkssteil ist, zugleich aber keine Nullwerte enthält, bietet sich eine Logarithmustransformation an, hier z. B. mit dem natürlichen Logarithmus.\nLoesung 1: log-Transformation der abhaengigen Variablen\n\n\npar(mfrow = c(1, 2))\nboxplot(decay$amount)\nboxplot(log(decay$amount))\n\n\n\nhist(decay$amount)\nhist(log(decay$amount))\n\n\n\n\nDie log-transformierte Variante rechts sieht sowohl im Boxplot als auch im #Histogramm viel symmetrischer/besser normalverteilt aus. Damit ergibt sich #dann folgendes lineares Modell\n\n\nlm.2 <- lm(log(amount)~time, data = decay)\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = log(amount) ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5935 -0.2043  0.0067  0.2198  0.6297 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.547386   0.100295   45.34  < 2e-16 ***\ntime        -0.068528   0.005743  -11.93 1.04e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.286 on 29 degrees of freedom\nMultiple R-squared:  0.8308,    Adjusted R-squared:  0.825 \nF-statistic: 142.4 on 1 and 29 DF,  p-value: 1.038e-12\n\nJetzt ist der R²-Wert noch höher und der p-Wert noch niedriger als im ursprünglichen linearen Modell ohne Transformation. Das erlaubt aber keine Aussage, da wir Äpfel mit Birnen vergleichen, da die abhängige Variable einmal untransformiert und einmal log-transformiert ist. Entscheidend ist die Modelldiagnostik.\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.2)\n\n\n\n\nDer Q-Q-Plot sieht jetzt exzellent aus, der Plot rechts oben hat kaum noch eine Banane, nur noch einen leichten Keil. Insgesamt deutlich besser und auf jeden Fall ein statistisch korrektes Modell.\nLösungen 2 und 3 greifen auf Methoden von Statistik 3 und 4 zurück, sie sind hier nur zum Vergleich angeführt\nLoesung 2: quadratische Regression (kam erst in Statistik 3; koente fuer die Datenverteilung passen, entspricht aber nicht der physikalischen\nGesetzmaessigkeit\n\n\nmodel.quad <- lm(amount~time + I(time^2), data=  decay)\nsummary(model.quad)\n\n\n\nCall:\nlm(formula = amount ~ time + I(time^2), data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.302  -6.044  -1.603   4.224  20.581 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 106.38880    4.65627  22.849  < 2e-16 ***\ntime         -7.34485    0.71844 -10.223 5.90e-11 ***\nI(time^2)     0.15059    0.02314   6.507 4.73e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.205 on 28 degrees of freedom\nMultiple R-squared:  0.908, Adjusted R-squared:  0.9014 \nF-statistic: 138.1 on 2 and 28 DF,  p-value: 3.122e-15\n\nHier können wir R² mit dem ursprünglichen Modell vergleichen (beide haben amount als abhängige Grösse) und es sieht viel besser aus. Sowohl der lineare als auch der quadratische Term sind hochsignifikant. Sicherheitshalber vergleichen wir die beiden Modelle aber noch mittels ANOVA.\nVergleich mit dem einfachen Modell mittels ANOVA (es ginge auch AICc)\n\n\nanova(lm.1, model.quad)\n\n\nAnalysis of Variance Table\n\nModel 1: amount ~ time\nModel 2: amount ~ time + I(time^2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     29 5960.6                                  \n2     28 2372.6  1    3588.1 42.344 4.727e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nIn der Tat ist das komplexere Modell (jenes mit dem quadratischen Term) höchstsignifikant besser. Jetzt brauchen wir noch die Modelldiagnostik.\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(model.quad)\n\n\n\n\nLoesung 3 (die beste, hatten wir aber am 2. Tag noch nicht; mit Startwerten muss man ggf. ausprobieren)\nmit Startwerten muss man ggf. ausprobieren)\n\n\nmodel.nls <- nls(amount~a*exp(-b*time), start=(list(a = 100, b = 1)),data = decay)\nsummary(model.nls)\n\n\n\nFormula: amount ~ a * exp(-b * time)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na 1.081e+02  4.993e+00   21.66  < 2e-16 ***\nb 8.019e-02  5.833e-03   13.75 3.12e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.243 on 29 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 7.966e-06\n\nModelldiagnostik\n\n\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(nlstools)\nresiduals.nls <- nlsResiduals(model.nls)\nplot(residuals.nls)\n\n\n\n\nFür nls kann man nicht den normalen Plotbefehl für die Residualdiagnostik nehmen, sondern verwendet das Äquivalent aus nlstools. Die beiden entscheidenden Plots sind jetzt links oben und rechts unten. Der QQ-Plot hat im unteren Bereich einen kleinen Schönheitsfehler, aber ansonsten ist alles OK.\nDa alle drei Lösungen zumindest statistisch OK waren, sollen jetzt noch die zugehörigen Ergebnisplots erstellt werden.\nErgebnisplots\n\n\npar(mfrow = c(1, 1))\nxv <- seq(0, 30, 0.1)\n\n\n\nlineares Modell mit log-transformierter Abhaengiger\n\n\nplot(decay$time, decay$amount)\nyv1 <- exp(predict(lm.2, list(time = xv)))\nlines(xv, yv1, col = \"red\")\n\n\n\n\nquadratisches Modell\n\n\nplot(decay$time, decay$amount)\nyv2 <- predict(model.quad, list(time = xv))\nlines(xv, yv2, col=  \"blue\")\n\n\n\n\nnicht-lineares Modell\n\n\nplot(decay$time, decay$amount)\nyv3 <- predict(model.nls, list(time = xv))\nlines(xv, yv3, col = \"green\")\n\n\n\n\nOptisch betrachtet, geben (2) und (3) den empirischen Zusammenhang etwas besser wieder als (1), da sie im linken Bereich die hohen Werte besser treffen. Man könnte sogar meinen, bei Betrachtung der Daten, dass die Werte ab time = 28 wieder leicht ansteigen, was die quadratische Funktion wiedergibt. Wer sich aber mit Physik etwas auskennt, weiss, dass Version (2) physikalisch nicht zutrifft, da die Zerfallsrate mit der Zeit immer weiter abfällt. Aufgrund der kurzen Messreihe wäre eine quadratische Funktion trotzdem eine statistisch korrekte Interpretation. Mit längeren Messreihen würde sich jedoch schnell zeigen, dass sie nicht zutrifft.\n\n\n\n",
    "preview": "statistik/Statistik2_03_Solution_Stat_Beispiel/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_04_solution_2.1/",
    "title": "Musterlösung Übung 2.1 Regression",
    "description": {},
    "author": [],
    "date": "2021-11-05",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nLösungsweg\n\n\n\n\nRCode als Download\nLösungstext als Download\nLösungsweg\n\n\nSAR <- read.delim(\"SAR.csv\", sep = \";\")\n\n\n\n\n\nSAR\n\n\n\nExplorative Datenanalyse\n\n\nsummary(SAR)\n\n\n      area             richness    \n Min.   :  0.0001   Min.   : 1.00  \n 1st Qu.:  0.0010   1st Qu.: 4.00  \n Median :  0.1000   Median : 9.00  \n Mean   :  9.4017   Mean   :16.37  \n 3rd Qu.:  1.0000   3rd Qu.:24.00  \n Max.   :100.0000   Max.   :85.00  \n\nboxplot(SAR$area) # extrem rechtsschief\n\n\n\nboxplot(SAR$richness) # extrem rechtsschief\n\n\n\nplot(richness~area, data = SAR) # sieht nicht linear aus\n\n\n\n\nEinfaches lineares Modell\n\n\nlm.1 <- lm(richness~area, data = SAR)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = richness ~ area, data = SAR)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.567  -8.474  -3.503   6.112  35.317 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  11.4742     0.9582   11.97   <2e-16 ***\narea          0.5209     0.0342   15.23   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.27 on 154 degrees of freedom\nMultiple R-squared:  0.601, Adjusted R-squared:  0.5984 \nF-statistic: 231.9 on 1 and 154 DF,  p-value: < 2.2e-16\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n\nErgebnisplot\n\n\npar(mfrow = c(1, 1))\nplot(SAR$area, SAR$richness, xlab = \"Area [m²]\", ylab = \"Species richness\")\nabline(lm(richness~area, data = SAR), col = \"red\") #Alternative 1\nabline(lm.1, col = \"red\") #Alternative 2\n\n\n\n\nLösung A: log-Transformation der abhängigen Variablen\n\n\npar(mfrow=c(1,2))\nboxplot(SAR$richness)\nboxplot(log10(SAR$richness))\n\n\n\nhist(SAR$richness)\nhist(log10(SAR$richness))\n\n\n\nSAR$log_richness <- log10(SAR$richness)\nlm.2 <- lm(log_richness~area, data = SAR)\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = log_richness ~ area, data = SAR)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.85613 -0.34114 -0.01204  0.36365  0.75729 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.856116   0.036657   23.36  < 2e-16 ***\narea        0.010259   0.001309    7.84 6.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4313 on 154 degrees of freedom\nMultiple R-squared:  0.2853,    Adjusted R-squared:  0.2806 \nF-statistic: 61.47 on 1 and 154 DF,  p-value: 6.939e-13\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.2)\n\n\n\n\n#sieht noch schlechter aus\nLösung B: log-Transformation beider Variablen\n\n\npar(mfrow=c(1,2))\nboxplot(SAR$area)\nboxplot(log10(SAR$area))\n\n\n\nhist(SAR$area)\nhist(log10(SAR$area))\n\n\n\nSAR$log_area <- log10(SAR$area)\nlm.3 <- lm(log_richness~log_area, data = SAR)\nsummary(lm.3)\n\n\n\nCall:\nlm(formula = log_richness ~ log_area, data = SAR)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50241 -0.09353  0.02130  0.09965  0.40068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.265730   0.015607   81.10   <2e-16 ***\nlog_area    0.254440   0.006926   36.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1633 on 154 degrees of freedom\nMultiple R-squared:  0.8976,    Adjusted R-squared:  0.8969 \nF-statistic:  1349 on 1 and 154 DF,  p-value: < 2.2e-16\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.3)\n\n\n\n\ndas sieht jetzt sehr gut aus, bis auf zwei Ausreisser im QQ-Plot\nErgebnisplots C \n\n\npar(mfrow = c(1, 1))\nxv <- seq(0, 100, 0.1)\n\n\n\nErgebnisplots\n\n\npar(mfrow = c(1,1))\nxv <- seq(0,100,0.1)\n\n\n\nA. lineares Modell mit log-transformierter Abhaengiger\n\n\nplot(SAR$area, SAR$richness)\nyv1a <- 10^predict(lm.2, list(area = xv))\nlines(xv, yv1a, col = \"blue\")\n\n\n\n\nB. lineares Modell mit log-Transformation beider Variablen\n\n\nxvlog <- seq(-4,2,0.1)\nplot(SAR$log_area, SAR$log_richness, xlab = \"log10 (Fläche [m²])\", ylab = \"log10 (Artenreichtum)\")\nyv1b <- predict(lm.3, list(log_area = xvlog))\nlines(xvlog, yv1b, col = \"green\")\n\n\n\n\nB. lineares Modell mit log-Transformation beider Variablen (zurücktransformiert)\n\n\nplot(SAR$area, SAR$richness, xlab = \"Fläche [m²]\", ylab = \"Artenreichtum\")\nyv1b <- predict(lm.3, list(log_area = xv))\nlines(10^xv, 10^yv1b, col = \"green\")\n\n\n\n\nModelle im Vergleich\n\n\n#Modelle im Vergleich\nplot(SAR$area, SAR$richness)\nabline(lm.1, col=\"red\")\nlines(xv, yv1a, col=\"blue\")\nlines(10^xv, 10^yv1b, col=\"green\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_04_solution_2.1/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_05_Solution/",
    "title": "Musterlösung Übung 2.2 & 2.3s",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-08",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 2.2\nkommentierter Lösungsweg\nMethoden\nErgebnisse\n\nMusterlösung Übung 2.3S (SozWis)\nkommentierter Lösungsweg\nMethode\nErgebnisse\n\n\n\n\n\n\nDownload R-Skript\n\nMusterlösung Übung 2.2\nkommentierter Lösungsweg\n\n\n\n\n\ndf <- nova # klone den originaler Datensatz\n\n# fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen.\ndf %<>%\n  # Geflügel & Fisch zu fleischgerichte zählen\n  mutate(label_content = str_replace(label_content, \"Geflügel|Fisch\", \"Fleisch\")) %>% \n  # achtung reihenfolge spielt eine rolle, wegen des + (plus)\n  mutate(label_content = str_replace(label_content, \"Pflanzlich[+]|Pflanzlich\", \"Vegetarisch\"))\n\n# gruppiert Daten nach Menü-Inhalt und Woche\ndf %<>%\n    group_by(label_content, week) %>% \n    summarise(tot_sold = n()) %>%\n    drop_na() %>% \n    ungroup() # lasst die unbekannten Menü-Inhalte weg\n\n# überprüft die Voraussetzungen für eine ANOVA\n# Schaut euch die Verteilungen der Mittelwerte an (plus Standardabweichungen)\n# Sind Mittelwerte nahe bei Null? \n# Gäbe uns einen weiteren Hinweis auf eine spezielle Binomail-Verteilung \ndf %>% \n  split(.$label_content) %>% # teilt den Datensatz in 3 verschiedene Datensätze auf\n  purrr::map(~ psych::describe(.$tot_sold)) # mit map können andere Funktionen \n\n\n$Fleisch\n   vars  n    mean     sd median trimmed    mad min  max range skew\nX1    1 12 1135.58 200.03   1088  1129.2 223.13 917 1418   501 0.19\n   kurtosis    se\nX1    -1.89 57.74\n\n$`Hot and Cold`\n   vars  n   mean    sd median trimmed   mad min max range skew\nX1    1 12 308.33 23.53    310   307.3 30.39 276 351    75 0.32\n   kurtosis   se\nX1    -1.25 6.79\n\n$Vegetarisch\n   vars  n   mean     sd median trimmed    mad min  max range  skew\nX1    1 12 739.25 213.54    710   741.8 323.95 449 1004   555 -0.01\n   kurtosis    se\nX1    -1.85 61.64\n\n# auf den Datensatz angewendet werden (alternative Funktionen sind aggregate oder apply)\n\n\n# Boxplot\nggplot(df, aes(x = label_content, y= tot_sold)) +\n  # Achtung: Reihenfolge spielt hier eine Rolle!\n  stat_boxplot(geom = \"errorbar\", width = 0.25) +\n  geom_boxplot(fill=\"white\", color = \"black\", size = 1, width = .5) +\n  labs(x = \"\\nMenü-Inhalt\", y = \"Anzahl verkaufte Gerichte pro Woche\\n\") +\n  # achtung erster Hinweis einer Varianzheterogenität, wegen den Hot&Cold Gerichten\n  mytheme\n\n\n\n#alternative mit base\nboxplot(df$tot_sold~df$label_content)\n\n\n\n# definiert das Modell (vgl. Skript Statistik 2)\nmodel <- aov(tot_sold ~ label_content, data = df)\n\nsummary.lm(model)\n\n\n\nCall:\naov(formula = tot_sold ~ label_content, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-290.250 -135.083    1.667  125.500  282.417 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                1135.58      48.92  23.211  < 2e-16 ***\nlabel_contentHot and Cold  -827.25      69.19 -11.956 1.54e-13 ***\nlabel_contentVegetarisch   -396.33      69.19  -5.728 2.15e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 169.5 on 33 degrees of freedom\nMultiple R-squared:  0.8125,    Adjusted R-squared:  0.8012 \nF-statistic: 71.52 on 2 and 33 DF,  p-value: 1.007e-12\n\n# überprüft die Modelvoraussetzungen\npar(mfrow = c(2,2))\nplot(model)\n\n\n\n\nFazit: Inspektion der Modellvoraussetzung zeigt klare Verletzungen des Residualplots (zeigt einen “Trichter”, siehe Skript Statistik 2), D.h. die Voraussetzung der Homoskedastizität sind verletzt. Mögliche nächste Schritte:\nMenüinhalt “Buffet” aus der Analyse ausschliessen, da sowieso kein richtiger Menüinhalt (aber Informationsverlust)\nDatentransformation z.B. log-Transformation\nnicht-parametrischer Test (Achtung, auch dieser setzt Voraussetzungen voraus)\nein glm Model (general linear model) mit einer poisson/quasipoisson link Funktion (vgl. Skript Statistik 4), weitere Infos dazu Link \n\n\n# überprüft die Voraussetzungen des Welch-Tests:\n# Gibt es eine hohe Varianzheterogenität und ist die relative Verteilung der \n# Residuen gegeben? (siehe Statistik 2)\n# Ja Varianzheterogenität ist gegeben, aber die Verteilung der Residuen folgt \n# einem \"Trichter\", also keiner \"normalen/symmetrischen\" Verteilung um 0\n# Daher ziehe ich eine Transformation der AV einem nicht-parametrischen Test vor\n# für weitere Infos: \n# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n\n# achtung hier log10, bei Rücktransformation achten\nmodel_log <- aov(log10(tot_sold) ~ label_content, data = df) \npar(mfrow = c(2,2))\nplot(model_log) # scheint ok zu sein\n\n\n\nsummary.lm(model_log) # Referenzkategorie ist Fleisch\n\n\n\nCall:\naov(formula = log10(tot_sold) ~ label_content, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.198920 -0.059343  0.003477  0.062579  0.150567 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                3.04908    0.02585 117.942  < 2e-16 ***\nlabel_contentHot and Cold -0.56121    0.03656 -15.350  < 2e-16 ***\nlabel_contentVegetarisch  -0.19792    0.03656  -5.413 5.45e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08956 on 33 degrees of freedom\nMultiple R-squared:  0.8802,    Adjusted R-squared:  0.8729 \nF-statistic: 121.2 on 2 and 33 DF,  p-value: 6.238e-16\n\nTukeyHSD(model_log) # (vgl. Statistik 2)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ label_content, data = df)\n\n$label_content\n                               diff        lwr        upr   p adj\nHot and Cold-Fleisch     -0.5612085 -0.6509215 -0.4714955 0.0e+00\nVegetarisch-Fleisch      -0.1979175 -0.2876305 -0.1082044 1.6e-05\nVegetarisch-Hot and Cold  0.3632910  0.2735780  0.4530041 0.0e+00\n\n# Achtung Beta-Werte resp. Koeffinzienten sind nicht direkt interpretierbar\n# sie müssten zuerst wieder zurück transformiert werden, hier ein Beispiel dafür:\n# für Fleisch\n10^model_log$coefficients[1]\n\n\n(Intercept) \n   1119.655 \n\n# für Hot & Cold,\n10^(model_log$coefficients[1] + model_log$coefficients[2])\n\n\n(Intercept) \n   307.5216 \n\n# ist equivalent zu\n10^(model_log$coefficients[1]) * 10^(model_log$coefficients[2])\n\n\n(Intercept) \n   307.5216 \n\n# für Vegi\n10^(model_log$coefficients[1] + model_log$coefficients[3])\n\n\n(Intercept) \n   709.8501 \n\nMethoden\nZiel war es, die Unterschiede in den wöchentlichen Verkaufszahlen pro Menüinhalt aufzuzeigen. Da die Responsevariable (Verkaufszahlen) “metrisch” und die Prädiktorvariable kategorial sind, wurde eine einfaktorielle ANOVA gerechnet. Die visuelle Inspektion des Modells zeigte insbesondere schwere Verletzungen der Homoskedastizität. Der Boxplot bestätigt dieser Befund. Weil die Voraussetzungen schwer verletzt sind, wurde eine log-Transformation der Responsevariable vorgenommen. Anschliessend wurde erneut eine ANOVA gerechnet und die Modelvoraussetzungen visuell inspiziert: Homoskedastizität und Normalverteilung der Residuen sind gegeben. Für mehr Informatinen zu log-Transformationen und Darstellung der Ergebnisse findet ihr hier\nErgebnisse\nDie Menüinhalte (Fleisch, Vegetarisch und Buffet) unterscheiden sich in den wöchentlichen Verkaufszahlen signifikant (F(2,15) = 121.22, p < .001). Die Abbildung 1 zeigt die wöchentlichen Verkaufszahlen pro Menüinhalt.\n\n\n\n(#fig:plot results 2.3s)Die wöchentlichen Verkaufzahlen unterscheiden sich je nach Menüinhalt stark. Das Modell wurde mit den log-tranformierten Daten gerechnet.\n\n\n\nMusterlösung Übung 2.3S (SozWis)\nLese-Empfehlung Kapitel 7 von Manny Gimond\nkommentierter Lösungsweg\n\n\n\n\n\n# klone den originaler Datensatz\ndf <- nova \n\n# Daten vorbereiten\ndf %<>% # schaut euch das Package \"magrittr\" an\n  # ersetze Local mit einem leeren String\n  mutate(article_description = str_replace(article_description, \"Local \", \"\")) %>% \n  filter(article_description != \"Hot and Cold\") %>% # lasse Buffet Gerichte weg\n  filter(member != \"Spezialkarten\") %>% # Spezialkarten können vernachlässigt werden\n  #  fasse die zwei Menülinien \"World & Favorite\" zusammen\n  mutate(article_description = str_replace_all(article_description, \"Favorite|World\",\n                                               \"Fav_World\"))  \n\n# gruppiere Daten nach Menülinie, Geschlecht und Hochschulzugehörigkeit\ndf %<>%\n    group_by(article_description, member, week) %>% \n    summarise(tot_sold = n()) %>%\n    ungroup() %>% \n    drop_na()  # lasst die unbekannten Menü-Inhalte weg\n\n# überprüft die Voraussetzungen für eine ANOVA\n# Schaut euch die Verteilungen der Mittelwerte der Responsevariable an\n# Sind Mittelwerte nahe bei Null? Gäbe uns einen weiteren Hinweis auf \n# eine spezielle Binomial-Verteilung (vgl. Statistik 4)\ndf %>% \n  split(.$article_description) %>% # teilt den Datensatz in 3 verschiedene Datensätze auf\n  # mit map können andere Funktionen auf den Datensatz angewendet werden \n  # (alternative Funktionen sind aggregate oder apply)\n  purrr::map(~ psych::describe(.$tot_sold)) \n\n\n$Fav_World\n   vars  n   mean     sd median trimmed    mad min max range skew\nX1    1 24 622.67 178.79  599.5   620.8 253.52 378 876   498 0.04\n   kurtosis   se\nX1    -1.88 36.5\n\n$Kitchen\n   vars  n  mean    sd median trimmed   mad min max range skew\nX1    1 24 128.5 22.21  124.5   128.2 23.72  79 187   108 0.27\n   kurtosis   se\nX1     0.43 4.53\n\n# visualisiere dir dein Model, was siehst du? \n# sind möglicherweise gewiesse Voraussetzungen verletzt?\n# Boxplot\nggplot(df, aes(x = interaction(article_description, member), y= tot_sold)) + \n   # Achtung: Reihenfolge spielt hier eine Rolle!\n  stat_boxplot(geom = \"errorbar\", width = 0.25) +\n  geom_boxplot(fill=\"white\", color = \"black\", size = 1, width = .5) +\n  labs(x = \"\\nMenülinie nach Hochschulzugehörigkeit\", y = \"Anzahl verkaufte Gerichte\\n\") + \n  # ändere Gruppennamen händisch\n  scale_x_discrete(limits = c(\"Fav_World.Mitarbeitende\", \"Kitchen.Mitarbeitende\",\n                              \"Fav_World.Studierende\", \"Kitchen.Studierende\"),\n                   breaks = c(\"Fav_World.Mitarbeitende\", \"Fav_World.Studierende\",\n                              \"Kitchen.Mitarbeitende\",  \"Kitchen.Studierende\"),\n                   labels = c(\"Fav_World\\nMitarbeitende\", \"Fav_World\\nStudierende\",\n                              \"Kitchen\\nMitarbeitende\",  \"Kitchen\\nStudierende\")) +\n  mytheme # wie sind die Voraussetzungen erfüllt?\n\n\n\n\n\n\n# definiert das Modell (Skript Statistik 2)\nmodel <- aov(tot_sold ~ article_description * member, data = df)\n\nsummary.lm(model)\n\n\n\nCall:\naov(formula = tot_sold ~ article_description * member, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-91.00 -17.33   0.50  14.83  83.00 \n\nCoefficients:\n                                             Estimate Std. Error\n(Intercept)                                   452.333      9.734\narticle_descriptionKitchen                   -327.000     13.766\nmemberStudierende                             340.667     13.766\narticle_descriptionKitchen:memberStudierende -334.333     19.469\n                                             t value Pr(>|t|)    \n(Intercept)                                    46.47   <2e-16 ***\narticle_descriptionKitchen                    -23.75   <2e-16 ***\nmemberStudierende                              24.75   <2e-16 ***\narticle_descriptionKitchen:memberStudierende  -17.17   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 33.72 on 44 degrees of freedom\nMultiple R-squared:  0.9864,    Adjusted R-squared:  0.9855 \nF-statistic:  1063 on 3 and 44 DF,  p-value: < 2.2e-16\n\n# überprüft die Modelvoraussetzungen (Statistik 2)\npar(mfrow = c(2,2)) # alternativ gäbe es die ggfortify::autoplot(model) funktion\nplot(model)\n\n\n\n\nFazit: Die Inspektion des Modells zeigt kleinere Verletzungen bei der Normalverteilung der Residuen (Q-Q Plot). Aufgrund keiner starken Verbesserung durch eine Transformation der Responsevariable, entscheide ich mich für eine ANOVA ohne log-tranformierten Responsevariablen (AV).\n\n\n# sieht aus, als ob die Voraussetzungen für eine Anova nur geringfügig verletzt sind\n# mögliche alternativen: \n# 0. keine Tranformation der AV (machen wir hier)\n# 1. log-transformation um die grossen werte zu minimieren (nur möglich, wenn \n# keine 0 enthalten sind und die Mittelwerte weit von 0 entfernt sind (bei uns wäre dieser Fall erfüllt)\n# => bei Zähldaten ist dies leider nicht immer gegeben)\n# 2. nicht parametrische Test z.B. Welch-Test, wenn hohe Varianzheterogenität \n# zwischen den Residuen\n\n#0) keine Tranformation\n# post-hov Vergleiche\nTukeyHSD(model)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = tot_sold ~ article_description * member, data = df)\n\n$article_description\n                       diff      lwr       upr p adj\nKitchen-Fav_World -494.1667 -513.785 -474.5484     0\n\n$member\n                           diff      lwr      upr p adj\nStudierende-Mitarbeitende 173.5 153.8817 193.1183     0\n\n$`article_description:member`\n                                                     diff        lwr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -327.000000 -363.75650\nFav_World:Studierende-Fav_World:Mitarbeitende  340.666667  303.91017\nKitchen:Studierende-Fav_World:Mitarbeitende   -320.666667 -357.42317\nFav_World:Studierende-Kitchen:Mitarbeitende    667.666667  630.91017\nKitchen:Studierende-Kitchen:Mitarbeitende        6.333333  -30.42317\nKitchen:Studierende-Fav_World:Studierende     -661.333333 -698.08983\n                                                     upr     p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -290.24350 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende  377.42317 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   -283.91017 0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende    704.42317 0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende       43.08983 0.9672944\nKitchen:Studierende-Fav_World:Studierende     -624.57683 0.0000000\n\n#1) Alterativ: log-transformation\nmodel_log <- aov(log10(tot_sold) ~ article_description * member, data = df)\n\nsummary.lm(model_log) # interaktion ist nun nicht mehr signifikant: vgl. \n\n\n\nCall:\naov(formula = log10(tot_sold) ~ article_description * member, \n    data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.191372 -0.025043  0.003191  0.037604  0.182842 \n\nCoefficients:\n                                             Estimate Std. Error\n(Intercept)                                   2.65417    0.01696\narticle_descriptionKitchen                   -0.56517    0.02398\nmemberStudierende                             0.24438    0.02398\narticle_descriptionKitchen:memberStudierende -0.21726    0.03391\n                                             t value Pr(>|t|)    \n(Intercept)                                  156.533  < 2e-16 ***\narticle_descriptionKitchen                   -23.569  < 2e-16 ***\nmemberStudierende                             10.191 3.71e-13 ***\narticle_descriptionKitchen:memberStudierende  -6.407 8.51e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05874 on 44 degrees of freedom\nMultiple R-squared:  0.9745,    Adjusted R-squared:  0.9728 \nF-statistic: 561.4 on 3 and 44 DF,  p-value: < 2.2e-16\n\n# nochmals euren Boxplot zu beginn, machen diese Koeffizienten sinn?\n\n# überprüft die Modelvoraussetzungen (vgl. Skript Statistik 2)\n# bringt aber keine wesentliche Verbesserung, daher bleibe ich bei den \n# untranfromierten Daten\npar(mfrow = c(2,2))\nplot(model_log)\n\n\n\n# post-hov Vergleiche\nTukeyHSD(model_log) # gibt sehr ähnliche Resultate im Vergleich zum nicht-transformierten Model\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ article_description * member, data = df)\n\n$article_description\n                        diff        lwr        upr p adj\nKitchen-Fav_World -0.6738029 -0.7079755 -0.6396302     0\n\n$member\n                               diff       lwr       upr p adj\nStudierende-Mitarbeitende 0.1357518 0.1015791 0.1699244     0\n\n$`article_description:member`\n                                                     diff         lwr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.56517128 -0.62919652\nFav_World:Studierende-Fav_World:Mitarbeitende  0.24438333  0.18035809\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.53805110 -0.60207634\nFav_World:Studierende-Kitchen:Mitarbeitende    0.80955461  0.74552937\nKitchen:Studierende-Kitchen:Mitarbeitende      0.02712017 -0.03690507\nKitchen:Studierende-Fav_World:Studierende     -0.78243444 -0.84645968\n                                                      upr     p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.50114604 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende  0.30840857 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.47402586 0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende    0.87357985 0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende      0.09114541 0.6726112\nKitchen:Studierende-Fav_World:Studierende     -0.71840920 0.0000000\n\nMethode\nZiel war es die Unterschiede zwischen den preisgünstigeren und teureren Menülinien und der Hochschulzugehörigkeit herauszufinden: Hierfür wurde eine ANOVA mit Interaktion gerechnet, da wir eine (quasi)-metrische Responsevariable und zwei Prädiktorvariablen (Menülinie und Hochschulzugehörigkeit) haben.\nDie Voraussetzungen für eine ANOVA waren im ersten Model nicht stark verletzt, lediglich die Normalverteilung der Residuen: Deshalb habe wurde auf eine log-Transformation der Responsevariable verzichtet. Anschliessend wurden noch post-hoc Einzelvergleiche nach Tukey durchgeführt.\nKleiner Exkurs: Verkaufsdaten sind Zähldaten und perse binomial-Verteilt, da es keine negativen Werte geben kann. Ich versuche immer folgende Fragen zu beantworten:\nWie weit ist der Mittelwert von “Null entfernt”? -> Wenn ja uns keine Voraussetzungen zur Normalverteilung gibt, kann auch eine Normalverteilung angenommen werden\nBeinhalten die Daten viele “Null’s”? -> Wenn ja muss eine spezielle binomial Verteilung angenommen werden, z.B. negative binomiale Transformation mit GLM (see Skript XY)\nErgebnisse\nDie wöchentlichen Verkaufszahlen der Menülinien unterscheiden sich nach Hochschulzugehörigkeit signifikant (F(3,44) = 561.42, p < .001). Inhaltich bedeutet dies, dass Studierende signifikant häufiger die preisgünstigere Menülinie “Favorite & World” als Mitarbeitende kaufen. Entgegen der Annahme gibt es aber keine signifikanten Unterschiede zwischen Studierende und Mitarbeitende bei dem Kauf der teureren Menülinie “Kitchen”. Über die möglichen Gründe können nur spekuliert werden, hierfür bedarf es weiteren Analysen z.B. mit dem Prädiktor “Menüinhalt”.\n\n\n\n(#fig:plot results 2.2)Box-Whisker-Plots der wöchentlichen Verkaufszahlen pro Menü-Inhalte. Kleinbuchstaben bezeichnen homogene Gruppen auf p < .05 nach Tukeys post-hoc-Test.\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_05_Solution/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_06_solution_2.3n/",
    "title": "Musterlösung Übung 2.3n Mehrfaktorielle ANOVA",
    "description": {},
    "author": [],
    "date": "2021-11-05",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\n\n\nRCode als Download\nLoesungstext 2.3\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird) - Laden Sie den Datensatz kormoran.csv mit ein Dieser enthält Tauchzeiten (hier ohne Einheit) von Kormoranen in Abhängigkeit von Jahreszeit und Unterart. Unterarten: Phalacrocorax carbo carbo (C) und Phalacrocorax carbo sinensis (S); Jahreszeiten: F = Frühling, S = Sommer, H = Herbst, W = Winter. - Ihre Gesamtaufgabe ist es, aus diesen Daten ein minimal adäquates Modell zu ermitteln, das diese Abhängigkeit beschreibt. - Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren. - Dieser Ablauf sollte insbesondere beinhalten: - Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen, welches statistische Verfahren wenden Sie an? - Explorative Datenanalyse, um zu sehen, ob schon vor dem Start der Analysen Transformationen o.ä. vorgenommen werden sollten - Definition eines vollen Modelles, das nach statistischen Kritierien zum minimal adäquaten Modell reduziert wird - Durchführen der Modelldiagnostik, um zu entscheiden, ob das gewählte Vorgehen korrekt war oder ggf. angepasst werden muss - Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden - Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden. - Abzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\nkommentierter Lösungsweg\n\n\n# Working directory muss angepasst werden\nkormoran <- read.delim(\"kormoran.csv\", sep = \";\", stringsAsFactors = T)  # \n\n# Ueberpruefen, ob Einlesen richtig funktioniert hat und welche Datenstruktur vorliegt\nstr(kormoran)\n\n\n'data.frame':   40 obs. of  4 variables:\n $ ï..Obs    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Tauchzeit : num  9.5 11.9 13.4 13.8 15.3 15.5 15.6 16.7 16.8 18.7 ...\n $ Unterart  : Factor w/ 2 levels \"C\",\"S\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Jahreszeit: Factor w/ 4 levels \"F\",\"H\",\"S\",\"W\": 1 1 1 1 1 3 3 3 3 3 ...\n\nsummary(kormoran)\n\n\n     ï..Obs        Tauchzeit     Unterart Jahreszeit\n Min.   : 1.00   Min.   : 9.50   C:20     F:10      \n 1st Qu.:10.75   1st Qu.:13.38   S:20     H:10      \n Median :20.50   Median :16.75            S:10      \n Mean   :20.50   Mean   :17.40            W:10      \n 3rd Qu.:30.25   3rd Qu.:20.77                      \n Max.   :40.00   Max.   :30.40                      \n\nMan erkennt, dass es sich um einen Dataframe mit einer metrischen (Tauchzeit) und zwei kategorialen (Unterart, Jahreszeit) Variablen handelt. Die adäquate Analyse (1 metrische Abhängige vs. 2 kategoriale Unabhängige) ist damit eine zweifaktorielle ANOVA Die Sortierung der Jahreszeiten (default: alphabetisch) ist inhaltlich aber nicht sinnvoll und sollte angepasst werden.\n\n\n# Umsortieren der Faktoren, damit sie in den Boxplots eine sinnvolle Reihung haben\nlevels(kormoran$Jahreszeit) <- c(\"F\", \"S\", \"H\", \"W\")\n\n# Explorative Datenanalyse (zeigt uns die Gesamtverteilung)\nboxplot(kormoran$Tauchzeit)\n\n\n\n\nDas ist noch OK für parametrische Verfahren (Box ziemlich symmetrisch um Median, Whisker etwas asymmetrisch aber nicht kritisch). Wegen der leichten Asymmetrie (Linksschiefe) könnte man eine log-Transformation ausprobieren.\n\n\nboxplot(log10(kormoran$Tauchzeit))\n\n\n\n\nDer Gesamtboxplot für log10 sieht perfekt symmetrisch aus, das spräche also für eine log10-Transformation. De facto kommt es aber nicht auf den Gesamtboxplot an, sondern auf die einzelnen.\n\n\n# Explorative Datenanalyse \n# (Check auf Normalverteilung der Residuen und Varianzhomogenitaet)\nboxplot(Tauchzeit~Jahreszeit * Unterart, data = kormoran)\n\n\n\nboxplot(log10(Tauchzeit)~Jahreszeit * Unterart, data = kormoran)\n\n\n\n\nHier sieht mal die Verteilung für die untransformierten Daten, mal für die transformierten besser aus. Da die Transformation keine klare Verbesserung bringt, bleiben wir im Folgenden bei den untransformierten Daten, da diese leichter (direkter) interpretiert werden können\n\n\n# Vollständiges Modell mit Interaktion\naov.1 <- aov(Tauchzeit~Unterart * Jahreszeit, data = kormoran)\naov.1\n\n\nCall:\n   aov(formula = Tauchzeit ~ Unterart * Jahreszeit, data = kormoran)\n\nTerms:\n                Unterart Jahreszeit Unterart:Jahreszeit Residuals\nSum of Squares   106.929    756.170              11.009    84.992\nDeg. of Freedom        1          3                   3        32\n\nResidual standard error: 1.629724\nEstimated effects may be unbalanced\n\nsummary(aov.1)\n\n\n                    Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart             1  106.9  106.93  40.259 4.01e-07 ***\nJahreszeit           3  756.2  252.06  94.901 5.19e-16 ***\nUnterart:Jahreszeit  3   11.0    3.67   1.382    0.266    \nResiduals           32   85.0    2.66                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# p-Wert der Interaktion ist 0.266\n\n\n\nDas volle (maximale) Modell zeigt, dass es keine signifikante Interaktion zwischen Jahreszeit und Unterart gibt. Wir können das Modell also vereinfachen, indem wir die Interaktion herausnehmen (+ statt * in der Modellspezifikation)\n\n\n# Modellvereinfachung\naov.2 <- aov(Tauchzeit~Unterart + Jahreszeit, data = kormoran)\naov.2\n\n\nCall:\n   aov(formula = Tauchzeit ~ Unterart + Jahreszeit, data = kormoran)\n\nTerms:\n                Unterart Jahreszeit Residuals\nSum of Squares   106.929    756.170    96.001\nDeg. of Freedom        1          3        35\n\nResidual standard error: 1.656166\nEstimated effects may be unbalanced\n\nsummary(aov.2)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart     1  106.9  106.93   38.98 3.69e-07 ***\nJahreszeit   3  756.2  252.06   91.89  < 2e-16 ***\nResiduals   35   96.0    2.74                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nIm so vereinfachten Modell sind alle verbleibenden Terme signifikant, wir sind also beim „minimal adäquaten Modell“ angelangt\n\n\n# Anderer Weg, um zu pruefen, ob man das komplexere Modell mit Interaktion behalten soll\nanova(aov.1, aov.2)\n\n\nAnalysis of Variance Table\n\nModel 1: Tauchzeit ~ Unterart * Jahreszeit\nModel 2: Tauchzeit ~ Unterart + Jahreszeit\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     32 84.992                           \n2     35 96.001 -3   -11.009 1.3817 0.2661\n\n# In diesem Fall bekommen wir den gleichen p-Wert wie oben (0.266)\n\n# Modelldiagnostik\npar(mfrow = c(2, 2)) #alle vier Abbildungen in einem 2 x 2 Raster\nplot(aov.2)\n\n\n\n\n\n\ninfluence.measures(aov.2) # \n# kann man sich zusätzlich zum \"plot\" ansehen, um herauszufinden, \n# ob es evtl. sehr einflussreiche Werte mit Cook's D von 1 oder grösser gibt\n\n\n\nLinks oben ist alles bestens, d. h. keine Hinweise auf Varianzheterogenität („Keil“) oder Nichtlinearität („Banane“) Rechts oben ganz gut, allerdings weichen Punkte 1 und 20 deutlich von der optimalen Gerade ab -> aus diesem Grund können wir es doch noch mal mit der log10-Transformation versuchen (s.u.) Rechts unten: kein Punkt hat einen problematischen Einfluss (die roten Linien für Cook’s D > 0.5 und > 1 sind noch nicht einmal im Bildausschnitt.\n\n\n# Alternative mit log10\naov.3 <-aov(log10(Tauchzeit)~Unterart + Jahreszeit, data=kormoran)\naov.3\n\n\nCall:\n   aov(formula = log10(Tauchzeit) ~ Unterart + Jahreszeit, data = kormoran)\n\nTerms:\n                 Unterart Jahreszeit Residuals\nSum of Squares  0.0627004  0.4958434 0.0562031\nDeg. of Freedom         1          3        35\n\nResidual standard error: 0.04007247\nEstimated effects may be unbalanced\n\nsummary(aov.3)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart     1 0.0627 0.06270   39.05 3.64e-07 ***\nJahreszeit   3 0.4958 0.16528  102.93  < 2e-16 ***\nResiduals   35 0.0562 0.00161                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(aov.3)\n\n\n\n\nRechts oben: Punkt 20 jetzt auf der Linie, aber Punkt 1 weicht umso deutlicher ab -> keine Verbesserung -> wir bleiben bei den untransformierten Daten.\n\n\n# Ergebnisdarstellung\n\n\n\nDa wir keine Interaktion zwischen Unterart und Jahreszeit festgestellt haben, brauchen wir auch keinen Interaktionsplot (unnötig kompliziert), statt dessen können wir die Ergebnisse am besten mit zwei getrennten Plots für die beiden Faktoren darstellen. Bitte die Achsenbeschriftungen und den Tukey post-hoc-Test nicht vergessen.\n\n\npar(mfrow = c(1, 1)) #Zurückschalten auf Einzelplots\nif(!require(multcomp)){install.packages(\"multcomp\")} \nlibrary(multcomp)\n\nboxplot(Tauchzeit~Unterart, xlab = \"Unterart\", ylab = \"Tauchzeit\", data = kormoran)\nletters <- cld(glht(aov.2, linfct = mcp(Unterart = \"Tukey\")))\nmtext(letters$mcletters$Letters, at = 1:2)\n\n\n\n# genaugenommen braucht man bei nur zwei Kategorien keinen post hoc-Test\n\nletters <- cld(glht(aov.2, linfct = mcp(Jahreszeit = \"Tukey\")))\n# Achsenbeschriftung nicht vergessen\nboxplot(Tauchzeit~Jahreszeit, xlab = \"Jahreszeit\", ylab = \"Tauchzeit\", data = kormoran)\nmtext(letters$mcletters$Letters, at = 1:4)\n\n\n\n\nJetzt brauchen wir noch die Mittelwerte bzw. Effektgroessen\nFür den Ergebnistext brauchen wir auch noch Angaben zu den Effektgrössen. Hier sind zwei Möglichkeiten, um an sie zu gelangen.\n\n\naggregate(Tauchzeit~Jahreszeit, FUN = mean, data = kormoran)\n\n\n  Jahreszeit Tauchzeit\n1          F     11.86\n2          S     19.23\n3          H     15.09\n4          W     23.42\n\naggregate(Tauchzeit~Unterart, FUN = mean, data = kormoran)\n\n\n  Unterart Tauchzeit\n1        C    19.035\n2        S    15.765\n\nsummary(lm(Tauchzeit~Jahreszeit, data = kormoran))\n\n\n\nCall:\nlm(formula = Tauchzeit ~ Jahreszeit, data = kormoran)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.820 -1.617 -0.145  1.587  6.980 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  11.8600     0.7508  15.797  < 2e-16 ***\nJahreszeitS   7.3700     1.0618   6.941 3.92e-08 ***\nJahreszeitH   3.2300     1.0618   3.042  0.00437 ** \nJahreszeitW  11.5600     1.0618  10.887 6.11e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.374 on 36 degrees of freedom\nMultiple R-squared:  0.7884,    Adjusted R-squared:  0.7708 \nF-statistic: 44.72 on 3 and 36 DF,  p-value: 3.156e-12\n\nsummary(lm(Tauchzeit~Unterart, data = kormoran))\n\n\n\nCall:\nlm(formula = Tauchzeit ~ Unterart, data = kormoran)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.535 -3.585 -0.335  3.760 11.365 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   19.035      1.059  17.976   <2e-16 ***\nUnterartS     -3.270      1.498  -2.184   0.0352 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.736 on 38 degrees of freedom\nMultiple R-squared:  0.1115,    Adjusted R-squared:  0.08811 \nF-statistic: 4.768 on 1 and 38 DF,  p-value: 0.03523\n\n\n\n\n",
    "preview": "statistik/Statistik2_06_solution_2.3n/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_01_Demo/",
    "title": "Demo Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik3"
    ],
    "contents": "\n\nContents\nANCOVA\n\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\nSimulation Overfitting\nModellvereinfachung (mit Loyn-Datensatz)\nHierarchical partitioning\nPartial regressions\nMultimodel inference\n\n\n\n\nDemoscript als Download\nDatensatz ipomopsis.csv\nDatensatz loyn.csv\nANCOVA\nExperiment zur Fruchtproduktion (“Fruit”) von Ipomopsis sp. (“Fruit”) in Abhängigkeit Ungrazedvon der Beweidung (Grazing mit 2 Levels: Grazed, Ungrazed) und korrigiert für die Pflanzengrösse vor der Beweidung (hier ausgedrückt als Durchmesser an der Spitze des Wurzelstock: “Root”)\n\n\ncompensation <- read.delim(\"ipomopsis.csv\", sep = \",\", stringsAsFactors = T)\n\n\n\n\n\nsummary(compensation)\n\n\n      Root            Fruit            Grazing  \n Min.   : 4.426   Min.   : 14.73   Grazed  :20  \n 1st Qu.: 6.083   1st Qu.: 41.15   Ungrazed:20  \n Median : 7.123   Median : 60.88                \n Mean   : 7.181   Mean   : 59.41                \n 3rd Qu.: 8.510   3rd Qu.: 76.19                \n Max.   :10.253   Max.   :116.05                \n\nplot(Fruit~Root, data = compensation)\n\n\n\nboxplot(Fruit~Grazing, data = compensation)\n\ntapply(compensation$Fruit, compensation$Grazing, mean)\n\n\n  Grazed Ungrazed \n 67.9405  50.8805 \n\naoc.1 <- lm(Fruit~Root * Grazing, data = compensation)\nsummary.aov(aoc.1)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot          1  16795   16795 359.968  < 2e-16 ***\nGrazing       1   5264    5264 112.832 1.21e-12 ***\nRoot:Grazing  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.2 <- lm(Fruit~Grazing * Root, data = compensation)\nsummary.aov(aoc.2)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nGrazing       1   2910    2910  62.380 2.26e-09 ***\nRoot          1  19149   19149 410.420  < 2e-16 ***\nGrazing:Root  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.3 <- lm(Fruit~Grazing + Root, data = compensation)\nsummary.lm(aoc.3)\n\n\n\nCall:\nlm(formula = Fruit ~ Grazing + Root, data = compensation)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1920  -2.8224   0.3223   3.9144  17.3290 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -127.829      9.664  -13.23 1.35e-15 ***\nGrazingUngrazed   36.103      3.357   10.75 6.11e-13 ***\nRoot              23.560      1.149   20.51  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.747 on 37 degrees of freedom\nMultiple R-squared:  0.9291,    Adjusted R-squared:  0.9252 \nF-statistic: 242.3 on 2 and 37 DF,  p-value: < 2.2e-16\n\n# Plotten der Ergebnisse\nlibrary(tidyverse)\n\n\n\nggplot(compensation, aes(Root, Fruit, color = Grazing)) +\n  geom_point() + theme_classic()\n\n\n\n# Ploten mit base R\nplot(Fruit~Root, pch = 16, col = Grazing, data = compensation)\nlegend(\"topleft\", c(\"grazed\", \"ungrazed\"), col = c(\"black\",\"red\"), pch = 16) \n\n\n\n\n\n\n\ne <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(12, 15, 10, 7, 2, 10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nlm.1 <- lm(f~e)\nlm.quad <- lm(f~e + I(e^2))\n\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = f ~ e)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.0549 -1.7015  0.5654  2.0617  5.6406 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  12.2879     2.4472   5.021 0.000234 ***\ne            -0.1541     0.1092  -1.412 0.181538    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.863 on 13 degrees of freedom\nMultiple R-squared:  0.1329,    Adjusted R-squared:  0.06622 \nF-statistic: 1.993 on 1 and 13 DF,  p-value: 0.1815\n\nsummary(lm.quad)\n\n\n\nCall:\nlm(formula = f ~ e + I(e^2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3866 -1.1018 -0.2027  1.3831  4.4211 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -2.239308   3.811746  -0.587  0.56777   \ne            1.330933   0.360105   3.696  0.00306 **\nI(e^2)      -0.031587   0.007504  -4.209  0.00121 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.555 on 12 degrees of freedom\nMultiple R-squared:  0.6499,    Adjusted R-squared:  0.5915 \nF-statistic: 11.14 on 2 and 12 DF,  p-value: 0.001842\n\npar(mfrow = c(1, 1))\n\n# 1. lineares Modell\nplot(f~e, xlim = c(0, 40), ylim = c(0, 20))\nabline(lm(f~e), col = \"blue\")\n\n\n\n# 2. quadratisches Modell\nxv <- seq(0, 40, 0.1)\nplot(f~e, xlim = c(0, 40), ylim = c(0, 20))\nyv2 <- predict(lm.quad, list(e = xv))\nlines(xv, yv2, col = \"red\")\n\n\n\n# Residualplots\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\nplot(lm.quad)\n\n\n\n\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\n\n\nloyn <- read.delim(\"loyn.csv\", sep = \",\")\n\n\n\n\n\nsummary(loyn)\n\n\n     ABUND            AREA            YR.ISOL          DIST       \n Min.   : 1.50   Min.   :   0.10   Min.   :1890   Min.   :  26.0  \n 1st Qu.:12.40   1st Qu.:   2.00   1st Qu.:1928   1st Qu.:  93.0  \n Median :21.05   Median :   7.50   Median :1962   Median : 234.0  \n Mean   :19.51   Mean   :  69.27   Mean   :1950   Mean   : 240.4  \n 3rd Qu.:28.30   3rd Qu.:  29.75   3rd Qu.:1966   3rd Qu.: 333.2  \n Max.   :39.60   Max.   :1771.00   Max.   :1976   Max.   :1427.0  \n     LDIST            GRAZE            ALT       \n Min.   :  26.0   Min.   :1.000   Min.   : 60.0  \n 1st Qu.: 158.2   1st Qu.:2.000   1st Qu.:120.0  \n Median : 338.5   Median :3.000   Median :140.0  \n Mean   : 733.3   Mean   :2.982   Mean   :146.2  \n 3rd Qu.: 913.8   3rd Qu.:4.000   3rd Qu.:182.5  \n Max.   :4426.0   Max.   :5.000   Max.   :260.0  \n\nlm.1 <- lm (ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \nALT           0.03285    0.02679   1.226 0.225618    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\naov(lm.1)\n\n\nCall:\n   aov(formula = lm.1)\n\nTerms:\n                 YR.ISOL      ALT    GRAZE Residuals\nSum of Squares  1605.835  483.787 1007.904  3240.403\nDeg. of Freedom        1        1        1        52\n\nResidual standard error: 7.894013\nEstimated effects may be unbalanced\n\npar(mfrow = c(2,2))\nplot(lm.1)\n\n\n\ninfluence.measures(lm.1)\n\n\nInfluence measures of\n     lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn) :\n\n      dfb.1_  dfb.YR.I   dfb.ALT  dfb.GRAZ     dffit cov.r   cook.d\n1   0.128900 -0.136701 -2.25e-02  8.68e-02 -0.455383 0.663 4.64e-02\n2  -0.046388  0.041396  1.50e-01 -2.15e-02 -0.222873 1.159 1.26e-02\n3  -0.178685  0.184085 -5.40e-02 -4.08e-02 -0.298379 1.108 2.23e-02\n4   0.054207 -0.053864 -2.43e-02 -4.06e-02 -0.085906 1.099 1.87e-03\n5   0.032249 -0.035235  3.34e-02  6.56e-02  0.138294 1.123 4.85e-03\n6   0.072550 -0.075381  3.68e-02 -3.40e-02 -0.129304 1.072 4.22e-03\n7   0.153153 -0.155477  8.56e-02 -1.78e-01 -0.263831 1.139 1.75e-02\n8  -0.044533  0.039741  1.44e-01 -2.07e-02 -0.213965 1.162 1.16e-02\n9   0.305330 -0.305810  1.16e-02 -2.93e-01 -0.412610 0.935 4.12e-02\n10 -0.134119  0.136978 -1.50e-02 -2.15e-02 -0.217402 1.140 1.19e-02\n11  0.145761 -0.154644  2.14e-01 -2.21e-02  0.300565 1.103 2.26e-02\n12 -0.246939  0.255702 -1.22e-01 -2.33e-02 -0.369735 1.161 3.42e-02\n13  0.071832 -0.068266 -1.34e-01 -3.53e-02 -0.191283 1.110 9.23e-03\n14  0.019281 -0.016626 -3.08e-01  1.90e-01 -0.597735 0.810 8.32e-02\n15  0.000311 -0.000315 -2.26e-05  2.96e-05  0.000496 1.184 6.27e-08\n16 -0.131537  0.136111 -5.26e-02 -3.46e-02 -0.223973 1.146 1.27e-02\n17 -0.098856  0.108184 -1.60e-01  1.44e-02  0.266285 0.984 1.75e-02\n18  0.238014 -0.243468  3.85e-02 -1.36e-01 -0.397451 0.753 3.65e-02\n19 -0.031350  0.029292  5.78e-02  3.66e-02  0.081711 1.121 1.70e-03\n20 -0.024122  0.019709  7.59e-02  5.75e-02 -0.093805 1.170 2.24e-03\n21  0.036050 -0.033748 -7.79e-02 -2.15e-02 -0.102357 1.162 2.66e-03\n22 -0.015768  0.016959  4.26e-03 -6.28e-02 -0.127636 1.116 4.13e-03\n23  0.050368 -0.052333  2.55e-02 -2.36e-02 -0.089769 1.095 2.04e-03\n24 -0.012264  0.008841  5.20e-02  5.07e-02 -0.071851 1.209 1.31e-03\n25  0.145637 -0.146703  2.41e-02 -7.94e-02  0.157322 1.319 6.30e-03\n26 -0.007372  0.007451  1.67e-03  5.11e-03  0.015793 1.106 6.36e-05\n27  0.043873 -0.045585  2.22e-02 -2.05e-02 -0.078194 1.100 1.55e-03\n28 -0.018037  0.016743  2.82e-02  2.63e-02  0.036688 1.224 3.43e-04\n29 -0.131935  0.133012 -2.20e-02  1.11e-01  0.164334 1.152 6.84e-03\n30  0.094249 -0.092478 -8.47e-02  1.81e-02  0.210983 1.127 1.12e-02\n31  0.118899 -0.130120  1.93e-01 -1.73e-02 -0.320276 0.928 2.49e-02\n32 -0.103130  0.098781  9.40e-02  1.33e-01  0.170699 1.126 7.37e-03\n33 -0.284839  0.290760 -1.33e-01  2.50e-01  0.433995 0.919 4.54e-02\n34 -0.213008  0.199453  2.95e-01  3.01e-01  0.408017 1.071 4.12e-02\n35  0.068874 -0.066760 -1.35e-01 -3.57e-03 -0.246916 1.008 1.51e-02\n36 -0.151383  0.159324 -1.23e-01  5.71e-02  0.283014 0.959 1.96e-02\n37  0.022901 -0.022520 -3.21e-02  3.25e-02  0.103312 1.136 2.71e-03\n38 -0.001488  0.001427  3.83e-03 -1.89e-04  0.006929 1.125 1.22e-05\n39 -0.299662  0.296262  7.86e-02  2.86e-01  0.365529 1.060 3.31e-02\n40  0.045779 -0.044212 -7.15e-02  3.70e-02  0.168859 1.126 7.21e-03\n41 -0.043463  0.037744  6.26e-02  1.22e-01 -0.153196 1.126 5.94e-03\n42 -0.067499  0.070133 -3.42e-02  3.16e-02  0.120302 1.078 3.66e-03\n43  0.002552 -0.002850 -1.05e-02  1.52e-02 -0.036428 1.143 3.38e-04\n44  0.011473 -0.009053 -3.51e-02 -3.92e-02  0.052676 1.192 7.07e-04\n45  0.002848  0.003165 -8.61e-02 -6.95e-02  0.137899 1.092 4.81e-03\n46 -0.116776  0.109111  2.15e-01  1.36e-01  0.304366 0.977 2.28e-02\n47  0.445830 -0.431209 -2.69e-01 -3.41e-01  0.629701 0.642 8.76e-02\n48 -0.000133  0.004718  4.46e-02 -1.58e-01  0.302736 1.002 2.26e-02\n49  0.008724 -0.006876 -2.00e-02 -3.60e-02  0.048292 1.150 5.94e-04\n50  0.019369 -0.017688 -5.80e-03 -5.14e-02  0.069197 1.136 1.22e-03\n51 -0.122055  0.122805  7.02e-02  2.13e-02  0.231107 1.022 1.33e-02\n52  0.020580 -0.015671 -8.25e-02 -6.78e-02  0.099679 1.298 2.53e-03\n53  0.014674 -0.013095 -8.87e-03 -4.28e-02  0.057249 1.139 8.35e-04\n54  0.138452 -0.137403  3.82e-02 -1.54e-01  0.204365 1.168 1.06e-02\n55 -0.000650  0.000535 -4.05e-03  6.97e-03 -0.014242 1.144 5.17e-05\n56  0.021139 -0.021938  2.56e-02 -1.62e-02  0.039541 1.363 3.98e-04\n      hat inf\n1  0.0286   *\n2  0.0996    \n3  0.0901    \n4  0.0331    \n5  0.0597    \n6  0.0315    \n7  0.0978    \n8  0.0996    \n9  0.0593    \n10 0.0876    \n11 0.0883    \n12 0.1318    \n13 0.0653    \n14 0.0692    \n15 0.0874    \n16 0.0923    \n17 0.0393    \n18 0.0293   *\n19 0.0460    \n20 0.0829    \n21 0.0786    \n22 0.0531    \n23 0.0315    \n24 0.1091    \n25 0.1876   *\n26 0.0232    \n27 0.0315    \n28 0.1175    \n29 0.0836    \n30 0.0790    \n31 0.0393    \n32 0.0690    \n33 0.0602    \n34 0.1008    \n35 0.0407    \n36 0.0376    \n37 0.0605    \n38 0.0393    \n39 0.0860    \n40 0.0685    \n41 0.0653    \n42 0.0315    \n43 0.0558    \n44 0.0953    \n45 0.0427    \n46 0.0460    \n47 0.0483   *\n48 0.0520    \n49 0.0626    \n50 0.0548    \n51 0.0408    \n52 0.1704   *\n53 0.0549    \n54 0.1011    \n55 0.0555    \n56 0.2077   *\n\ncor <- cor(loyn[, 2:7])\nprint(cor, digits = 2)\n\n\n           AREA YR.ISOL  DIST  LDIST  GRAZE   ALT\nAREA     1.0000 -0.0015  0.11  0.035 -0.310  0.39\nYR.ISOL -0.0015  1.0000  0.11 -0.083 -0.636  0.23\nDIST     0.1083  0.1132  1.00  0.317 -0.256 -0.11\nLDIST    0.0346 -0.0833  0.32  1.000 -0.028 -0.31\nGRAZE   -0.3104 -0.6356 -0.26 -0.028  1.000 -0.41\nALT      0.3878  0.2327 -0.11 -0.306 -0.407  1.00\n\ncor[abs(cor)<0.6] <- 0\ncor\n\n\n        AREA    YR.ISOL DIST LDIST      GRAZE ALT\nAREA       1  0.0000000    0     0  0.0000000   0\nYR.ISOL    0  1.0000000    0     0 -0.6355671   0\nDIST       0  0.0000000    1     0  0.0000000   0\nLDIST      0  0.0000000    0     1  0.0000000   0\nGRAZE      0 -0.6355671    0     0  1.0000000   0\nALT        0  0.0000000    0     0  0.0000000   1\n\nprint(cor, digits = 3)\n\n\n        AREA YR.ISOL DIST LDIST  GRAZE ALT\nAREA       1   0.000    0     0  0.000   0\nYR.ISOL    0   1.000    0     0 -0.636   0\nDIST       0   0.000    1     0  0.000   0\nLDIST      0   0.000    0     1  0.000   0\nGRAZE      0  -0.636    0     0  1.000   0\nALT        0   0.000    0     0  0.000   1\n\nif(!require(car)){install.packages(\"car\")} \nlibrary(car)\nvif(lm.1)\n\n\n YR.ISOL      ALT    GRAZE \n1.679995 1.200372 1.904799 \n\nSimulation Overfitting\n\n\ntest <- data.frame(\"x\" = c(1, 2, 3, 4, 5, 6), \"y\" = c(34, 21, 70, 47, 23, 45))\n\npar(mfrow=c(1,1))\nplot(y~x, data = test)\n\nlm.0 <- lm(y~1, data = test)\nlm.1 <- lm(y~x, data = test)\nlm.2 <- lm(y~x+ I(x^2), data = test)\nlm.3 <- lm(y~x+ I(x^2) + I(x^3), data = test)\nlm.4 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4), data = test)\nlm.5 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5), data = test)\nlm.6 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6), data = test)\nsummary(lm.0)\nsummary(lm.1)\nsummary(lm.2)\nsummary(lm.3)\nsummary(lm.4)\nsummary(lm.5)\n\nxv <- seq(from = 0, to = 10, by = 0.1)\n\nplot(y~x, cex = 2, col = \"black\", lwd = 3, data = test)\nyv <- predict(lm.1, list(x = xv))\nlines(xv, yv, col = \"red\", lwd = 3)\nyv <- predict(lm.2, list(x = xv))\nlines(xv, yv, col = \"blue\", lwd = 3)\nyv<-predict(lm.3, list(x = xv))\nlines(xv, yv, col = \"green\", lwd =3)\nyv <- predict(lm.4, list(x = xv))\nlines(xv, yv, col = \"orange\", lwd = 3)\nyv <- predict(lm.5, list(x = xv))\nlines(xv, yv, col = \"black\", lwd = 3)\n\n\n\nModellvereinfachung (mit Loyn-Datensatz)\n\n\nlm.1 <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \nALT           0.03285    0.02679   1.226 0.225618    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\nlm.2 <- update(lm.1,~.-YR.ISOL)\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = ABUND ~ ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.1677  -4.8261   0.0266   4.6944  19.1054 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 28.55582    5.43245   5.257 2.67e-06 ***\nALT          0.03191    0.02675   1.193    0.238    \nGRAZE       -4.59679    0.79167  -5.806 3.67e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.887 on 53 degrees of freedom\nMultiple R-squared:  0.4798,    Adjusted R-squared:  0.4602 \nF-statistic: 24.44 on 2 and 53 DF,  p-value: 3.011e-08\n\nanova(lm.1, lm.2)\n\n\nAnalysis of Variance Table\n\nModel 1: ABUND ~ YR.ISOL + ALT + GRAZE\nModel 2: ABUND ~ ALT + GRAZE\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     52 3240.4                           \n2     53 3297.1 -1   -56.662 0.9093 0.3447\n\nHierarchical partitioning\n\n\nif(!require(hier.part)){install.packages(\"hier.part\")}\nlibrary(hier.part)\n\nloyn.preds <-with(loyn, data.frame(YR.ISOL, ALT, GRAZE))\nhier.part(loyn$ABUND, loyn.preds, gof = \"Rsqu\")\n\n\n\n$gfs\n[1] 0.0000000 0.2533690 0.1488696 0.4658218 0.3297010 0.4739432\n[7] 0.4797883 0.4887284\n\n$IJ\n                 I          J     Total\nYR.ISOL 0.11892853 0.13444049 0.2533690\nALT     0.06960132 0.07926823 0.1488696\nGRAZE   0.30019854 0.16562324 0.4658218\n\n$I.perc\n        ind.exp.var\nYR.ISOL    24.33428\nALT        14.24131\nGRAZE      61.42441\n\n$params\n$params$full.model\n[1] \"y ~ YR.ISOL + ALT + GRAZE\"\n\n$params$family\n[1] \"gaussian\"\n\n$params$link\n[1] \"default\"\n\n$params$gof\n[1] \"Rsqu\"\n\nPartial regressions\n\n\navPlots(lm.1, ask=F)\n\n\n\n\nMultimodel inference\n\n\nif(!require(MuMIn)){install.packages(\"MuMIn\")}\nlibrary(MuMIn)\n\nglobal.model <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\noptions(na.action = \"na.fail\")\n\nallmodels <- dredge(global.model)\nallmodels\n\n\nGlobal model call: lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n---\nModel selection table \n     (Int)     ALT    GRA  YR.ISO df   logLik  AICc delta weight\n3   34.370         -4.981          3 -194.315 395.1  0.00  0.407\n4   28.560 0.03191 -4.597          4 -193.573 395.9  0.84  0.267\n7  -62.750         -4.440 0.04898  4 -193.886 396.6  1.46  0.196\n8  -73.580 0.03285 -4.017 0.05143  5 -193.087 397.4  2.28  0.130\n6 -348.500 0.07006        0.18350  4 -200.670 410.1 15.03  0.000\n5 -392.300                0.21120  3 -203.690 413.8 18.75  0.000\n2    5.598 0.09515                 3 -207.358 421.2 26.09  0.000\n1   19.510                         2 -211.871 428.0 32.88  0.000\nModels ranked by AICc(x) \n\nimportance(allmodels)\n\n\n                     GRAZE ALT  YR.ISOL\nSum of weights:      1.00  0.40 0.33   \nN containing models:    4     4    4   \n\navgmodel <- model.avg(allmodels, subset = TRUE)\nsummary(avgmodel)\n\n\n\nCall:\nmodel.avg(object = allmodels, subset = TRUE)\n\nComponent model call: \nlm(formula = ABUND ~ <8 unique rhs>, data = loyn)\n\nComponent models: \n       df  logLik   AICc delta weight\n2       3 -194.31 395.09  0.00   0.41\n12      4 -193.57 395.93  0.84   0.27\n23      4 -193.89 396.56  1.46   0.20\n123     5 -193.09 397.37  2.28   0.13\n13      4 -200.67 410.13 15.03   0.00\n3       3 -203.69 413.84 18.75   0.00\n1       3 -207.36 421.18 26.09   0.00\n(Null)  2 -211.87 427.97 32.88   0.00\n\nTerm codes: \n    ALT   GRAZE YR.ISOL \n      1       2       3 \n\nModel-averaged coefficients:  \n(full average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64605    0.89257     0.91048   5.103    3e-07 ***\nALT          0.01282    0.02311     0.02340   0.548    0.584    \nYR.ISOL      0.01631    0.03883     0.03941   0.414    0.679    \n \n(conditional average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64724    0.88957     0.90755   5.121    3e-07 ***\nALT          0.03224    0.02678     0.02741   1.176    0.240    \nYR.ISOL      0.05007    0.05421     0.05548   0.902    0.367    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n",
    "preview": "statistik/Statistik3_01_Demo/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_02_assigment/",
    "title": "Übung Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik3"
    ],
    "contents": "\nDatensatz Ukraine_bearbeitet.xlsx Ukraine_bearbeitet.xlsx Datensatz Ukraine_bearbeitet.csv Ukraine_bearbeitet.csv\nAufgabe 3: Multiple Regression\nBereiten Sie den Datensatz Ukraine.xlsx für das Einlesen in R vor und lesen Sie ihn dann ein. Dieser enthält Pflanzenartenzahlen (Species.richness) von 199 10 m² grossen Plots (Vegetationsaufnahmen) von Steppenrasen in der Ukraine sowie zahlreiche Umweltvariablen, deren Bedeutung und Einheiten im Kopf der ExcelTabelle angegeben sind.\nErmitteln Sie ein minimal adäquates Modell, das den Artenreichtum in den Plots durch die Umweltvariablen erklärt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen: welches sind die abhängige(n) und welches die unabängige(n) Variablen, sind alle Variablen für die Analyse geeignet?\nExplorative Datenanalyse, um zu sehen, ob die abhängige Variable in der vorliegenden Form für die Analyse geeignet ist\nDefinition eines globalen Modelles und dessen Reduktion zu einem minimal adäquaten Modell\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\n",
    "preview": {},
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik4_01_Demo/",
    "title": "Demo Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nvon LMs zu GLMs\nLogistische Regression\nNicht-lineare Regression\nSmoother\nGAMs\n\nDemoscript als Download\nDatensatz loyn.csv\nvon LMs zu GLMs\n\n\ntemp <- c(10, 12 ,16, 20, 24, 25, 30, 33, 37)\nbesucher <- c(40, 12, 50, 500, 400, 900, 1500, 900, 2000)\nstrand <- data.frame(\"Temperatur\" = temp, \"Besucher\" = besucher)\n\nplot(besucher~temp, data = strand)\n\n\n\nlm.strand <- lm(Besucher~Temperatur, data = strand)\nsummary(lm.strand)\n\n\n\nCall:\nlm(formula = Besucher ~ Temperatur, data = strand)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-476.41 -176.89   55.59  218.82  353.11 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 7 degrees of freedom\nMultiple R-squared:  0.8244,    Adjusted R-squared:  0.7993 \nF-statistic: 32.86 on 1 and 7 DF,  p-value: 0.0007115\n\npar(mfrow = c(2, 2))\nplot(lm.strand)\n\n\n\npar(mfrow = c(1 ,1))\nxv <- rep(0:40, by = .1)\nyv <- predict(lm.strand, list(Temperatur = xv), data = strand)\nplot(strand$Temperatur, strand$Besucher, xlim = c(0, 40))\nlines(xv, yv, lwd = 3, col=  \"blue\")\n\n\n\nglm.gaussian <- glm(Besucher~Temperatur, family = gaussian, data = strand)\nglm.poisson <- glm(Besucher~Temperatur, family = poisson, data = strand)\n\nsummary(glm.gaussian)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = gaussian, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-476.41  -176.89    55.59   218.82   353.11  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 97138.03)\n\n    Null deviance: 3871444  on 8  degrees of freedom\nResidual deviance:  679966  on 7  degrees of freedom\nAIC: 132.63\n\nNumber of Fisher Scoring iterations: 2\n\nsummary(glm.poisson)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = poisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 3.500301   0.056920   61.49   <2e-16 ***\nTemperatur  0.112817   0.001821   61.97   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: 1185.1\n\nNumber of Fisher Scoring iterations: 5\n\nRücktranformation der Werte auf die orginale Skale (Hier Exponentialfunktion da family=possion als Link-Funktion den natürlichen Logarithmus (log) verwendet) Besucher = exp(3.50 + 0.11 Temperatur/°C)\n\n\nexp(3.500301) #Anzahl besucher bei 0°C\n\n\n[1] 33.12542\n\nexp(3.500301 + 30*0.112817) #Anzahl besucher bei 30°C\n\n\n[1] 977.3169\n\n# Test Overdispersion\nif(!require(AER)){install.packages(\"AER\")}\nlibrary(AER)\ndispersiontest(glm.poisson)\n\n\n\n    Overdispersion test\n\ndata:  glm.poisson\nz = 3.8576, p-value = 5.726e-05\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  116.5467 \n\nglm.quasi <- glm(Besucher~Temperatur, family = quasipoisson, data = strand)\nsummary(glm.quasi)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = quasipoisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  3.50030    0.69639   5.026  0.00152 **\nTemperatur   0.11282    0.02227   5.065  0.00146 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 149.6826)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\npar(mfrow = c(2,2))\nplot(glm.gaussian)\n\n\n\nplot(glm.poisson)\n\n\n\nplot(glm.quasi)\n\n\n\npar(mfrow = c(1, 1))\nplot(strand$Temperatur, strand$Besucher, xlim=c(0, 40))\nxv <- rep(0:40, by = .1)\n\nyv <- predict(lm.strand, list(Temperatur = xv))\nlines(xv, yv, lwd = 3, col = \"blue\")\n\nyv2 <- predict(glm.poisson, list(Temperatur = xv))\nlines(xv, exp(yv2), lwd = 3, col = \"red\")\n\nyv3 <- predict(glm.quasi, list(Temperatur = xv))\nlines(xv, exp(yv3), lwd = 3, col = \"green\")\n\n\n\n\nLogistische Regression\n\n\nbathing <- data.frame(\n  \"temperature\" = c(1, 2, 5, 9, 14, 14, 15, 19, 22, 24, 25, 26, 27, 28, 29),\n  \"bathing\" = c(0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1))\nplot(bathing~temperature, data = bathing)\n\n\n\nglm.1<-glm(bathing~temperature, family = \"binomial\", data = bathing)\nsummary(glm.1)\n\n\n\nCall:\nglm(formula = bathing ~ temperature, family = \"binomial\", data = bathing)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7408  -0.4723  -0.1057   0.5123   1.8615  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)  -5.4652     2.8501  -1.918   0.0552 .\ntemperature   0.2805     0.1350   2.077   0.0378 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 20.728  on 14  degrees of freedom\nResidual deviance: 10.829  on 13  degrees of freedom\nAIC: 14.829\n\nNumber of Fisher Scoring iterations: 6\n\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq (glm.1$deviance,glm.1$df.resid)\n\n\n[1] 0.6251679\n\n# Modellgüte (pseudo-R²)\n1 - (glm.1$dev / glm.1$null)\n\n\n[1] 0.4775749\n\n# Steilheit der Beziehung (relative Änderung der odds bei x + 1 vs. x)\nexp(glm.1$coefficients[2])\n\n\ntemperature \n   1.323807 \n\n# LD50 (also hier: Temperatur, bei der 50% der Touristen baden)\n-glm.1$coefficients[1]/glm.1$coefficients[2]\n\n\n(Intercept) \n   19.48311 \n\n# Vorhersagen\npredicted <- predict(glm.1, type = \"response\")\n\n# Konfusionsmatrix\nkm <- table(bathing$bathing, predicted > 0.5)\nkm\n\n\n   \n    FALSE TRUE\n  0     7    1\n  1     1    6\n\n# Missklassifizierungsrate\n1 - sum(diag(km) / sum(km))\n\n\n[1] 0.1333333\n\n#Plotting\nxs <- seq(0, 30, l = 1000)\nmodel.predict <- predict(glm.1, type = \"response\", se = T, \n                         newdata = data.frame(temperature = xs))\n\nplot(bathing~temperature, xlab = \"Temperature (°C)\", \n     ylab = \"% Bathing\", pch = 16, col = \"red\", data = bathing)\npoints(model.predict$fit ~ xs, type=\"l\")\nlines(model.predict$fit+model.predict$se.fit ~ xs, type = \"l\", lty = 2)\nlines(model.predict$fit-model.predict$se.fit ~ xs, type = \"l\", lty = 2)\n\n\n\n\nNicht-lineare Regression\n\n\nif(!require(AICcmodavg)){install.packages(\"AICcmodavg\")}\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(AICcmodavg)\nlibrary(nlstools)\n\nloyn <- read.delim(\"loyn.csv\", sep = \",\") # Verzeichnis muss dort gesetzt sein wo Daten sind\n\n#Selbstdefinierte Funktion, hier Potenzfunktion\npower.model <- nls(ABUND~c*AREA^z, start = (list(c = 1, z = 0)), data = loyn)\nsummary(power.model)\n\n\n\nFormula: ABUND ~ c * AREA^z\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \nc 13.39418    1.30721  10.246 2.87e-14 ***\nz  0.16010    0.02438   6.566 2.09e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.995 on 54 degrees of freedom\n\nNumber of iterations to convergence: 12 \nAchieved convergence tolerance: 7.124e-06\n\nAICc(power.model)\n\n\n[1] 396.1723\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(power.model))\n\n\n\n#Vordefinierte \"Selbststartfunktionen\"#\n?selfStart\nlogistic.model <- nls(ABUND~SSlogis(AREA, Asym, xmid, scal), data = loyn)\nsummary(logistic.model)\n\n\n\nFormula: ABUND ~ SSlogis(AREA, Asym, xmid, scal)\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nAsym   31.306      2.207  14.182  < 2e-16 ***\nxmid    6.501      2.278   2.854  0.00614 ** \nscal    9.880      3.152   3.135  0.00280 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.274 on 53 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 4.371e-06\n\nAICc(logistic.model)\n\n\n[1] 386.8643\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(logistic.model))\n\n\n\n#Visualisierung\nplot(ABUND~AREA, data = loyn)\npar(mfrow = c(1, 1))\nxv <- seq(0, 2000, 0.01)\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(xv, yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(xv, yv2, col = \"blue\")\n\n\n\n#Visualisierung II\nplot(ABUND~log10(AREA), data = loyn)\npar(mfrow = c(1, 1))\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(log10(xv), yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(log10(xv), yv2, col = \"blue\")\n\n\n\n#Model seletkion zwischen den nicht-lineraen Modelen\ncand.models<-list()\ncand.models[[1]] <- power.model\ncand.models[[2]] <- logistic.model\n\nModnames <- c(\"Power\", \"Logistic\")\n\naictab(cand.set = cand.models, modnames = Modnames)\n\n\n\nModel selection based on AICc:\n\n         K   AICc Delta_AICc AICcWt Cum.Wt      LL\nLogistic 4 386.86       0.00   0.99   0.99 -189.04\nPower    3 396.17       9.31   0.01   1.00 -194.86\n\nSmoother\n\n\nloyn$log_AREA<-log10(loyn$AREA)       \nplot(ABUND~log_AREA, data = loyn)\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.25), lwd = 2, col = \"red\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.5), lwd = 2, col = \"blue\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 1), lwd = 2, col = \"green\")\n\n\n\n\nGAMs\n\n\nif(!require(mgcv)){install.packages(\"mgcv\")}\nlibrary(mgcv)\n\ngam.1 <- gam(ABUND~s(log_AREA), data = loyn)\ngam.1\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nEstimated degrees of freedom:\n2.88  total = 3.88 \n\nGCV score: 52.145     \n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\nplot(loyn$log_AREA, loyn$ABUND, pch = 16)\nxv <- seq(-1,4, by = 0.1)\nyv <- predict(gam.1, list(log_AREA = xv))\nlines(xv, yv, lwd = 2, col = \"red\")\n\n\n\nAICc(gam.1)\n\n\n[1] 383.2109\n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\n\n\n\n",
    "preview": "statistik/Statistik4_01_Demo/distill-preview.png",
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_02_Uebung/",
    "title": "Übungen Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nAufgabe 4.1: Nicht-lineare Regression\nAufgabe 4.2N: Logistische Regression (NatWis)\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\n\nAufgabe 4.1: Nicht-lineare Regression\nDatensatz Curonian_Spit.csv\nDieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von geschachtelten Plots (Vegetationsaufnahmen) der Pflanzengesellschaft LolioCynosuretum im Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis 900 m².\nErmittelt den funktionellen Zusammenhang (das beste Modell), der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt.Berücksichtigt dabei mindestens die Potenzfunktion (power function, die logarithmische Funktion (logarithmic function,und eine Funktion mit Sättigung (saturation, asymptote) eurer Wahl.\nAufgabe 4.2N: Logistische Regression (NatWis)\nDatensatz polis.csv\nDer Datensatz polis.csv beschreibt für 19 Inseln im Golf von Kalifornien, ob Eidechsen der Gattung Uta vorkommen (presence/absence: PA) in Abhängigkeit von der Form der Inseln (Verhältnis Umfang zu Fläche: RATIO).\nBitte prüft mit einer logistischen Regression, ob und ggf. wie die Inselform die Präsenz der Eidechsen beinflusst\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\nFührt mit dem Datensatz der Gästebefragung eine logistische Regression durch. Kann der Mensabesuch druch die sozioökonomischen Variablen (Alter, Geschlecht, Hochschulzugehörigkeit), wahrgenommener Fleischkonsum und Einstellung zu ?? vorhergesagt werden?\nHinweise:\nDas Item tho_2 (“Ich mache mir allgemein Gedanken über die Folgen meiner Ernährungsgewohnheiten für die Umwelt.”) müsst ihr in einem ersten Schritt zu einer Dummy-Variable umcodieren: die Antwortkategorien «stimme eher zu» (=3) und «stimme zu» (=4) müsst ihr eine 1 zuweisen, den anderen zwei Kategorien eine 0. Hinweis dafür könnt ihr die Funktion dpylr::case_when() oder dpylr::if_else() verwenden.\nFehlende Werten könnt ihr weglassen (z.B. dpylr::drop_na())\nDefiniert das Modell und wendet es auf den Datensatz an\nBerechnet eine Vorhersage des Modells mit predict()\nEruiert den Modellfit und die Modellgenauigkeit\nFür Motivierte: Berechnet eine Konfusionsmatrix und zieht euer Fazit daraus\nStellt eure Ergebnisse angemessen dar (Text und/oder Tabelle)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-11-08T13:12:30+00:00",
    "input_file": {}
  }
]
