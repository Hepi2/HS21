---
title: "Konsolidierung 4: GLM"
output: distill::distill_article
author:
  Gian-Andrea Egeler
categories:
- Statistik_Konsolidierung4
draft: true



---

```{r echo = FALSE}
#TODO: transformation back noch ergänzen!

#export files
knitr::purl("index.Rmd", "Demo_GLM_Konsolidierung4.R", documentation = 0)

```

# Demo GLM

> Download [R-Skript](Demo_GLM_Konsolidierung4.R)


```{r, include=FALSE, purl=F}

knitr::opts_chunk$set(echo = T, collapse=TRUE)

library(tidyverse)

mytheme <- 
  theme_classic() + 
  theme(
    axis.line = element_line(color = "black"), 
    axis.text = element_text(size = 12, color = "black"), 
    axis.title = element_text(size = 12, color = "black"), 
    axis.ticks = element_line(size = .75, color = "black"), 
    axis.ticks.length = unit(.5, "cm")
    )

```



```{r quasi-poisson regression, message=FALSE}
############
# quasipoisson regression
############

cars <- mtcars %>% 
   mutate(kml = (235.214583/mpg))

glm.poisson <- glm(hp ~ kml, data = cars, family = poisson(link = log))

summary(glm.poisson) # klare overdisperion

# deshalb quasipoisson
glm.quasipoisson <- glm(hp ~ mpg, data = cars, family = quasipoisson(link = log))

summary(glm.quasipoisson)


# visualisiere
ggplot2::ggplot(cars, aes(x = mpg, y = hp)) + 
    geom_point(size = 8) + 
    geom_smooth(method = "glm", method.args = list(family = "poisson"), se = F,
                color = "green", size = 2) + 
    scale_x_continuous(limits = c(0,35)) + 
    scale_y_continuous(limits = c(0,400)) + 
    theme_classic()


#Rücktransformation meiner Variablen




```



```{r logistische regression, message=FALSE}
############
# logistische regression
############
cars <- mtcars

# erstelle das modell
glm.binar <- glm(vs ~ hp, data = cars, family = binomial(link = logit)) 


summary(glm.binar)


# überprüfe das modell
cars$predicted <- predict(glm.binar, type = "response")


# visualisiere
ggplot(cars, aes(x = hp, y = vs)) +    
    geom_point(size = 8) +
    geom_point(aes(y = predicted), shape  = 1, size = 6) +
    guides(color = F) +
    geom_smooth(method = "glm", method.args = list(family = 'binomial'), 
                se = FALSE,
                size = 2) +
    # geom_smooth(method = "lm", color = "red", se = FALSE) +
    mytheme

#Modeldiagnostik (wenn nicht signifikant, dann OK)
1 - pchisq(glm.binar$deviance,glm.binar$df.resid)  


#Modellgüte (pseudo-R²)
1 - (glm.binar$dev / glm.binar$null)  

#Steilheit der Beziehung (relative Änderung der odds von x + 1 vs. x)
exp(glm.binar$coefficients[2])


#LD50 (wieso negativ: weil zweiter koeffizient negative steigung hat)
abs(glm.binar$coefficients[1]/glm.binar$coefficients[2])


# kreuztabelle (confusion matrix): fasse die ergebnisse aus predict und "gegebenheiten, realität" zusammen
tab1 <- table(cars$predicted>.5, cars$vs)
dimnames(tab1) <- list(c("M:S-type","M:V-type"), c("T:S-type", "T:V-type"))
tab1

prop.table(tab1, 2)

#Rücktransformation meiner Variablen



```



```{r glm m& gam, message=FALSE}

###########
# LOESS & GAM
###########

ggplot2::ggplot(mtcars, aes(x = mpg, y = hp)) + 
  geom_point(size = 8) + 
  geom_smooth(method = "gam", se = F, color = "green", size = 2, formula = y ~ s(x, bs = "cs")) + 
  geom_smooth(method = "loess", se = F, color = "red", size = 2) + 
  geom_smooth(method = "glm", size = 2, color = "blue", se = F) + 
  scale_x_continuous(limits = c(0,35)) + 
    scale_y_continuous(limits = c(0,400)) + 
    mytheme


ggplot2::ggplot(mtcars, aes(x = mpg, y = hp)) + 
  geom_point(size = 8) + 
  geom_smooth(method = "gam", se = F, color = "green", size = 2, formula = y ~ s(x, bs = "cs")) + 
    # geom_smooth(method = "loess", se = F, color = "red", size = 2) + 
  geom_smooth(method = "glm", size = 2, color = "grey", se = F) + 
  scale_x_continuous(limits = c(0,35)) + 
  scale_y_continuous(limits = c(0,400)) + 
  mytheme


```



