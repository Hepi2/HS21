## Übung A: Lösung

###  Musterlösung Aufgabe 3
[R-script als Download](13_Statistik1/RFiles/Uebung_A_loesung.R)


```{r,warning=F}
library(tidyverse)
```



Aus @crawley2015 [S. 162] (Scripts angepasst)

There are two traditional ways of plotting the results of ANOVA:

- box-and-whisker plots
- barplots with error bars

We have an experiment on plant competition where the response variable is biomass and we have one factor with five levels. The factor is called cl ipping and the levels are control (i.e. unclipped), two intensities of shoot pruning and two intensities of root pruning:

```{r}
comp <- read_delim("13_Statistik1/data/competition.csv",",")

ggplot(comp, aes(clipping, biomass)) +
  geom_boxplot(fill = "lightgrey") +
  labs(x = "Competition treatment", y = "Biomass")


```

The box-and-whisker plot is good at showing the nature of the variation within each treatment, and also whether there is skew within each treatment (e.g. for the control plots, there is a wider range of values between the median and upper quartile than between the lower quartile and median). No outliers are shown above the whiskers, so the tops and bottoms of the bars are the maxima and minima within each treatment. The medians for the competition treatments are all higher than the upper quartile of the controls, suggesting that they may be significantly different from the controls, but there is little to suggest that any of the competition treatments are significantly different from one another (see below for the analysis).

Barplots with error bars are the style preferred by many journal editors, and some people think that they make hypothesis testing easier. We shall see.
```{r}
comp_summary <- comp %>% 
  group_by(clipping) %>%
  summarise(
    mean = mean(biomass)
  )
```


Now draw the barplot, making sure that the y axis is long enough to accommodate the tops of the error bars that we intend to add later:


```{r}

p <- ggplot(comp_summary, aes(clipping, mean)) +
  geom_bar(stat = "identity")

p
```

This is fine as far as it goes, but it gives us no impression of the uncertainty associated with the estimated heights of the bars. 

Let us use one standard error of the mean based on the pooled error variance from the ANOVA, then return to a discussion of the pros and cons of different kinds of error bars later. Here is the one-way ANOVA:

```{r}
t <- aov(biomass~clipping, comp)

summary(t)

```

There was equal replication (which makes life easier), and each mean was based on six replicates, so the standard error of the mean is $\sqrt{\frac{s^2}{n}} = \sqrt{\frac{4961}{6}} = 28.75$

We shall draw an error bar up 28.75 from each mean and down by the same distance, so we need five values, one for each bar, each of 28.75:

```{r}
comp_summary <- comp %>% 
  group_by(clipping) %>%
  summarise(
    mean = mean(biomass),
    se = sqrt(4691/n())
  )

comp_summary

```
Now we can use the new function to add the error bars to the plot:
```{r}
ggplot(comp_summary, aes(clipping, mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),width = 0.2)


```

We do not get the same feel for the distribution of the values within each treatment as was obtained by the box-and-whisker plot, but we can certainly see clearly which means are not significantly different. If, as here, we use ± 1 standard error as the length of the error bars, then when the bars overlap this implies that the two means are not significantly different. Remember the rule of thumb for t: significance requires 2 or more standard errors, and if the bars overlap it means that the difference between the means is less than 2 standard errors.This shows clearly that none of the means for the clipped plants (n25, n50, r10 or r5) is significantly different from any other (the top of the bar for n25 overlaps the bottom of the bar for r10).

There is another issue, too. For comparing means, we should be using the standard error of the difference between two means (not the standard error of one mean) in our tests (see p. 91); these bars would be about 1.4 times as long as the bars we have drawn here. So while we can be sure that the pruning treatments are not significantly different from one another, we cannot conclude from this plot that the controls have significantly lower biomass than the rest (because the error bars are not the correct length for testing differences between means).

An alternative graphical method is to use 95% confidence intervals for the lengths of the bars, rather than standard errors of means. This is easy to do: we multiply our standard errors by Student’s t, qt ( .975,5) = 2.570582, to get the lengths of the confidence intervals:

```{r}






comp_summary <- comp %>% 
  group_by(clipping) %>%
  summarise(
    mean = mean(biomass),
    se = sqrt(4691/n())
  ) %>%
  mutate(
    ci = se*qt(0.975,5)
  )

ggplot(comp_summary, aes(clipping, mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean-ci, ymax = mean+ci),width = 0.2)



comp_summary <- comp %>% 
  group_by(clipping) %>%
  summarise(
    mean = mean(biomass),
    se = sqrt(4691/n())
  ) %>%
  mutate(
    ci = se*qt(0.975,5),
    lsd = (qt(0.975,10)*sqrt(2*4961/6))/2
  )


ggplot(comp_summary, aes(clipping, mean)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = mean-lsd, ymax = mean+lsd),width = 0.2)
```


