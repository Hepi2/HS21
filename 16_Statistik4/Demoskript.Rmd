```{r, include=FALSE, purl=F}

knitr::opts_chunk$set(echo = TRUE,include = T, results = "hide",collapse=TRUE)
```
## Statistik 4 - Demoskript

**(c) Juergen Dengler, 05.11.2018**

```{r}
compensation<-read.table("16_Statistik4/data/ipomopsis.csv", header=T,sep=",")
summary(compensation)
attach(compensation)

plot(Fruit~Root)
plot(Fruit~Grazing)

tapply(Fruit,Grazing,mean)

model<-lm(Fruit~Root*Grazing)
summary.aov(model)

model2<-lm(Fruit~Grazing*Root)
summary.aov(model2)

model3<-lm(Fruit~Grazing+Root)
summary.lm(model3)

#Plotten der Ergebnisse
plot(Fruit~Root,pch=21,bg=(1+as.numeric(Grazing)))
#legend(locator(1),c("grazed","ungrazed"),col=c(2,3),pch=16)

abline(-127.829,23.56,col="red")
abline(-127.892+36.103,23.56,col="green")

##Nicht-lineare Regression

library(AICcmodavg)
library(nlstools)

loyn <- read.table("16_Statistik4/data/loyn.csv", header=T,sep=",")
attach(loyn)

#Selbstdefinierte Funktion, hier Potenzfunktion
power.model<-nls(ABUND~c*AREA^z,start=(list(c=1,z=0)))
summary(power.model)
AICc(power.model)

#Modeldiagnostik (in nlstools)
plot(nlsResiduals(power.model))

#Vordefinierte "Selbststartfunktionen"#
?selfStart
logistic.model<-nls(ABUND~SSlogis(AREA,Asym,xmid,scal))
summary(logistic.model)
AICc(logistic.model)

#Modeldiagnostik (in nlstools)
plot(nlsResiduals(logistic.model))

#Visualisierung
plot(ABUND~AREA)
par(mfrow=c(1,1))
xv<-seq(0,2000,0.01)

# 1. Potenzfunktion
yv1 <-predict(power.model,list(AREA=xv))
lines(xv,yv1,col="green")

# 2. Logistische Funktion
yv2 <-predict(logistic.model,list(AREA=xv))
lines(xv,yv2,col="blue")

#Visualisierung II
plot(ABUND~log10(AREA))
par(mfrow=c(1,1))

# 1. Potenzfunktion
yv1 <-predict(power.model,list(AREA=xv))
lines(log10(xv),yv1,col="green")

# 2. Logistische Funktion
yv2 <-predict(logistic.model,list(AREA=xv))
lines(log10(xv),yv2,col="blue")

#Model selection among several non-linear models

cand.models<-list()
cand.models[[1]]<-power.model
cand.models[[2]]<-logistic.model

Modnames <- c("Power", "Logistic")

aictab(cand.set = cand.models, modnames = Modnames)


##Smoother

attach(loyn)
log_AREA<-log10(AREA)       
plot(ABUND~log_AREA)
lines(lowess(log_AREA,ABUND,f=0.25),lwd=2,col="red")
lines(lowess(log_AREA,ABUND,f=0.5),lwd=2,col="blue")
lines(lowess(log_AREA,ABUND,f=1),lwd=2,col="green")


#GAMs

library(mgcv)

model<-gam(ABUND~s(log_AREA))
model
summary(model)
plot(log_AREA,ABUND,pch=16)
xv<-seq(-1,4,by=0.1)
yv<-predict(model,list(log_AREA=xv))
lines(xv,yv,lwd=2,col="red")
AICc(model)
summary(model)



##von LMs zu GLMs

temp<-c(10,12,16,20,24,25,30,33,37)
besucher<-c(40,12,50,500,400,900,1500,900,2000)
strand<-data.frame("Temperatur"=temp,"Besucher"=besucher)
attach(strand)
par(mfrow=c(1,1))
plot(besucher~temp)
lm.strand<-lm(Besucher~Temperatur, data=strand)
summary(lm.strand)
par(mfrow=c(2,2))
plot(lm.strand)

par(mfrow=c(1,1))
xv<-rep(0:40,by=.1)
yv<-predict(lm.strand,list(Temperatur=xv))
plot(Temperatur,Besucher,xlim=c(0,40))
lines(xv,yv,lwd=3,col="blue")

glm.gaussian<-glm(Besucher~Temperatur,family=gaussian)
glm.poisson<-glm(Besucher~Temperatur,family=poisson)

summary(glm.gaussian)
summary(glm.poisson)


glm.quasi<-glm(Besucher~Temperatur,family=quasipoisson)
summary(glm.quasi)

par(mfrow=c(2,2))
plot(glm.gaussian)
plot(glm.poisson)
plot(glm.quasi)

par(mfrow=c(1,1))
plot(Temperatur,Besucher,xlim=c(0,40))
xv<-rep(0:40,by=.1)

yv<-predict(lm.strand,list(Temperatur=xv))
lines(xv,yv,lwd=3,col="blue")
yv2<-predict(glm.poisson,list(Temperatur=xv))
lines(xv,exp(yv2),lwd=3,col="red")
yv3<-predict(glm.quasi,list(Temperatur=xv))
lines(xv,exp(yv3),lwd=3,col="green")

#test for overdispersion

library(AER)
dispersiontest(glm.poisson)


##logistic regression

bathing<-data.frame("temperature"=c(1,2,5,9,14,14,15,19,22,24,25,26,27,28,29),
                    "bathing"=c(0,0,0,0,0,1,0,0,1,0,1,1,1,1,1))
plot(bathing~temperature, data=bathing)

model<-glm(bathing~temperature,data=bathing,family="binomial")
summary(model)

#Modeldiagnostik (wenn nicht signifikant, dann OK)
1 - pchisq (model$deviance,model$df.resid)

#Modellge (pseudo-R)
1 - (model$dev / model$null)

#Steilheit der Beziehung (relative Aenderung der odds bei x + 1 vs. x)
exp(model$coefficients[2])

#LD50 (also hier: Temperatur, bei der 50% der Touristen baden)
-model$coefficients[1]/model$coefficients[2]

#Vorhersagen
predicted <- predict(model, type="response")

#Konfusionsmatrix
km <- table(bathing$bathing, predicted > 0.5)
km

# Missklassifizierungsrate
1-sum(diag(km)/sum(km))


#Plotting
xs<-seq(0,30,l=1000)
model.predict<-predict(model,type="response",se=T,newdata=data.frame(temperature=xs))
plot(bathing~temperature,data=bathing,xlab="Temperature (C)",ylab="% Bathing",pch=16, col="red")
points(model.predict$fit ~ xs,type="l")
lines(model.predict$fit+model.predict$se.fit ~ xs, type="l",lty=2)
lines(model.predict$fit-model.predict$se.fit ~ xs, type="l",lty=2)
```



