[
  {
    "path": "prepro/PrePro1_Demo_Datentypen/",
    "title": "Demo Datentypen",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-26",
    "categories": [
      "PrePro1",
      "PrePro"
    ],
    "contents": "\n\nContents\nDatentypen\nData Frames und Conveniance Variabeln\n\n\n\n\nR-Code als Download\nDatentypen\nNumerics\nUnter die Kategorie numeric fallen in R zwei Datentypen:\ndouble: Gleitkommazahl (z.B. 10.3, 7.3)\ninteger: Ganzzahl (z.B. 10, 7)\nDoubles\nFolgendermassen wird eine Gleitkommazahl einer Variabel zuweisen:\n\n\nx <- 10.3\n\nx\n\n\n[1] 10.3\n\ntypeof(x)\n\n\n[1] \"double\"\n\nStatt <-kann auch = verwendet werden. Dies funktioniert aber nicht in allen Situationen, und ist zudem leicht mit == zu verwechseln.\n\n\ny = 7.3\n\ny\n\n\n[1] 7.3\n\nOhne explizite Zuweisung nimmt R immer den Datentyp doublean:\n\n\nz <- 42\ntypeof(z)\n\n\n[1] \"double\"\n\nis.integer(z)\n\n\n[1] FALSE\n\nis.numeric(z)\n\n\n[1] TRUE\n\nis.double(z)\n\n\n[1] TRUE\n\nGanzzahl / Integer\nErst wenn man eine Zahl explizit als integer definiert (mit as.integer() oder L), wird sie auch als solches abgespeichert.\n\n\na <- as.integer(z)\nis.numeric(a)\n\n\n[1] TRUE\n\nis.integer(a)\n\n\n[1] TRUE\n\nc <- 8L\nis.numeric(c)\n\n\n[1] TRUE\n\nis.integer(c)\n\n\n[1] TRUE\n\n\n\ntypeof(a)\n\n\n[1] \"integer\"\n\nis.numeric(a)\n\n\n[1] TRUE\n\nis.integer(a)\n\n\n[1] TRUE\n\nMit c() können eine Reihe von Werten in einer Variabel zugewiesen werden (als vector). Es gibt zudem auch character vectors.\n\n\nvector <- c(10,20,33,42,54,66,77)\nvector\n\n\n[1] 10 20 33 42 54 66 77\n\nvector[5]\n\n\n[1] 54\n\nvector[2:4]\n\n\n[1] 20 33 42\n\nvector2 <- vector[2:4]\n\n\n\nEine Ganzzahl kann explizit mit as.integer() definiert werden.\n\n\na <- as.integer(7)\nb <- as.integer(3.14)\na\n\n\n[1] 7\n\nb\n\n\n[1] 3\n\ntypeof(a)\n\n\n[1] \"integer\"\n\ntypeof(b)\n\n\n[1] \"integer\"\n\nis.integer(a)\n\n\n[1] TRUE\n\nis.integer(b)\n\n\n[1] TRUE\n\nEine Zeichenkette kann als Zahl eingelesen werden.\n\n\nc <- as.integer(\"3.14\")\nc\n\n\n[1] 3\n\ntypeof(c)\n\n\n[1] \"integer\"\n\nLogische Abfragen\nWird auch auch als boolesch (Eng. boolean) bezeichnet.\n\n\ne <- 3\nf <- 6\ng <- e > f\ne\n\n\n[1] 3\n\nf\n\n\n[1] 6\n\ng\n\n\n[1] FALSE\n\ntypeof(g)\n\n\n[1] \"logical\"\n\nLogische Operationen\n\n\nsonnig <- TRUE\ntrocken <- FALSE\n\nsonnig & !trocken\n\n\n[1] TRUE\n\nOft braucht man auch das Gegenteil / die Negation eines Wertes. Dies wird mittels ! erreicht\n\n\nu <- TRUE\nv <- !u \nv\n\n\n[1] FALSE\n\nZeichenketten\nZeichenketten (Eng. character) stellen Text dar\n\n\ns <- as.character(3.14)\ns\n\n\n[1] \"3.14\"\n\ntypeof(s)\n\n\n[1] \"character\"\n\nZeichenketten verbinden / zusammenfügen (Eng. concatenate)\n\n\nfname <- \"Hans\"\nlname <- \"Muster\"\npaste(fname,lname)\n\n\n[1] \"Hans Muster\"\n\nfname2 <- \"hans\"\nfname == fname2\n\n\n[1] FALSE\n\nFactors\nMit Factors wird in R eine Sammlung von Zeichenketten bezeichnet, die sich wiederholen, z.B. Wochentage (es gibt nur 7 unterschiedliche Werte für “Wochentage”).\n\n\nwochentage <- c(\"Montag\",\"Dienstag\",\"Mittwoch\",\"Donnerstag\",\"Freitag\",\"Samstag\",\"Sonntag\",\n                \"Montag\",\"Dienstag\",\"Mittwoch\",\"Donnerstag\",\"Freitag\",\"Samstag\",\"Sonntag\")\n\ntypeof(wochentage)\n\n\n[1] \"character\"\n\nwochentage_fac <- as.factor(wochentage)\n\nwochentage\n\n\n [1] \"Montag\"     \"Dienstag\"   \"Mittwoch\"   \"Donnerstag\" \"Freitag\"   \n [6] \"Samstag\"    \"Sonntag\"    \"Montag\"     \"Dienstag\"   \"Mittwoch\"  \n[11] \"Donnerstag\" \"Freitag\"    \"Samstag\"    \"Sonntag\"   \n\nwochentage_fac\n\n\n [1] Montag     Dienstag   Mittwoch   Donnerstag Freitag    Samstag   \n [7] Sonntag    Montag     Dienstag   Mittwoch   Donnerstag Freitag   \n[13] Samstag    Sonntag   \n7 Levels: Dienstag Donnerstag Freitag Mittwoch Montag ... Sonntag\n\nWie man oben sieht, unterscheiden sich character vectors und factors v.a. dadurch, dass letztere über sogenannte levels verfügt. Diese levels entsprechen den Eindeutigen (unique) Werten.\n\n\nlevels(wochentage_fac)\n\n\n[1] \"Dienstag\"   \"Donnerstag\" \"Freitag\"    \"Mittwoch\"   \"Montag\"    \n[6] \"Samstag\"    \"Sonntag\"   \n\nunique(wochentage)\n\n\n[1] \"Montag\"     \"Dienstag\"   \"Mittwoch\"   \"Donnerstag\" \"Freitag\"   \n[6] \"Samstag\"    \"Sonntag\"   \n\nZudem ist fällt auf, dass die Reihenfolge der Wohentag alphabetisch sortiert ist. Wie diese sortiert werden zeigen wir an einem anderen Beispiel:\n\n\nzahlen <- factor(c(\"null\",\"eins\",\"zwei\",\"drei\"))\n\nzahlen\n\n\n[1] null eins zwei drei\nLevels: drei eins null zwei\n\nOffensichtlich sollten diese factors geordnet sein, R weiss davon aber nichts. Eine Ordnung kann man mit dem Befehl ordered = T festlegen.\nBeachtet: ordered = T kann nur bei der Funktion factor() spezifiziert werden, nicht bei as.factor(). Ansonsten sind factor() und as.factor() sehr ähnlich.\n\n\nzahlen <- factor(zahlen,ordered = T)\n\nzahlen\n\n\n[1] null eins zwei drei\nLevels: drei < eins < null < zwei\n\nBeachtet das “<”-Zeichen zwischen den Levels. Die Zahlen werden nicht in der korrekten Reihenfolge, sondern Alphabetisch geordnet. Die richtige Reihenfolge kann man mit levels = festlegen.\n\n\nzahlen <- factor(zahlen,ordered = T,levels = c(\"null\",\"eins\",\"zwei\",\"drei\",\"vier\"))\n\nzahlen\n\n\n[1] null eins zwei drei\nLevels: null < eins < zwei < drei < vier\n\nWie auch schon erwähnt werden factors als character Vektor dargestellt, aber als Integers gespeichert. Das führt zu einem scheinbaren Wiederspruch wenn man den Datentyp auf unterschiedliche Weise abfragt.\n\n\ntypeof(zahlen)\n\n\n[1] \"integer\"\n\nis.integer(zahlen)\n\n\n[1] FALSE\n\nMit typeof() wird eben diese Form der Speicherung abgefragt und deshalb mit integer beantwortet. Da es sich aber nicht um einen eigentlichen Integer Vektor handelt, wird die Frage is.integer() mit FALSE beantwortet. Das ist etwas verwirrend, beruht aber darauf, dass die beiden Funktionen die Frage von unterschiedlichen Perspektiven beantworten. In diesem Fall schafft class() Klarheit:\n\n\nclass(zahlen)\n\n\n[1] \"ordered\" \"factor\" \n\nWirklich verwirrend wird es, wenn factors in numeric umgewandelt werden sollen.\n\n\nzahlen\n\n\n[1] null eins zwei drei\nLevels: null < eins < zwei < drei < vier\n\nas.integer(zahlen)\n\n\n[1] 1 2 3 4\n\nDas die Übersetzung der auf Deutsch ausgeschriebenen Nummern in nummerische Zahlen nicht funktionieren würde, war ja klar. Weniger klar ist es jedoch, wenn die factors bereits aus nummerischen Zahlen bestehen.\n\n\nzahlen2 <- factor(c(\"3\",\"2\",\"1\",\"0\"))\n\nas.integer(zahlen2)\n\n\n[1] 4 3 2 1\n\nIn diesem Fall müssen die factors erstmals in character umgewandelt werden.\n\n\nzahlen2 <- factor(c(\"3\",\"2\",\"1\",\"0\"))\n\nas.integer(as.character(zahlen2))\n\n\n[1] 3 2 1 0\n\nZeit/Datum\nUm in R mit Datum/Zeit Datentypen umzugehen, müssen sie als POSIXct eingelesen werden (es gibt alternativ noch POSIXlt, aber diese ignorieren wir mal). Anders als Beispielsweise bei Excel, sollten in R Datum und Uhrzeit immer in einer Spalte gespeichert werden.\n\n\ndatum <- \"2017-10-01 13:45:10\"\n\nas.POSIXct(datum)\n\n\n[1] \"2017-10-01 13:45:10 CEST\"\n\nWenn das die Zeichenkette in dem obigen Format (Jahr-Monat-Tag Stunde:Minute:Sekunde) daher kommt, braucht as.POSIXctkeine weiteren Informationen. Sollte das Format von dem aber Abweichen, muss man der Funktion das genaue Schema jedoch mitteilen. Der Syntax dafür kann via ?strptime nachgeschlagen werden.\n\n\ndatum <- \"01.10.2017 13:45\"\n\nas.POSIXct(datum,format = \"%d.%m.%Y %H:%M\")\n\n\n[1] \"2017-10-01 13:45:00 CEST\"\n\ndatum <- as.POSIXct(datum,format = \"%d.%m.%Y %H:%M\")\n\n\n\nBeachtet, dass in den den obigen Beispiel R automatisch eine Zeitzone angenommen hat (CEST). R geht davon aus, dass die Zeitzone der System Timezone (Sys.timezone()) entspricht.\n\n\nstrftime(datum, format = \"%m\")\n\n\n[1] \"10\"\n\nstrftime(datum, format = \"%b\")\n\n\n[1] \"Okt\"\n\nstrftime(datum, format = \"%B\")\n\n\n[1] \"Oktober\"\n\nData Frames und Conveniance Variabeln\nEine data.frame ist die gängigste Art, Tabellarische Daten zu speichern.\n\n\ndf <- data.frame(\n  Stadt = c(\"Zürich\",\"Genf\",\"Basel\",\"Bern\",\"Lausanne\"),\n  Einwohner = c(396027,194565,175131,140634,135629),\n  Ankunft = c(\"1.1.2017 10:00\",\"1.1.2017 14:00\",\n              \"1.1.2017 13:00\",\"1.1.2017 18:00\",\"1.1.2017 21:00\")\n)\n\nstr(df)\n\n\n'data.frame':   5 obs. of  3 variables:\n $ Stadt    : chr  \"Zürich\" \"Genf\" \"Basel\" \"Bern\" ...\n $ Einwohner: num  396027 194565 175131 140634 135629\n $ Ankunft  : chr  \"1.1.2017 10:00\" \"1.1.2017 14:00\" \"1.1.2017 13:00\" \"1.1.2017 18:00\" ...\n\nIn der obigen data.frame wurde die Spalte Einwohner als Fliesskommazahl abgespeichert. Dies ist zwar nicht tragisch, aber da wir wissen das es sich hier sicher um Ganzzahlen handelt, können wir das korrigieren. Wichtiger ist aber, dass wir die Ankunftszeit (SpalteAnkunft) von einem Factor in ein Zeitformat (POSIXct) umwandeln.\n\n\ndf$Einwohner <- as.integer(df$Einwohner)\n\ndf$Einwohner\n\n\n[1] 396027 194565 175131 140634 135629\n\ndf$Ankunft <- as.POSIXct(df$Ankunft, format = \"%d.%m.%Y %H:%M\")\n\ndf$Ankunft\n\n\n[1] \"2017-01-01 10:00:00 CET\" \"2017-01-01 14:00:00 CET\"\n[3] \"2017-01-01 13:00:00 CET\" \"2017-01-01 18:00:00 CET\"\n[5] \"2017-01-01 21:00:00 CET\"\n\nDiese Rohdaten können nun helfen, um Hilfsvariablen (convenience variables) zu erstellen. Z.B. können wir die Städte einteilen in gross, mittel und klein.\n\n\ndf$Groesse[df$Einwohner > 300000] <- \"gross\"\ndf$Groesse[df$Einwohner <= 300000 & df$Einwohner > 150000] <- \"mittel\"\ndf$Groesse[df$Einwohner <= 150000] <- \"klein\"\n\n\n\nOder aber, die Ankunftszeit kann von der Spalte Ankunftabgeleitet werden. Dazu brauchen wir aber das Package lubridate\n\n\nlibrary(lubridate)\n\n\n\n\n\ndf$Ankunft_stunde <- hour(df$Ankunft)\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-26T05:47:12+02:00",
    "input_file": "index.knit.md"
  },
  {
    "path": "prepro/PrePro1_Uebung_A/",
    "title": "Uebung A",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-19",
    "categories": [
      "PrePro1",
      "PrePro"
    ],
    "contents": "\n\nContents\nArbeiten mit RStudio “Project”\nArbeiten mit Libraries / Packages\nAufgabe 1\nAufgabe 2\nAufgabe 3\nAufgabe 4\nAufgabe 5\nAufgabe 6\nAufgabe 7\nAufgabe 8\n\nArbeiten mit RStudio “Project”\nWir empfehlen die Verwendung von “Projects” innerhalb von RStudio. RStudio legt für jedes Projekt dann einen Ordner an, in welches die Projekt-Datei abgelegt wird (Dateiendung .Rproj). Sollen innerhalb des Projekts dann R-Skripts geladen oder erzeugt werden, werden diese dann auch im angelegten Ordner abgelegt. Mehr zu RStudio Projects findet ihr hier.\nDas Verwenden von Projects bringt verschiedene Vorteile, wie zum Beispiel:\nFestlegen der Working Directory ohne die Verwendung des expliziten Pfades (setwd()). Das ist sinnvoll, da sich dieser Pfad ändern kann (Zusammenarbeit mit anderen Usern, Ausführung des Scripts zu einem späteren Zeitpunkt)\nAutomatisches Zwischenspeichern geöffneter Scripts und Wiederherstellung der geöffneten Scripts bei der nächsten Session\nFestlegen verschiedener projektspezifischer Optionen\nVerwendung von Versionsverwaltungssystemen (git oder SVN)\nArbeiten mit Libraries / Packages\nR ist ohne Zusatzpackete nicht mehr denkbar. Die allermeisten Packages werden auf CRAN gehostet und können leicht mittels install.packages() installiert werden. Eine sehr wichtige Sammlung von Packages wird von RStudio entwickelt. Unter dem Namen Tidyverse werden eine Reihe von Packages angeboten, den R-Alltag enorm erleichtert. Wir werden später näher auf das “Tidy”-Universum eingehen, an dieser Stelle können wir die Sammlung einfach mal installieren.\ninstall.packages(\"tidyverse\")\nUm ein package in R verwenden zu können, gibt es zwei Möglichkeiten:\nentweder man lädt es zu Beginn der R-session mittles library(tidyverse) (ohne Anführungs- und Schlusszeichen).\noder man ruft eine function mit vorangestelltem Packetname sowie zwei Doppelpunkten auf. dplyr::filter() ruft die Funktion filter() des Packets dplyr auf.\nLetztere Notation ist vor allem dann sinnvoll, wenn sich zwei unterschiedliche Funktionen mit dem gleichen namen in verschiedenen pacakges existieren. filter() existiert als Funktion einersits im package dplyr sowie in stats. Dieses Phänomen nennt man “masking”.\nZu beginn laden wir die nötigen Pakete:\n\n\n\n\nTidyverse liefert viele Funktionen, für die es in der normalen R-Umgebung (“base R”) keine wirkliche Alternative gibt. Andere Funktionen sind alternativen zu Base-R Funktionen:\ndata_frame() statt data.frame()\nread_* statt read.*\nparse_datetime statt as.POSIXct()\nDiese verhalten sich leicht anders als Base-R Funktionen: Sie treffen weniger Annahmen und sind etwas restriktiver. Wir verwenden oft Tidyverse Funktionen, ihr könnt aber selber entscheiden welche Version ihr benutzt.\nAufgabe 1\nErstelle eine data.frame mit nachstehenden Daten.\nTipps:\nEine leere data.frame zu erstellen ist schwieriger als wenn erstellen und befüllen der data.frame in einem Schritt erfolgt\nR ist dafür gedacht, Spalte für Spalte zu arbeiten (warum?), nicht Reihe für Reihe. Versuche dich an dieses Schema zu halten.\n\n\n\n\nTierart\nAnzahl\nGewicht\nGeschlecht\nBeschreibung\nFuchs\n2\n4.4\nm\nRötlich\nBär\n5\n40.3\nf\nBraun, gross\nHase\n1\n1.1\nm\nklein, mit langen Ohren\nElch\n3\n120.0\nm\nLange Beine, Schaufelgeweih\n\nAufgabe 2\nWas für Datentypen wurden (in Aufgabe 1) von R automatisch angenommen? Sind diese sinnvoll?\nTipp: Nutze dazu str()\n\n'data.frame':   4 obs. of  5 variables:\n $ Tierart     : chr  \"Fuchs\" \"Bär\" \"Hase\" \"Elch\"\n $ Anzahl      : num  2 5 1 3\n $ Gewicht     : num  4.4 40.3 1.1 120\n $ Geschlecht  : chr  \"m\" \"f\" \"m\" \"m\"\n $ Beschreibung: chr  \"Rötlich\" \"Braun, gross\" \"klein, mit langen Ohren\" \"Lange Beine, Schaufelgeweih\"\n\n\n[1] \"double\"\n\nAufgabe 3\nNutze die Spalte Gewicht um die Tiere in 3 Gewichtskategorien einzuteilen:\nleicht: < 5kg\nmittel: 5 - 100 kg\nschwer: > 100kg\n\n\n\n\nTierart\nAnzahl\nGewicht\nGeschlecht\nBeschreibung\nGewichtsklasse\nFuchs\n2\n4.4\nm\nRötlich\nleicht\nBär\n5\n40.3\nf\nBraun, gross\nmittel\nHase\n1\n1.1\nm\nklein, mit langen Ohren\nleicht\nElch\n3\n120.0\nm\nLange Beine, Schaufelgeweih\nschwer\n\nAufgabe 4\nImportiere den Datensatz order_52252_data.txt. Es handelt sich dabei um die stündlich gemittelten Temperaturdaten an verschiedenen Standorten in der Schweiz im Zeitraum 2000 - 2005. Wir empfehlen read_table()1 anstelle von read.table().\n\n\n\n\nstn\ntime\ntre200h0\nABO\n2000010100\n-2.6\nABO\n2000010101\n-2.5\nABO\n2000010102\n-3.1\nABO\n2000010103\n-2.4\nABO\n2000010104\n-2.5\nABO\n2000010105\n-3.0\nABO\n2000010106\n-3.7\nABO\n2000010107\n-4.4\nABO\n2000010108\n-4.1\nABO\n2000010109\n-4.1\n\nAufgabe 5\nSchau dir die Rückmeldung von read_table()an. Sind die Daten korrekt interpretiert worden?\n\n\n\nAufgabe 6\nDie Spalte time ist eine Datum/Zeitangabe im Format JJJJMMTTHH (siehe meta.txt). Damit R dies als Datum-/Zeitangabe erkennt, müssen wir die Spalte in einem R-Format (POSIXct) einlesen und dabei R mitteilen, wie sie aktuell formatiert ist. Lies die Spalte mit as.POSIXct() (oder parse_datetime) ein und spezifiziere sowohl format wie auch tz.\nTipps:\nWenn keine Zeitzone festgelegt wird, trifft as.POSIXct() eine Annahme (basierend auf Sys.timezone()). In unserem Fall handelt es sich aber um Werte in UTC (siehe meta.txt)\nas.POSIXcterwartet character: Wenn du eine Fehlermeldung hast die 'origin' must be supplied (o.ä) heisst, hast du der Funktion vermutlich einen Numeric übergeben.\n\n\n\n\nstn\ntime\ntre200h0\nABO\nNA\n-2.6\nABO\nNA\n-2.5\nABO\nNA\n-3.1\nABO\nNA\n-2.4\nABO\nNA\n-2.5\nABO\nNA\n-3.0\nABO\nNA\n-3.7\nABO\nNA\n-4.4\nABO\nNA\n-4.1\nABO\nNA\n-4.1\n\nAufgabe 7\nErstelle zwei neue Spalten mit Wochentag (Montag, Dienstag, etc) und Kalenderwoche. Verwende dazu die neu erstellte POSIXct-Spalte\n\n\n\n\nstn\ntime\ntre200h0\nwochentag\nkw\nABO\nNA\n-2.6\nNA\nNA\nABO\nNA\n-2.5\nNA\nNA\nABO\nNA\n-3.1\nNA\nNA\nABO\nNA\n-2.4\nNA\nNA\nABO\nNA\n-2.5\nNA\nNA\nABO\nNA\n-3.0\nNA\nNA\nABO\nNA\n-3.7\nNA\nNA\nABO\nNA\n-4.4\nNA\nNA\nABO\nNA\n-4.1\nNA\nNA\nABO\nNA\n-4.1\nNA\nNA\n\nAufgabe 8\nErstelle eine neue Spalte basierend auf die Temperaturwerte mit der Einteilung “kalt” (Unter Null Grad) und “warm” (über Null Grad)\n\n\n\n\nstn\ntime\ntre200h0\nwochentag\nkw\ntemp_kat\nABO\nNA\n-2.6\nNA\nNA\nkalt\nABO\nNA\n-2.5\nNA\nNA\nkalt\nABO\nNA\n-3.1\nNA\nNA\nkalt\nABO\nNA\n-2.4\nNA\nNA\nkalt\nABO\nNA\n-2.5\nNA\nNA\nkalt\nABO\nNA\n-3.0\nNA\nNA\nkalt\nABO\nNA\n-3.7\nNA\nNA\nkalt\nABO\nNA\n-4.4\nNA\nNA\nkalt\nABO\nNA\n-4.1\nNA\nNA\nkalt\nABO\nNA\n-4.1\nNA\nNA\nkalt\n\n\n@wickham2017, Kapitel 8 bzw. http://r4ds.had.co.nz/data-import.html)↩︎\n",
    "preview": {},
    "last_modified": "2021-08-19T12:24:03+02:00",
    "input_file": {}
  },
  {
    "path": "prepro/PrePro1_Uebung_B/",
    "title": "Uebung B",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [
      "PrePro1",
      "PrePro"
    ],
    "contents": "\n\nContents\nAufgabe 1\nAufgabe 2\nAufgabe 3\n\n\n\nlibrary(tidyverse)\n\n\n\nFahre mit dem Datensatz wetter aus Übung A fort.\n\n\nwetter <- read_table(\"order_52252_data.txt\",\n                  col_types = list(\n                    col_factor(levels = NULL),    \n                    col_datetime(format = \"%Y%m%d%H\"),\n                    col_double()\n                    )\n                  )\n\n\n\nAufgabe 1\nNutze plot() um die Temparaturkurve zu visualisieren. Verwende aber vorher filter() um dich auf eine Station (z.B. “ABO”) zu beschränken (es handelt sich sonst um zuviele Datenpunkte).\n\n\n# Lösung Aufgabe 1\n\nwetter_fil <- dplyr::filter(wetter, stn == \"ABO\")\n\nplot(wetter_fil$time,wetter_fil$tre200h0, type = \"l\")\n\n\n\n\nNun schauen wir uns das plotten mit ggplot2 an. Ein simpler Plot wie der in der vorherigen Aufgabe ist in ggplot2 zugegebenermassen etwas komplizierter. ggplot2 wird aber rasch einfacher, wenn die Grafiken komplexer werden. Wir empfehlen deshalb stark, ggplot2 zu verwenden.\nSchau dir ein paar online Tutorials zu ggplot2 an (siehe 1) und reproduziere den obigen Plot mit ggplot2\n\n\np <- ggplot(wetter_fil, aes(time,tre200h0)) +\n  geom_line()\n\np\n\n\n\n\nAufgabe 2\nSpiele mit Hilfe der erwähnten Tutorials mit dem Plot etwas rum. Versuche die x-/y-Achsen zu beschriften sowie einen Titel hinzu zu fügen.\n\n\n# Lösung Aufgabe 2\np <- p +\n  labs(x = \"Datum\", y = \"Temperatur\", title = \"Stündlich gemittelte Temperaturwerte\")\n\np\n\n\n\n\nAufgabe 3\nReduziere den x-Achsenausschnitt auf einen kleineren Zeitraum, beispielsweise einn beliebigen Monat. Verwende dazu lims() zusammen mit as.POSIXct() oder mache ein Subset von deinem Datensatz mit einer convenience-Variabel und filter().\n\n\n# Lösung Aufgabe 3\n\nlimits <- as.POSIXct(c(\"2002-01-01 00:00:00\",\"2002-02-01 00:00:00\"),tz = \"UTC\")\n\np +\n  lims(x = limits)\n\n\n\n\n\n@wickham2017, Kapitel 1 bzw. http://r4ds.had.co.nz/data-visualisation.html oder hier ein sehr schönes Video: Learn R: An Introduction to ggplot2↩︎\n",
    "preview": "prepro/PrePro1_Uebung_B/distill-preview.png",
    "last_modified": "2021-08-18T15:56:13+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "prepro/PrePro2_Demo_Tidyverse/",
    "title": "Demo tidyverse",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-19",
    "categories": [
      "PrePro2",
      "PrePro"
    ],
    "contents": "\n\nContents\nSplit-Apply-Combine\nPackete laden\nDaten Laden\nKennwerte berechnen\nConvenience Variablen\nKennwerte nach Gruppen berechnen\nVerketten vs. verschachteln\nResultate plotten\n\nReshaping data\nBreit -> lang\nLang -> breit\n\n\n\n\n\nDemoscript als Download\nHier möchten wir euch mit einer Sammlung von Tools vertraut machen, die spezifisch für das Daten prozessieren in Data Science entwickelt wurden. Der Prozess und das Modell ist hier1 schön beschrieben. Die Sammlung von Tools wird unter dem Namen tidyverse vertrieben, welches wir ja schon zu Beginn der ersten Übung installiert und geladen haben. Die Tools erleichtern den Umgang mit Daten ungeheuer und haben sich mittlerweile zu einem “must have” im Umgang mit Daten in R entwickelt.\nWir können Euch nicht sämtliche Möglichkeiten von tidyverse zeigen. Wir fokussieren uns deshalb auf einzelne Komponenten2 und zeigen ein paar Funktionalitäten, die wir oft verwenden und Euch ggf. noch nicht bekannt sind. Wer sich vertieft mit dem Thema auseinandersetzen möchte, der sollte sich unbedingt das Buch @wickham2017 beschaffen. Eine umfangreiche, aber nicht ganz vollständige Version gibt es online3, das vollständige eBook kann über die Bibliothek bezogen werden4.\nSplit-Apply-Combine\nPackete laden\n\n\nlibrary(tidyverse)\n\n\n\nMit library(tidyverse) werden nicht alle Packete geladen, die mit install.packages(tidyverse) intalliert wurden (warum?). Unter anderem muss lubridate noch separat geladen werden:\n\n\nlibrary(lubridate) \n\n\n\nDaten Laden\nWir laden die Wetterdaten von der letzten Übung.\n\n\nwetter <- read_table(\"order_52252_data.txt\",\n                  col_types = list(\n                    col_factor(levels = NULL),    \n                    col_datetime(format = \"%Y%m%d%H\"),\n                    col_double()\n                    )\n                  )\n\n\n\nKennwerte berechnen\nWir möchten den Mittelwert aller gemessenen Temperaturwerte berechnen. Dazu könnten wir folgenden Befehl verwenden:\n\n\nmean(wetter$tre200h0, na.rm = TRUE) \n\n\n[1] 8.962106\n\nDie Option na.rm = T bedeutet, dass NA Werte von der Berechnung ausgeschlossen werden sollen.\nMit der selben Herangehensweise können diverse Werte berechnet werden (z.B. das Maximum (max()), Minimum (min()), Median (median()) u.v.m.).\nDiese Herangehensweise funktioniert nur dann gut, wenn wir die Kennwerte über alle Beobachtungen (Zeilen) für eine Variable (Spalte) berechnen wollen. Sobald wir die Beobachtungen gruppieren wollen, wird es schwierig. Zum Beispiel, wenn wir die durchschnittliche Temperatur pro Jahr berechnen wollen.\nConvenience Variablen\nUm diese Aufgabe zu lösen, muss zuerst das “Jahr” berechne werden (das Jahr ist die convenience variabel). Hierfür brauchen wir die Funktion year() (von lubridate).\nNun kann kann die convenience Variable “Jahr” erstellt werden. Ohne dpylr wird eine neue Spalte wird folgendermassen hinzugefügt.\n\n\nwetter$year <- year(wetter$time)\n\n\n\nMit dplyr (siehe 5) sieht der gleiche Befehl folgendermassen aus:\n\n\nwetter <- mutate(wetter,year = year(time))\n\n\n\nDer grosse Vorteil von dplyr ist an dieser Stelle noch nicht ersichtlich. Dieser wird aber später klar.\nKennwerte nach Gruppen berechnen\nJetzt kann man die data.frame mithilfe der Spalte “Jahr” filtern.\n\n\nmean(wetter$tre200h0[wetter$year == 2000], na.rm = TRUE)\n\n\n[1] 9.281542\n\nDies müssen wir pro Jahr wiederholen, was natürlich sehr umständlich ist, v.a. wenn man eine Vielzahl an Gruppen hat (z.B. Kalenderwochen statt Jahre). Deshalb nutzen wir das package dplyr. Damit geht die Aufgabe (Temperaturmittel pro Jahr berechnen) folgendermassen:\n\n\nsummarise(group_by(wetter,year),temp_mittel = mean(tre200h0, na.rm = TRUE))\n\n\n# A tibble: 7 × 2\n   year temp_mittel\n  <dbl>       <dbl>\n1  2000        9.28\n2  2001        8.76\n3  2002        9.30\n4  2003        9.48\n5  2004        8.64\n6  2005        8.31\n7    NA      NaN   \n\nVerketten vs. verschachteln\nAuf Deutsch übersetzt heisst die obige Operation folgendermassen:\nnimm den Datensatz wetter\nBilde Gruppen pro Jahr (group_by(wetter,year))\nBerechne das Temperaturmittel (mean(tre200h0))\n\nDiese Übersetzung R-> Deutsch unterscheidet sich vor allem darin, dass die Operation auf Deutsch verkettet ausgesprochen wird (Operation 1->2->3) während der Computer verschachtelt liest 3(2(1)). Um R näher an die gesprochene Sprache zu bringen, kann man den %>%-Operator verwenden (siehe 6).\n\n\nsummarise(group_by(wetter,year),temp_mittel = mean(tre200h0))\n\n# wird zu:\n\nwetter %>%                                #1) nimm den Datensatz \"wetter\"\n  group_by(year) %>%                      #2) Bilde Gruppen pro Jahr\n  summarise(temp_mittel = mean(tre200h0)) #3) berechne das Temperaturmittel \n\n\n\nDieses Verketten mittels %>% macht den Code einiges schreib- und leserfreundlicher, und wir werden ihn in den nachfolgenden Übungen verwenden. Dabei handelt es sich um das package magrittr, welches mit tidyverse mitgeliefert wird.\nZu dplyr und magrittrgibt es etliche Tutorials online (siehe7), deshalb werden wir diese Tools nicht in allen Details erläutern. Nur noch folgenden wichtigen Unterschied zu zwei wichtigen Funktionen in dpylr: mutate() und summarise().\nsummarise() fasst einen Datensatz zusammen. Dabei reduziert sich die Anzahl Beobachtungen (Zeilen) auf die Anzahl Gruppen (z.B. eine zusammengefasste Beobachtung (Zeile) pro Jahr). Zudem reduziert sich die Anzahl Variablen (Spalten) auf diejenigen, die in der “summarise” Funktion spezifiziert wurde (z.B. temp_mittel).\nmit mutate wird ein data.frame vom Umfang her belassen, es werden lediglich zusätzliche Variablen (Spalten) hinzugefügt (siehe Beispiel unten).\n\n\n# Maximal und minimal Temperatur pro Kalenderwoche\nwetter %>%                              #1) nimm den Datensatz \"wetter\"\n  filter(stn == \"ABO\") %>%              #2) filter auf Station namnes \"ABO\"\n  mutate(kw = week(time)) %>%       #3) erstelle eine neue Spalte \"kw\"\n  group_by(kw) %>%                      #4) Nutze die neue Spalte um Guppen zu bilden\n  summarise(\n    temp_max = max(tre200h0, na.rm = TRUE),#5) Berechne das Maximum \n    temp_min = min(tre200h0, na.rm = TRUE) #6) Berechne das Minimum\n    )   \n\n\n# A tibble: 53 × 3\n      kw temp_max temp_min\n   <dbl>    <dbl>    <dbl>\n 1     1     11.4    -15.2\n 2     2     12.9    -15.9\n 3     3      8.2    -11.3\n 4     4      9.6    -15.9\n 5     5     16.9    -17.5\n 6     6     13.5    -13.1\n 7     7     12.9    -15.4\n 8     8     11      -14.4\n 9     9     12.9    -17.6\n10    10     15.4    -16.3\n# … with 43 more rows\n\nResultate plotten\nMit diesen Tools können wir nun auch eine neue Grafik plotten, ähnlich wie in der Übung 1. Dafür müssen wir die ganzen Operationen aber zuerst in einer Variabel speichern (bis jetzt hat R zwar alles schön berechnet, aber uns nur auf die Konsole ausgegeben).\n\n\nwetter_sry <- wetter %>%                              \n  mutate(\n    kw = week(time)\n    ) %>%\n  filter(stn == \"ABO\") %>%\n  group_by(kw) %>%                      \n  summarise(\n    temp_max = max(tre200h0),               \n    temp_min = min(tre200h0),\n    temp_mean = mean(tre200h0)\n    )  \n\n\n\nDieses Mal plotten wir nur mit ggplot2 (siehe 8)\n\n\nggplot() +\n  geom_line(data = wetter_sry, aes(kw,temp_max), colour = \"yellow\") +\n  geom_line(data = wetter_sry, aes(kw,temp_mean), colour = \"pink\") +\n  geom_line(data = wetter_sry, aes(kw,temp_min), colour = \"black\") +\n  labs(y = \"temp\")\n\n\n\n\nDas sieht schon mal gut aus. Nur, wir mussten pro Linie einen eigene Zeile schreiben (geom_line()) und dieser eine Farbe zuweisen. Bei drei Werten ist das ja ok, aber wie sieht es denn aus wenn es Hunderte sind? Da hat ggplot natürlich eine Lösung, dafür müssen aber alle Werte in einer Spalte daher kommen. Das ist ein häufiges Problem: Wir haben eine breite Tabelle (viele Spalten), bräuchten aber eine lange Tabelle (viele Zeilen).\nReshaping data\nBreit -> lang\nDa kommt tidyverse wieder ins Spiel. Die Umformung von Tabellen breit->lang erfolgt mittels tidyr(siehe 9). Auch dieses package funktioniert wunderbar mit piping (%>%).\n\n\nwetter_sry %>%\n  pivot_longer(c(temp_max,temp_min,temp_mean))\n\n\n# A tibble: 159 × 3\n      kw name       value\n   <dbl> <chr>      <dbl>\n 1     1 temp_max   11.4 \n 2     1 temp_min  -15.2 \n 3     1 temp_mean  -1.26\n 4     2 temp_max   12.9 \n 5     2 temp_min  -15.9 \n 6     2 temp_mean  -1.56\n 7     3 temp_max    8.2 \n 8     3 temp_min  -11.3 \n 9     3 temp_mean  -1.88\n10     4 temp_max    9.6 \n# … with 149 more rows\n\nIm Befehl pivot_longer() müssen wir festlegen, welche Spalten zusammengefasst werden sollen (hier: temp_max,temp_min,temp_mean). Alternativ (und in diesem Fall auch einfacher), können wir angeben, welche Spalten wir nicht zusammenfassen wollen:\n\n\nwetter_sry %>%\n  pivot_longer(-kw)\n\n\n# A tibble: 159 × 3\n      kw name       value\n   <dbl> <chr>      <dbl>\n 1     1 temp_max   11.4 \n 2     1 temp_min  -15.2 \n 3     1 temp_mean  -1.26\n 4     2 temp_max   12.9 \n 5     2 temp_min  -15.9 \n 6     2 temp_mean  -1.56\n 7     3 temp_max    8.2 \n 8     3 temp_min  -11.3 \n 9     3 temp_mean  -1.88\n10     4 temp_max    9.6 \n# … with 149 more rows\n\nWenn wir die Namen neuen Spalten festlegen wollen (anstelle von name und value) erreichen wir dies mit names_to bzw. values_to:\n\n\nwetter_sry_long <- wetter_sry %>%\n  pivot_longer(-kw, names_to = \"Messtyp\", values_to = \"Messwert\")\n\n\n\nDie ersten 6 Zeilen von wetter_sry_long:\n\nkw\nMesstyp\nMesswert\n1\ntemp_max\n11.400000\n1\ntemp_min\n-15.200000\n1\ntemp_mean\n-1.259325\n2\ntemp_max\n12.900000\n2\ntemp_min\n-15.900000\n2\ntemp_mean\n-1.557242\n\nDie ersten 6 Zeilen von wetter_sry:\n\nkw\ntemp_max\ntemp_min\ntemp_mean\n1\n11.4\n-15.2\n-1.2593254\n2\n12.9\n-15.9\n-1.5572421\n3\n8.2\n-11.3\n-1.8832341\n4\n9.6\n-15.9\n-2.8375000\n5\n16.9\n-17.5\n-0.9789683\n6\n13.5\n-13.1\n0.4392857\n\nBeachte: wetter_sry_long umfasst 159 Beobachtungen (Zeilen), das sind 3 mal soviel wie wetter_sry, da wir ja drei Spalten zusammengefasst haben.\n\n\nnrow(wetter_sry)\n\n\n[1] 53\n\nnrow(wetter_sry_long)\n\n\n[1] 159\n\n\n\nggplot(wetter_sry_long, aes(kw,Messwert, colour = Messtyp)) +\n  geom_line()\n\n\n\n\nBeachtet, dass wir gegenüber dem letzten Plot colour nun innerhalb von aes() festlegen und nicht mit einem expliziten Farbwert, sondern mit dem Verweis auf die Spalte key.\nLang -> breit\nDas Gegenstück zu pivot_longer ist pivot_wider. Mit dieser Funktion können wir eine lange Tabelle in eine breite überführen. Dazu müssen wir in names_from angeben, aus welcher Spalte die neuen Spaltennamen erstellt werden sollen (names_from) und aus welcher Spalte die Werte entstammen sollen (values_from):\n\n\nwetter_sry_long %>%\n  pivot_wider(names_from = Messtyp, values_from = Messwert)\n\n\n# A tibble: 53 × 4\n      kw temp_max temp_min temp_mean\n   <dbl>    <dbl>    <dbl>     <dbl>\n 1     1     11.4    -15.2    -1.26 \n 2     2     12.9    -15.9    -1.56 \n 3     3      8.2    -11.3    -1.88 \n 4     4      9.6    -15.9    -2.84 \n 5     5     16.9    -17.5    -0.979\n 6     6     13.5    -13.1     0.439\n 7     7     12.9    -15.4    -2.32 \n 8     8     11      -14.4    -2.84 \n 9     9     12.9    -17.6    -2.20 \n10    10     15.4    -16.3     0.917\n# … with 43 more rows\n\n\nhttp://r4ds.had.co.nz/introduction.html#↩︎\ndplyr, ggplot2, tidyr, stringr, magrittr, lubridate↩︎\nhttp://r4ds.had.co.nz/↩︎\nhttps://ebookcentral.proquest.com/lib/zhaw/detail.action?docID=4770093↩︎\n@wickham2017, Kapitel 10 / http://r4ds.had.co.nz/transform.html↩︎\n@wickham2017, Kapitel 14 / http://r4ds.had.co.nz/pipes.html↩︎\n@wickham2017, Kapitel 10 / http://r4ds.had.co.nz/transform.html, oder Hands-on dplyr tutorial..↩︎\n@wickham2017, Kapitel 1 / http://r4ds.had.co.nz/data-visualisation.html oder hier ein sehr schönes Video: Learn R: An Introduction to ggplot2↩︎\nhttps://r4ds.had.co.nz/tidy-data.html#pivoting↩︎\n",
    "preview": "prepro/PrePro2_Demo_Tidyverse/distill-preview.png",
    "last_modified": "2021-08-19T11:41:43+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "prepro/PrePro2_Uebung_A/",
    "title": "Uebung A",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-18",
    "categories": [
      "PrePro2",
      "PrePro"
    ],
    "contents": "\n\n\n\nAufgabe 1\nLade die Wetterdaten aus der letzten Übung.\nAufgabe 2\nBereinige den Datensatz. Entferne z.B. alle Zeilen, bei dem der Stationsnahme oder Temperaturwerte fehlen\nAufgabe 3\nÜberführe die lange Tabelle über in eine breite. Dabei sollte jede Station eine eigene Spalte enthalten (names_from), gefüllt mit den Temperaturwerten (values_from). Speichere diese Tabelle in einer neuen Variabel.\nAufgabe 4\nImportiere die Datei order_52252_legend.csv (z.B. mit read_delim).\nHinweis: Wenn Umlaute und Sonderzeichen nicht korrekt dargestellt werden (z.B. in Genève), hat das vermutlich mit der Zeichencodierung zu tun. Das File ist aktuell in ‘ANSI’ Codiert, welche für gewisse Betriebssysteme / R-Versionen ein Problem darstellt. Um das Problem zu umgehen muss man das File mit einem Editor öffnen (Windows ‘Editor’ oder ‘Notepad++’, Mac: ‘TextEdit’) und mit einer neuen Codierung (z.B ‘UTF-8’) abspeichern. Danach kann die Codierung spezifitiert werden (bei read_delim(): mitlocale = locale(encoding = “UTF-8”)`)\nAufgabe 5\nDie x-/y-Koordinaten sind aktuell in einer Spalte erfasst. Um mit den Koordinaten sinnvoll arbeiten zu können, brauchen wir die Koordinaten getrennt. Trenne die x und y Koordinaten aus der Spalte Koordinaten (Tipp: nutze dafür tidyr::separate()).\nAufgabe 6\nNun wollen wir den Datensatz wettermit den Informationen aus wetter_legendeanreichern. Uns interessiert aber nur das Stationskürzel, der Name, die x/y Koordinaten sowie die Meereshöhe. Lösche die nicht benötigten Spalten (oder selektiere die benötigten Spalten).\nTipp: Nutze select() von dplyr\nAufgabe 7\nNun ist der Datensatz wetter_legendegenügend vorbereitet. Jetzt kann er mit dem Datensatz wetter verbunden werden. Überlege dir, welcher Join dafür sinnvoll ist und mit welchem Attribut wir “joinen” können.\nNutze die Join-Möglichkeiten von dplyr (Hilfe via ?dplyr::join) um die Datensätze wetter und wetter_legendezu verbinden.\nAufgabe 8\nBerechne die Durchschnittstemperatur pro Station. Nutze dabei dplyr::summarise() und wenn möglich %>%. Speichere das Resultat in einer neuen Variabel.\nAufgabe 9\nNun wollen wir das Resultat aus Aufgabe 7 nutzen, um die Durchschnittstemperatur der Meereshöhe gegenüber zu stellen. Dummerweise ging das Attribut Meereshoehe bei der summarise() Operation verloren (da bei summarise() alle Spalten weg fallen, die nicht in group_by() definiert wurden). Um die Spalte Meereshoehe beizubehalten, muss sie also unter group_by() aufgelistet werden.\nWiederhole Übung 7 und siehe zu, dass die Meereshöhe beibehalten wird. Stelle danach in einem Scatterplot (wenn möglich mit ggplot()) die Meereshöhe der Durchschnittstemperatur gegenüber.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-18T15:56:36+02:00",
    "input_file": {}
  },
  {
    "path": "prepro/PrePro2_Uebung_B/",
    "title": "Übung B",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-08-19",
    "categories": [
      "PrePro2",
      "PrePro"
    ],
    "contents": "\n\nContents\nAufgabe 1\nAufgabe 2\nAufgabe 3\nAufgabe 4\n\n\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(stringr)\n\n\n\nAufgabe 1\nGegeben sind die Daten von drei Sensoren (sensor1.csv, sensor2.csv, sensor3.csv). Lade die Datensätze runter und lese sie ein.\n\n\n# Lösung Aufgabe 1\n\nsensor1 <- read_delim(\"sensor1.csv\",\";\")\nsensor2 <- read_delim(\"sensor2.csv\",\";\")\nsensor3 <- read_delim(\"sensor3.csv\",\";\")\n\n\n\nAufgabe 2\nErstelle aus den 3 Dataframes eine einzige Dataframe, die aussieht wie unten dargestellt. Dafür musst du:\njedem Dataframe eine neue Spalte “Sensor” hinzufügen wo der jeweilige Sensor vermerkt ist\ndie drei Dataframes zu einer mittels rbind() zusammenführen\ndie Spalte Datetime in ein POSIXct-Format konvertiren (das ursprüngliche Format lautet:DDMMYYYY_HHMM)\ndie Tabelle von long zu wide mittels pivot_wider überführen\n\n\n# Lösung Aufgabe 2\n\nsensor1$sensor <- \"sensor1\"\nsensor2$sensor <- \"sensor2\"\nsensor3$sensor <- \"sensor3\"\n\nsensor_all <- rbind(sensor1,sensor2,sensor3)\n\nsensor_all <- sensor_all %>%\n  mutate(\n    Datetime = as.POSIXct(Datetime,format = \"%d%m%Y_%H%M\")\n  ) %>%\n  pivot_wider(names_from = sensor, values_from = Temp)\n\n\n\n\nDatetime\nsensor1\nsensor2\nsensor3\n2017-10-16 18:00:00\n23.5\n13.5\n26.5\n2017-10-17 18:00:00\n25.4\n24.4\n24.4\n2017-10-18 18:00:00\n12.4\n22.4\n13.4\n2017-10-19 18:00:00\n5.4\n12.4\n7.4\n2017-10-23 18:00:00\n23.5\n13.5\nNA\n2017-10-24 18:00:00\n21.3\n11.3\nNA\n2017-10-25 18:00:00\n12.4\n22.4\n15.4\n2017-10-26 18:00:00\n13.5\n13.5\n16.5\n2017-10-27 18:00:00\n5.4\n5.4\n7.4\n2017-10-28 18:00:00\n4.4\n4.4\n4.4\n2017-10-29 18:00:00\nNA\n4.2\nNA\n2017-10-30 18:00:00\nNA\n5.4\nNA\n2017-10-31 18:00:00\nNA\n12.4\nNA\n2017-11-01 18:00:00\nNA\n14.4\nNA\n2017-11-02 18:00:00\nNA\n7.4\nNA\n2017-11-03 18:00:00\nNA\n4.8\nNA\n\nAufgabe 3\nImportiere die Datei sensor_1_fail.csv in R.\n\n\n# Lösung Aufgabe 3\n\nsensor_fail <- read_delim(\"sensor_fail.csv\", delim = \";\")\n\n\n\n\nSensor\nTemp\nHum_%\nDatetime\nSensorStatus\nSen102\n0.6\n98\n16102017_1800\n1\nSen102\n0.3\n96\n17102017_1800\n1\nSen102\n0.0\n87\n18102017_1800\n1\nSen102\n0.0\n86\n19102017_1800\n0\nSen102\n0.0\n98\n23102017_1800\n0\nSen102\n0.0\n98\n24102017_1800\n0\nSen102\n0.0\n96\n25102017_1800\n1\nSen103\n-0.3\n87\n26102017_1800\n1\nSen103\n-0.7\n98\n27102017_1800\n1\nSen103\n-1.2\n98\n28102017_1800\n1\n\nsensor_fail.csv hat eine Variabel SensorStatus: 1 bedeutet der Sensor misst, 0 bedeutet der Sensor miss nicht. Fälschlicherweise wurde auch dann der Messwert Temp = 0 erfasst, wenn Sensorstatus = 0. Richtig wäre hier NA (not available). Korrigiere den Datensatz entsprechend.\n\n\n# Lösungsweg 1\nsensor_fail$Datetime <- as.POSIXct(sensor_fail$Datetime,format = \"%d%m%Y_%H%M\")\n\nsensor_fail$`Hum_%`[sensor_fail$SensorStatus == 0] <- NA\nsensor_fail$Temp[sensor_fail$SensorStatus == 0] <- NA\n\n\n\nAufgabe 4\nWarum spielt das es eine Rolle, ob 0 oder NA erfasst wird? Berechne die Mittlere der Temperatur / Feuchtigkeit nach der Korrektur.\n\n\n# Lösung Aufgabe 4\n\n# Mittelwerte der korrigierten Sensordaten: mit na.rm = TRUE werden NA-Werte aus der Berechnung entfernt. \n# Ansonsten würden sie als 0 in die Berechnung einfliessen und diese verfälschen.\nmean(sensor_fail$Temp, na.rm = TRUE)\n\n\n[1] -0.1857143\n\nmean(sensor_fail$`Hum_%`, na.rm = TRUE)\n\n\n[1] 94.28571\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-19T12:24:05+02:00",
    "input_file": {}
  }
]
