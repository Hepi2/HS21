[
  {
    "path": "fallstudien/BE_N_0_Vorbemerkung/",
    "title": "Vorbemerkung Fallstudie WPZ - Profil N",
    "description": {},
    "author": [
      {
        "name": "Beni Sigrist",
        "url": {}
      }
    ],
    "date": "2021-10-11",
    "categories": [
      "Biodiversity & Ecosystems (N)"
    ],
    "contents": "\nAktuell dient diese Plattform für die BiEc Fallstudie - Profil N einzig der Bereitstellung von Aufgaben die von euch im Rahmen dieses Fallstudienprojekts erarbeitet werden sollen. Die Aufgaben werden in den meisten Fällen mit Code-Beispielen erläutert oder benötigten Code-snippets resp. Funktionen werden mitgeliefert. Im Laufe des Semesters werden hier ausserdem häppchenweise (mögliche) Lösungen zu den Aufgaben aufgeschaltet. Alles grundlegende Material und alle Unterlagen zu den theoretischen Inputs sind weiterhin und ausschliesslich im Moodlekurs Research Methods - Fallstudie BiEc zu finden. Die für die Aufgaben benötigten Datengrundlagen sind ebenfalls im entsprechenden Abschnitt auf Moodle zu finden. Frohes Schaffen!\n\n\n\n\n\n\n",
    "preview": "fallstudien/BE_N_0_Vorbemerkung/Reh_graf.jpg",
    "last_modified": "2021-10-11T09:58:27+02:00",
    "input_file": {}
  },
  {
    "path": "fallstudien/BE_N_1_Aufgabe3_Datenverarbeitung/",
    "title": "KW42: Daten(vor)verarbeitung Fallstudie WPZ - Profil N",
    "description": {},
    "author": [
      {
        "name": "Beni Sigrist",
        "url": {}
      }
    ],
    "date": "2021-10-14",
    "categories": [
      "Biodiversity & Ecosystems (N)"
    ],
    "contents": "\nProjektaufbau RStudio-Projekte\nVor den eigentlichen Auswertungen muessen einige vorbereitende Arbeiten unternommen werden. Die Zeit, die man hier investiert, wird in der spaeteren Projektphase um ein vielfaches eingespart. Im Skript soll die Ordnerstruktur des Projekts genannt werden, damit der Arbeitsvorgang auf verschiedenen Rechnern reproduzierbar ist.\nArbeitet mit Projekten, da diese sehr einfach ausgetauscht und somit auch reproduziert werden koennen; es gibt keine absoluten Arbeitspfade sondern nur relative. Der Datenimport (und auch der Export) kann mithilfe dieser relativen Pfaden stark vereinfacht werden. Projekte helfen alles am richtigen Ort zu behalten. (mehr zur Arbeit mit Projekten: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects)\nAufbau von R-Skripten\nIm Kopf des Skripts zuerst immer den Titel des Projekts sowie die Autor:innen des Skripts nennen. Hier soll auch die Herkunft der Daten ersichtlich sein und falls externe Daten verwendet werden, sollte geklaert werden, wer die Datenherrschaft hat (Rehdaten: Forschungsgruppe WILMA).\n\n\n#.##################################################################################\n# Daten(vor)verarbeitung Fallstudie WPZ  ####\n# Modul Research Methods, HS21. Autor/in ####\n#.##################################################################################\n\n# Beschreibt zudem folgendes:\n# • Ordnerstruktur (ich verwende hier den Projektordner mit den Unterordnern Skripts, \n# Feldaufnahmen, Data, Results, Plots)\n# • Verwendete Daten\n\n# Ein Skript soll in R eigentlich immer nach dem selbem Schema aufgebaut sein. \n# Dieses Schema beinhaltet (nach dem bereits erwaehnten Kopf des Skripts) 4 Kapitel: \n\n\n\n1. Datenimport\n2. Datenvorverarbeitung\n3. Analyse\n4. Visualisierung\nBereitet euer Skript also nach dieser Struktur vor. Nutzt fuer den Text, welcher nicht Code ist, vor dem Text das Symbol #. Wenn ihr den Text als Titel definieren wollt, der die grobe Struktur des Skripts absteckt, baut in wie in folgendem Beispiel auf:\n\n\n#.###################################################################################\n# METADATA ####\n#.###################################################################################\n# Datenherkunft ####\n# ...\n\n#.###################################################################################\n# 1. DATENIMPORT ####\n#.###################################################################################\n\n\n\nlibraries laden: hier tidyverse\n\n\nlibrary(tidyverse)\n\n\n\nHerunterladen der Daten der Feldaufnahmen von Moodle (Aufgabe3_Feldaufnahmen_alle_Gruppen.zip), Einlesen, Sichtung der Datensaetze und der Datentypen\n\n\n# Die Datensätze aller Teams müssen erst noch in CSVs umgewandelt werden, bevor sie \n# eingelesen werden können \n\ndf_team1 <- read_delim(\"Felderhebung Waldstruktur_TEAM_1_türkis.csv\", \n                       delim = \";\")\n\ndf_team2 <- read_delim(\"Felderhebung_Team_2.csv\", delim = \";\")\n# Achtung! Beim Datensatz des Teams 2 ist eine zusaetzliche Zeile eingefuegt, die\n# das Einlesen erschwert.\n# Ausserdem gibt es bei den Zeilen DG Rubus, DG Strauchschicht und DG Baumschicht ein  \n# Problem mit dem Datentyp resp. den Zahlen.\n\ndf_team3 <- read_delim(\"ReMe_Felderhebung_Gruppe3.csv\", delim = \";\")\n# Achtung! Hier ist beim Einlesen etwas falsch gelaufen. \n\ndf_team4 <- read_delim(\"Felderhebung_Waldstruktur_Team_4.csv\", \n                       delim = \";\")\n\ndf_team5 <- read_delim(\"Felderhebung_Waldstruktur_Team5.csv\", \n                       delim = \";\")\n# Achtung! Beim Umwandeln in das CSV muss hier die Titelzeile entfernt werden damit\n# das Einlesen reibungslos funktioniert\n\ndf_team6 <- read_delim(\"Aufnahmen_Landforst_HS21_Gruppe_6.csv\", \n                       delim = \";\")\n\n\n# hier koennen die Probekreise mit den Angaben zur Anzahl Rehlokalisationen und der \n# LIDAR-basierten Ableitung der Waldstruktur eingelesen werden\n\ndf_reh <- read_delim(\"Aufgabe3_Reh_Waldstruktur_211014.csv\", delim = \";\")\nstr(df_reh)\n\n\n# Die eingelesenen Datensaetze anschauen und versuchen zu einem Gesamtdatensatz  \n# verbinden. Ist der Output zufriedenstellend?\n\ndf_gesamt <- bind_rows(df_team1, df_team2, df_team3, df_team4, df_team5, df_team6)\nstr(df_gesamt)\n\n\n\nAufgabe 1:\n1.1 Einfuegen zusaetzliche Spalte pro Datensatz mit der Gruppenzugehoerigkeit (Team1-6)\n1.2 Spaltenumbenennung damit die Bezeichungen in allen Datensaetzen gleich sind und der Gesamtdatensatz zusammengefuegt werden kann\n–> Befehle mutate und rename, mit pipes (%>%) in einem Schritt moeglich\nAufgabe 2:\nZusammenfuehren der Teildatensaetze zu einem Datensatz\nAufgabe 3:\nVerbinden (join) des Datensatzes der Felderhebungen mit dem Datensatz der Rehe.\nZiel: ein Datensatz mit allen Kreisen der Felderhebung, angereichert mit den Umweltvariablen Understory und Overstory aus den LIDAR-Daten (DG_us, DG_os) aus dem Rehdatensatz.\n–> Welche Art von join? Welche Spalten zum Verbinden (by = ?) der Datensaetze\nAufgabe 4:\nScatterplot der korrespondondierenden Umweltvariablen aus den Felderhebungen gegen die Umweltvariablen aus den LIDAR-Daten erstellen (zusaetzlich Einfaerben der Gruppen und Regressionslinie darueberlegen).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-14T15:50:51+02:00",
    "input_file": {}
  },
  {
    "path": "fallstudien/BE_N_2_Aufgabe3_Berechnung_Homeranges/",
    "title": "KW43: Homeranges Fallstudie WPZ - Profil N",
    "description": {},
    "author": [
      {
        "name": "Beni Sigrist",
        "url": {}
      }
    ],
    "date": "2021-10-14",
    "categories": [
      "Biodiversity & Ecosystems (N)"
    ],
    "contents": "\nR-Skript zur Berechung der Home-Ranges der Rehe\nBenötigte Libraries laden\n\n\nipak <- function(pkg){\nnew.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\nif (length(new.pkg))\ninstall.packages(new.pkg, dependencies = TRUE)\nsapply(pkg, require, character.only = TRUE)\n}\npackages <- c(\"sf\", \"raster\", \"tidyverse\", \"adehabitatHR\", \"maptools\", \"sp\", \n              \"ggspatial\", \"rgeos\", \"rgdal\")\nipak(packages)\n\n\n\nEinlesen des Gesamtdatensatzes von Moodle, Sichtung des Datensatzes und der Datentypen\n\n\nRehe <- read_delim(\"Aufgabe3_Homeranges_Rehe_landforst_20211014.csv\", delim = \";\")\n\nstr(Rehe)\n\n\n\nAufgabe 1: In Datensatz Rehe eine neue Spalte mit Datum und Zeit in einer Spalte kreieren. Beim Format hat sich ein Fehler eingeschlichen. Findet ihr ihn?\n\n\nRehe <- Rehe %>%\n  mutate(UTC_DateTime = as.POSIXct(paste(UTC_Date, UTC_Time), \n                                   format = \"%Y-%m-%d %H:%M:%S\"))\n\n\n\nHier einige Zeilen Code, um eine HomeRange zu berechnen.\nAufgabe 2: Herumschrauben an den Einstellungen von:\n- href (in der Funktion kernelUD)\n- an der Ausdehung, resp. prozentualer Anteil Punkte in der HR (Funktion getverticeshr)\n–> Ziel: eine Karte erstellen mit der Visualiserung mindestens einer HR\n\n\nx <- Rehe$X[Rehe$TierID== \"RE13\"]    \ny <- Rehe$Y[Rehe$TierID== \"RE13\"]\nxy <- data.frame(cbind (x, y, rep(1, length(x))))       \ncoordinates(xy)<-c(\"x\",\"y\")                             \nproj4string(xy)<-CRS(\"+init=epsg:21781\")  \n\nplot(xy, col = \"blue\", pch = 19, cex = 1.5)\n\n# Berechnung von href nach: Pebsworth et al. (2012) Evaluating home range techniques: \n# use of Global Positioning System (GPS) collar data from chacma baboons\n\nsigma <- 0.5*(sd(x)+sd(y))                              \nn <- length(x)\nhref <- sigma * n^(-1/6)*0.9  \n\n# scaled reference: href * 0.9\n\nkud <- kernelUD(xy, h=href, grid=25)             \n\n# Berechnung der Home Range (95% Isopleth)\n\nhomerange <- getverticeshr(kud, percent=95)             \n\n\n# Schreibt HR in den oben beschriebenen Ordner (als Shapefile)\n\nhr <- st_as_sf(homerange)\n\nst_write(hr, dsn= \"Results\", layer=\"HR_RE13\", driver=\"ESRI Shapefile\",  \n         delete_layer = T )\n\n\n\n\n\n# mit diesem Befehl kann die HR geplottet werden\n\n\nggplot(hr, aes(color = \"red\", fill=\"red\")) + \n  geom_sf(size = 1, alpha = 0.3) +\ncoord_sf(datum = sf::st_crs(21781))+\ntheme(\naxis.title = element_blank(),\naxis.text = element_blank(),\naxis.ticks = element_blank(),\nlegend.position=\"none\"\n)\n\n# und die Punkte der GPS-Lokalisationen darüber gelegt werden \n\nxy_p <- st_as_sf(xy)\n\nggplot(hr, aes(color = \"red\", fill=\"red\")) + \n  geom_sf(size = 1, alpha = 0.3) +\ngeom_sf(data = xy_p, aes(fill = \"red\")) +\ncoord_sf(datum = sf::st_crs(21781))+\ntheme(\naxis.title = element_blank(),\naxis.text = element_blank(),\naxis.ticks = element_blank(),\nlegend.position=\"none\"\n)\n\n\n\nCode um die Homerange auf der Landeskarte 1:25000 zu plotten. Transparenz kann mit alpha angepasst werden\n\n\npk25_wpz <- brick(\"C:/Users/sigb/Beni/WPZ_Fallstudie/HS20/Data/pk25_wpz.tif\")\n\nxy_p <- st_as_sf(xy)\n\nggplot(hr, aes(color = \"red\", fill=\"red\")) +\nannotation_spatial(pk25_wpz) +\ngeom_sf(size = 1, alpha = 0.3) +\ngeom_sf(data = xy_p, aes(fill = \"red\")) +\ncoord_sf(datum = sf::st_crs(21781))+\ntheme(\naxis.title = element_blank(),\naxis.text = element_blank(),\naxis.ticks = element_blank(),\nlegend.position=\"none\"\n)\n\n\n\nErstellen des Sampling Grids mit den Kreisen (Wird als Grundlage für Extraktion der Umweltvariablen innerhalb der Homeranges benötigt)\nXmin bzw. Ymin des Grids: c(684000, 234000)\ncellsize des Grids: c(25, 25)\nAnzahl Kreise in X und Y Richtung: c(100, 160)\n\n\nx25       <- GridTopology(c(684000, 234000), c(25, 25), c(100, 160)) \ndata25    = data.frame(1:(100*160))           \n# Erstellt aus der GridTopology und den Daten ein SpatialGridDataFrame\ngrid25    <- SpatialGridDataFrame(x25, data25,  proj4string <- CRS(\"+init=epsg:21781\"))\npixel25   <- as(grid25, \"SpatialPixelsDataFrame\")\n\n\n# zweites Sampling Grid für einen Ausschnitt aufbauen, plotten\n# -> dient nur der Visualisierung des Sampling Grids um einen Eindruck zu erhalten\n\nx       <- GridTopology(c(684200, 236900), c(25, 25), c(35, 35)) \ndata    = data.frame(1:(35*35))           \n# Erstellt aus der GridTopology und den Daten ein SpatialGridDataFrame\ngrid    <- SpatialGridDataFrame(x, data,  proj4string <- CRS(\"+init=epsg:21781\"))\npixel  <- as(grid, \"SpatialPixelsDataFrame\")\n\npoints <- as(pixel, \"SpatialPointsDataFrame\")\n\ngrid_plot <- st_buffer(st_as_sf(points), 12.5)\n\nplot(st_geometry(grid_plot))\n\nggplot(grid_plot, color = \"black\", fill=NA) + \n  geom_sf() +\ngeom_sf(data = xy_p, color = \"blue\",  ) +\n  geom_sf(data = hr, color = \"red\", fill = NA, size = 2) +\ncoord_sf(datum = sf::st_crs(21781))+\ntheme(\naxis.title = element_blank(),\naxis.text = element_blank(),\naxis.ticks = element_blank(),\nlegend.position=\"none\"\n)\n\n\n\nAufgabe 3: Testen der Variablen der Vegetationsschichten von letzter Woche auf einen linearen Zusammenhang (Korrelation; Funktion cor.test). DG_Baumschicht vs. DG_os / DG_Strauchschicht vs. DG_us aus dem Datensatz df_with_lidar den wir letzte Woche erstellt haben\nDie Theorie zu Korrelation folgt erst ab 1.11\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-14T15:50:51+02:00",
    "input_file": {}
  },
  {
    "path": "fallstudien/BE_S_1_Einleitung/",
    "title": "KW40: Einführung",
    "description": {},
    "author": [
      {
        "name": "Adrian Hochreutener",
        "url": {}
      }
    ],
    "date": "2021-09-27",
    "categories": [
      "Biodiversity & Ecosystems (S)"
    ],
    "contents": "\nEinleitung\nHintergrund\nDas rund 1100 ha grosse Naturschutzgebiet Wildnispark Zürich Sihlwald, welches im periurbanen Raum südlich von Zürich liegt, gilt seit dem 1. Januar 2010 als erster national anerkannter Naturerlebnispark. Er ist Teil des Wildnisparks Zürich. Seine Rolle als Naherholungsgebiet für die Stadt Zürich ist von grosser Bedeutung.\nIm Perimeter gelten verschiedene Regeln. So darf z. B. nur auf bestimmten Wegen mit den Velo gefahren und Hunde müssen an der Leine geführt werden. Damit soll im Schutzgebiet die Balance zwischen Schutz und Nutzen bewahrt werden, denn einerseits sollen die Besuchenden den Wald erleben dürfen, andererseits soll sich dieser, in der Kernzone, frei entwicklen dürfen.\n\n\n\nDamit diese Balance erreicht werden kann, muss das Management auf solide, empirisch erhobene Daten zur Natur und zu den Besuchenden zurückgreifen können. Das Besuchermonitoring deckt den zweiten Teil dieser notwendigen Daten ab.\nIm Wildnispark Zürich sind dazu mehrere automatische Zählstellen in Betrieb. Die Zählstellen erfassen stundenweise Besuchende. Einige Zählstellen erfassen richtungsgetrennt und / oder können zwischen verschiedenen Nutzergruppen wie Personen, die zu Fuss gehen, und Velofahrenden unterscheiden.\nIm Rahmen des Moduls Research Methods werden in der Fallstudie Profil S mehrere dieser automatischen Zählstellen genauer untersucht. Die Daten, welche im Besitz des WPZ sind, wurden bereits kalibriert. Das heisst, Zählungen während Wartungsarbeiten, bei Felhbetrieb o.ä. wurden bereits ausgeschlossen. Dies ist eine Zeitintensive Arbeit und wir dürfen hier mit einem wahren, sauber aufbereiteten “Datenschatz” arbeiten.\nPerimeter des Wildnispark Zürichs mit den ungefähren Standorten von drei ausgewählten automatischen Zählstellen.\n\n\n\n\nHinweis:\nDie Zähler 211 und 502 erfassen sowohl Fussgänger:innen als auch Fahrräder. Die Erfassung erfolgt Richtungsgetrennt.\nDer Zähler 204 kann nicht zwischen Nutzungsarten unterscheiden; er erfasst alle Passagen auf den Hochwachtturm als Fussgänger:innen. Der Sensror hat keine Richtungserkennung und die Besuchenden werden jeweils 2x gezählt, einmal beim Aufstieg und einmal beim Abstieg. Das ist im Kalibrierunsgfaktor berücksichtigt, die Kalibrierte Zahl gibt also die Anzahl der Turmbesuche an.\nDer Wildnispark wertet die Zahlen auf verschiedene Weise aus. So sind z. B. Jahresgänge (an welchen Monaten herrscht besonders viel Betrieb) und Nutzungszahlen bekannt. Vertiefte Auswertungen, die beispielsweise den Zusammenhang zwischen Besuchszahlen und dem Wetter untersuchen, werden nicht gemacht, da dies die Kapazitäten übersteigen würde.\nUnsere Analysen in diesem Modul helfen dem Management, ein besseres Verständnis zum Verhalten der Besuchenden zu erlangen und bilden Grundlagen für Managemententscheide in der Praxis.\nZiele\nIn dieser Fallstudie zeigen wir, welche Einfluss der Lockdown während der Covid19-Pandemie im Frühjahr 2020 sowie jener im Winter 2020/2021 auf die täglichen Besuchszahlen im Wildnispark Zürich hatte.\nErgänzend beschreiben wir den Zusammenhang der Besuchszahlen mit verschiedenen Wetterparametern. Die Hypothese lautet, je mehr Sonnenstunden und je höher die Temperatur, desto mehr Besuchende sind im Untersuchungsgebiet unterwegs; je mehr Niederschlag gemessen wird, desto weniger Besuchende werden gezählt.\nDa neben dem Wetter aber auch saisonale Muster, wie z.B. Schulferien, einen grossen Einfluss auf Besuchszahlen haben können, ziehen wir diese und weitere Parameter (Wochentage, Kalenderwoche, Jahr) ebenfalls in die Auswertung ein.\nDiese kombinierte, statistisch schliesssende, Betrachtung erlaubt uns Aussagen darüber, ob “nur” aufgrund des schönen Frühlings 2021 mehr Menschen in Wald unterwegs waren, oder ob der Lockdown tatsächlich einen so deutlich positiven Einfluss auf die Besuche hatte.\nGrundlagen\nZur Verfügung stehen:\ndie stündlichen, richtungsgetrennten Zählungen von Fussgänger:innen und Velos an drei Zählstellen\nMeteodaten (Temperatur, Sonnenscheindauer, Niederschlagssumme)\nR-Skripte mit Hinweisen zur Auswertung\n\n\n\n",
    "preview": "fallstudien/BE_S_1_Einleitung/Perimeter.png",
    "last_modified": "2021-09-27T12:07:48+02:00",
    "input_file": {},
    "preview_width": 2001,
    "preview_height": 1051
  },
  {
    "path": "fallstudien/BE_S_2_Felderhebung/",
    "title": "KW40 - KW42: Aufgabe Felderhebung Grüntal",
    "description": {},
    "author": [
      {
        "name": "Adrian Hochreutener",
        "url": {}
      }
    ],
    "date": "2021-10-18",
    "categories": [
      "Biodiversity & Ecosystems (S)"
    ],
    "contents": "\nEinführung und Installation\nEs gibt eine Vielzahl an möglichen Methoden zur Erfassung der Besucherzahlen. Automatische Zählgeräte bieten die Möglichkeit lange und durchgehende Zeitreihen zu erfassen. Diese müssen aber natürlich auch ausgewertet werden. Hier erhaltet ihr erste Inputs dazu.\n\n\n\nZiele\nDie Studierenden können das eingesetzte Gerät installieren und kennen die Vor- und Nachteile verschiedener Methoden.\nSie können die Daten auslesen und explorativ analysieren.\nGrundlagen\nDie Geräte werden innerhalb der auf Abbildung 1 gekennzeichneten Standorte platziert. Damit soll überprüft werden, wie stark frequentiert die Waldränder der ökologisch aufgewerteten Seeparzelle sind.\n\n\n\nDatenschutz ist ein wichtiges Thema. Die Besuchenden werden über den Zweck der Kameras informiert, die Daten nach der Bearbeitung wieder gelöscht und nicht weitergegeben.\n\n\n\nNun geht es ins Feld uns die Geräte werden installiert.\nAuswertung\nAUFGABE ab dem 12.10.2021\nNachdem die Kameras für zwei Wochen im Einsatz standen, werden die Daten ausgelesen, die Sichtungen in Excel festgehalten und die explorativen Analysen durchgeführt.\nBereits beim Detektieren der Sichtungen muss einem klar sein, was man auswerten möchte. Nur so können die relevanten Variablen erfasst werden.\nIm Rahmen dieser Felderhebung erhaltet ihr von Adrian eine Excel-Vorlage zur Verifizeriung der automatisch detektierten Sichtungen.\nVerifiziert kurz, was euch der Algorithmus geliefert hat.\nAls nächstes geht es ins R. Da wir für unsere Auswertungen zu wenige Sichtungen haben, verwendet bitte den Datensatz DummyData (ReMe HS21 MSc ENR_/Fallstudie Biodiversity & Ecosystems/S_Daten/Felderhebungen). Eure Verifizierung braucht ihr nicht mehr.\nDatenanalyse in R\nVorbereitungen\nFuer diese Aufgabe benoetigen wir folgende Bibliotheken:\n\n\n# Benoetigte Bibliotheken ####\nlibrary(tidyverse) # Data wrangling und piping\nlibrary(lubridate) # Arbeiten mit Datumsformaten\nlibrary(data.table)# schnelles Dateneinlesen\n\n\n\nLese nun zuerst den bereitsgestellen, respektiven den selbst erstellten Datensatz (csv) mithilfe von fread() oder read.csv() ein und nennt ihn cam.\nPruefe die Daten. Wurden sie richtig eingelesen? Wie sieht die Struktur der Daten aus?\nTipp: Brauch zum pruefen den Befehl str() sowie head().\nAufgabe 1: Datentypen\nViele Befehle zum Einlesen erkennen die Datentypen automatisch. Bei Faktoren funktioniert das aber nicht (sie sind ja eigentlich einfach Text und R weiss nicht, was wir damit wollen).\nAuch das Datum muss vielfach manuell definiert werden (hier muessen wir R sagen, wie das Format dieses aussieht).\n\n\ncam <- cam %>% \n  mutate(Datum = as.Date(Datum, format = \"%d.%m.%Y\"))%>%\n  mutate(Kamerastandort = factor(Kamerastandort))%>%\n  ...\n\n\n\nDefiniert nun die restlichen (relevanten) Variablen als Faktor.\nAufgabe 2: Datensatz trennen\nUnser Datensatz enthaellt die Angeben zu ost und west. Wir wollen die Auswertungen aber pro Standort machen.\nTrennt den Datensatz aufgrund des Standorts. Nutzt dazu filter().\n\n\nost <- filter(DATENSATZ, SPALTENNAME == \"Attribut\")\nwest <- ...\n\n\n\nAufgabe 3: Verteilung pruefen\nBei explorativen Analysen macht es immer Sinn sich die Verteilung der Daten anzuschauen. Pruefe daher die Verteilung pro Datensatz mittels Histogram und Scatterplot.\nBeim Histogram sollen nur die Menschen angezeigt und die 0er ausgeschlossen werden. Das kann mit folgendem Code erreicht werden:\n\n\nhist(west$Anzahl[west$Art==\"Mensch\" &\n                  !west$Anzahl==0], # das \"!\" bedeutet \"nicht gleich\"\n     breaks = 10)                   # wie viele Balken brauchen wir im Histogram?\n\n\n\nBeim Scatterplot soll auf der x-Achse das Datum stehen, auf der y-Achse die Anzahl der Personen. Auch hier wollen wir keine Wildtiere im Plot.\nAufgabe 3: Daten ausschliessen\nFuer die weiteren Analysen schliessen wir die Wildtiere komplett aus.\nNutzt dazu wiederum den Befehl filter() und ueberschreibt die Datensaetze ost und west.\nDennoch wolle wir auch wissen, welche Tiere auf dem Areal (ost und west zusammen, also df cam) unterwegs sind.\nDafuer gibts einen separaten Datensatz namens Tiere. Nutzt dazu den Befehl filter().\nAufgabe 4: Explorative Analysen\nBerechnet zuerst die totale Anzahl Menschen / Standort mit sum(DATENSATZ$SPALTENNAME).\nGruppieren und summieren:\nBerechnet nun die Anzahl Menschen pro Aktivität sowie die Anzahl Begleittier pro Kategorie pro Standort.\nUntenstehender Code eigent sich dazu ganz gut:\n\n\nAkt_Ost <- ost %>%\n  group_by(Aktivitaet)%>%      # Hier sagen wir nach was wir gruppieren \n  summarise (n = n()) %>%      # und dann sagen wir, dass R zusammenfassen soll und zwar die Anzahl\n  mutate(freq = n / sum(n))%>% # und dann soll und R das prozentuale Verhaeltniss berechnen\n  arrange(desc(n))             # und dann das ganze absteigend sortieren\n\n\n\nNun soll noch berechnet werden, wie viele unterschiedliche Wildtiere auf dem ganzen Areal gezaehlt wurden.\nRecycelt dazu obenstenenden Code.\nAufgabe 5: Visualisieren\nVerteilung der Aktivitäten als Pie Chart\nZuerst eine Palette mit 5 Farben definieren:\n\n\npal <- hcl.colors(5, palette = \"heat\")\n\n\n\nDann als Kreisdiagramm plotten.\n\n\npie(Akt_West$n, labels = c(\"Anderes\", \"Biker\", \"Landwirtschaft\", \"Spaziergaenger\", \"unbestimmbar\"),\n    main = \"Prozentuales Verhaeltnis West\",\n    col = pal) \n\n\n\n\nFRAGE: eignen sich Pie Charts überhaupt für solche Darstellungen? Wie könnten die Aktivitäten auch noch dargestellt werden? Welches sind eure eigenen Ideen zur Visualisierung?\nBegleittier als Bar Chart\n\n\n# Begleittier als Bar Chart ####\nggplot(Begleit_ost,                      # hier den Datensatz spezifizieren\n       mapping=aes(x=Begleittier, y = n))+ # Absolute Anzahl darstellen\n  geom_col(width=0.9,position = \"dodge\")+# hier sage ich, dass ich ein Balkendiagramm will\n  labs(x=\"Begleittier\", y= \"Anzahl\")+    # Achsenbeschriftung setzen\n  theme_classic(base_size = 15)+         # Und zu guter letzt: Stil definieren\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) # sowie Achsenbeschr.ausrichten\n\n\n\n\nUnd schliesslich: Wildtier als Bar Chart Stellt hier auf der y-Achse die Anzahl nicht total sondern relativ (in Prozent) dar.\n\n\n\nBei Bedraf koennen die selben Plots fuer den zweiten Standort gemacht werden.\n\n\n\n",
    "preview": "fallstudien/BE_S_2_Felderhebung/gruental.jpg",
    "last_modified": "2021-10-18T12:30:55+02:00",
    "input_file": {}
  },
  {
    "path": "fallstudien/BE_S_3_Aufgabenstellung/",
    "title": "KW 43: Aufgabenstellung Wildnispark",
    "description": {},
    "author": [
      {
        "name": "Adrian Hochreutener",
        "url": {}
      }
    ],
    "date": "2021-10-06",
    "categories": [
      "Biodiversity & Ecosystems (S)"
    ],
    "contents": "\nAbschlussbericht über die multivariate Analyse\nZiele\nBisher habt ihr euch mit dem Untersuchungsgebiet beschäftigt und habt selbst ein (kleines) Besuchermonitoring durchgeführt. Das Besuchermonitoring Grüental ist nun abgeschlossen und wir beschäftigen uns voll und ganz mit dem Wildnispark Zürich.\nIm Rahmen dessen programmieren wir multivariate Modelle, welche den Zusammenhang zwischen der Anzahl Besuchenden und verschiedenen Einflussfaktoren (Lockdown, Wetter, Ferien, Wochentag, Kalenderwoche) beschreiben. Dank ihnen können wir sagen, wie die Besucher:innen auf die untersuchten Faktoren reagieren (siehe dazu [Einleitung], Ziele).\nKonkret sollen folgende Fragestellungen beantwortet werden:\n\nWelchen Einfluss haben neben den Lockdowns auch die Wetterparameter (Sonnenscheindauer, Tageshöchsttemperatur, Niederschlagssumme) sowie der Wochentag, die Ferien, die Kalenderwoche und das Jahr auf die Besuchszahlen?\nDabei interessiert uns besonders, wie stark die jeweiligen Einflüsse sind, welche Effektrichtungen beobachtbar sind und welche der untersuchten Parameter signifikant sind.\nKönnen deutliche Unterschiede zwischen den “normalen”, vor-Covid19-Jahren und danach bei Tages-, Wochen-, und / oder Saisongang sowie den wichtigsten, deskriptiven Kennzahlen gefunden werden?\n\nJede Gruppe wertet ausschliesslich Daten eines Zählers aus. Sprecht miteinander ab, wer welchen Zähler behandelt (204, 211 oder 502; Spezifikationen siehe [Einleitung], Hinweis). Jeder Zähler soll nur von einer Gruppe ausgewertet werden!\nFür euren Zähler stehen eventuell Zahlen zu Fussgänger:innen und Velos zur Verfügung (siehe [Einleitung], Hinweis). Entscheidet euch in diesem Fall selbst, ob ihr Fussgänger:innen ODER Velos auswerten wollt. Die anderen Daten dürft ihr vernachlässigen.\nIm Bericht sollen die Informationen und Erfahrungen aus dem gesamten Verlauf der Fallstudie in geeigneter Weise einfliessen. Bezüglich der Felderhebung Grüntal erwarten wir keine Angaben.\n\n\n\nErwartungen\nStruktur / Aufbau\nFragestellung (siehe oben; die Fragestellung ist vorgegeben, darf aber natürlich für den Bericht geschärft und optimal formuliert und konkretisiert werden.)\nMethoden (kurzes Kapitel mit den statistischen Analysen)\nResultate (deskriptive Statistik, multivariates Modell; kurzer Fliesstext sowie die notwendigen Tabellen und eine Auswahl möglichst informativer Grafiken)\nDiskussion (Diskussion der deskriptiven Analysen und der Modellergebnisse; dieser Abschnitt sollte die eigenen Resultate auch im Zusammenhang mit aktueller Fachliteratur reflektieren.)\nLiteraturverzeichnis (Tipp: Das Literaturverzeichnis sollte vollständig sein, sowie formal korrekt und einheitlich daherkommen. Wir erwarten speziell in der Diskussion eine Abstützung auf aktuelle Fachliteratur. Auf Moodle haben wir Euch eine Auswahl relevanter Papers bereitgestellt.)\nAnhang (für alle Auswertungen relevanter R-Code in geeigneter Form)\nGesamtumfang max. 7500 Zeichen (inkl. Leerzeichen; exkl. Einleitung, Tabellen, Literaturverzeichnis und Anhang)\nAbgabe am 9.1.2022 auf Moodle oder per Mail an hoce@zhaw.ch\nBewertungskriterien\nIst die Methode klar und verständlich formuliert?\nSind die deskriptiven Analysen klar beschrieben und geeignet visualisiert?\nIst die Variablenselektion klar beschrieben, plausibel und nachvollziehbar?\nSind die Modellresultate in Text- und Tabellenform korrekt beschrieben und geeignet visualisiert?\nIst die Diskussion klar formuliert und inhaltlich schlüssig?\nWie gut ist die Diskussion auf relevante und aktuelle Fachliteratur abgestützt?\nZusätzliche bewerten wir die inhaltliche Dichte der Arbeit und die formale Qualität (Sprache, Struktur, Aufbau, Darstellung, Literaturverzeichnis, Umgang mit Literatur im Text)\nZusammensetzung der Fallstudiennote:\nFallstudie-Leistungsnachweis 1 - Forschungsplan: 30%\nFallstudie-Leistungsnachweis 2 - Multivariate Analyse: 70%\n\n\n\n",
    "preview": "fallstudien/BE_S_3_Aufgabenstellung/Aufbau_Fallstudie_Profil_S.png",
    "last_modified": "2021-10-08T15:33:59+02:00",
    "input_file": {},
    "preview_width": 1429,
    "preview_height": 903
  },
  {
    "path": "fallstudien/BE_S_4_Projektierung/",
    "title": "KW 43: Aufgabe R Projekt vorbereiten",
    "description": {},
    "author": [
      {
        "name": "Adrian Hochreutener",
        "url": {}
      }
    ],
    "date": "2021-10-06",
    "categories": [
      "Biodiversity & Ecosystems (S)"
    ],
    "contents": "\nArbeiten mit Projekten\nVor den eigentlichen Auswertungen muessen einige Vorbereitungen unternommen werden. Die Zeit, die man hier investiert, wird in der späteren Projektphase um ein Mehrfaches eingespart.\n\n\n\nIch empfehle generell mit Projekten zu arbeiten, da diese sehr einfach ausgetauscht (auf verschiedene Rechner) und somit auch reproduziert werden können. Wichtig ist, dass es keine absoluten Arbeitspfade sondern nur relative gibt. Der Datenimport (und -export) kann mithilfe dieser relativen Pfade stark vereinfacht werden. –> Kurz gesagt: Projekte helfen alles am richtigen Ort zu behalten (mehr zur Arbeit mit Projekten: https://support.rstudio.com/hc/en-us/articles/200526207-Using-Projects).\nErstellt an einem passenden Speicherort ein neues Projekt mit einem treffenden Namen:\n–> File / New Project\nAufgabe 1: Projektaufbau\nNutzt für allen Text, welcher nicht im Code integriert ist, das Symbol #. Wenn ihr den Text als Titel definieren wollt, so dass er in der Übersicht erscheint, müssen vor dem Wort # und nach dem Wort #### eingefügt werden.\n\n\n# Texte, vor denen ein # und nach denen #### stehen, sind Titel\n# Texte, vor denen ein # steht, erklaeren den Ablauf\n# Zeilen ohne vorangehendes # sind Operationen\n\n# Wenn man rechts neben \"Source\" und links neben \"Environment\" klickt \n# (oder CTRL + SHIFT + O --> Show document Outline), \n# oeffnet sich die UEbersicht zu den UEberschriften\n\n\n\nTipp:\nAlt + - = <-\nCtrl + Shift + M = %>%\nCtrl + Shift + C = # vor der ausgewaehlten Zeile\nZuerst immer den Titel des Projekts sowie den Autor/ die Autorin des Skripts nennen. Hier soll auch die Herkunft der Daten ersichtlich sein und falls externe Daten verwendet werden, sollte geklärt werden, wer Dateneigentümer ist (Wildnispark und Meteo Schweiz).\nIm Skript soll immer die Ordnerstruktur des Projekts genannt werden. So kann der Arbeitsvorgang auf verschiedenen Rechnern einfach reproduziert werden (ich verwende hier ein Projektornder mit den Unterordnern __skripts, data, results).\nBeschreibt zudem folgendes die verwendete Meteodaten (siehe dazu Metadata Meteodaten, –> order_XXX_legend.txt)\nEin Skript soll in R eigentlich immer (mehr oder weniger) nach dem selbem Schema aufgebaut sein. Dieses Schema enthällt (nach den bereits erwähnten Definitionen) 4 Kapitel:\nMetadaten und Definitionen\nDatenimport,\nVorbereitung,\nDeskriptive Analyse und Visualisierung und\nMultifaktorielle Analyse und Visualisierung.\nBereitet euer Sktipt mit diesen Kapitel vor.\n\n\n#.########################################################################################### Einfluss von COVID19 auf das Naherholungsverhalten in WPZ ####\n# Fallstudie Modul Research Methods, HS21. Autor/in ####\n#.##########################################################################################\n\n#.##########################################################################################\n# METADATA UND DEFINITIONEN ####\n#.##########################################################################################\n\n# Datenherkunft ####\n# ...\n\n#.##########################################################################################\n# 1. DATENIMPORT #####\n#.##########################################################################################\n\n\n\nAufgabe 2: Laden der Bibliotheken\nGeplottet wird mit ggplot, daher wird tidyverse geladen. Diese Bibliothek ergaenzt BASE R in vielerlei Hinsicht uns ist eigentlich fast immer nötig. Da wir es bei Besucherdaten immer mit einem zeitlichen Bezug zu tun haben, benoetigen wir eine passende Bibliothek. Ich arbeite mit lubridate, POSIXct waere natuerlich auch moeglich. Base R bietet verschiedene Funktionen um Daten einzulesen. data.table ergaenzt diese Basisfunktionen sehr gut. ggpubr brauchen wir für das Darstellen von mehreren verschiedenen Plots in nur einem. PerformanceAnalytics, MuMIn, AICcmodavg, fitdistrplus, lme4 und sjPlot werden fuer die spaeteren multivariaten Analysen benoetigt. Die Modellguete werden wir mittels lattice, blmeco und lattice pruefen.\nLadet nun also die benoetigten Bibliotheken.\nAllenfalls muessen diese zuerst mit install.packages(“NAME”) installiert werden.\n\n\n# Benoetigte Bibliotheken ####\nlibrary(tidyverse) # Data wrangling und piping\nlibrary(lubridate) # Arbeiten mit Datumsformaten\nlibrary(data.table)# schnelles Dateneinlesen\nlibrary(ggpubr)    # to arrange multiple plots in one graph\nlibrary(PerformanceAnalytics) # Plotte Korrelationsmatrix\nlibrary(MuMIn)     # Multi-Model Inference\nlibrary(AICcmodavg)# Modellaverageing\nlibrary(fitdistrplus)# Prueft die Verteilung in Daten\nlibrary(lme4)      # Multivariate Modelle\nlibrary(blmeco)    # Bayesian data analysis using linear models\nlibrary(sjPlot)    # Plotten von Modellergebnissen (tab_model)\nlibrary(lattice)   # einfaches plotten von Zusammenhängen zwischen Variablen\n\n\n\nAufgabe 3: Zeitliche Definitionen\nDefiniert den zeitlichen Horizont, also Start sowie Ende der Untersuchungen. Bezieht in eure Auswertungen den gesamten verfügbaren Zeitraum ein.\nDafür müsst ihr in die Rohdaten eures Zählers schauen. Am einfachsten direkt in der .csv Datei.\n\n\ndepo_start <- as.Date(\"YYYY-MM-DD\")\ndepo_end <- ...\n\n\n\nWichtiger Teil unserer Auswertungen ist der Einfluss des Lockdown auf das Besuchsverhalten. -Wir müssen also Start und Ende der beiden Lockdowns in der Schweiz definieren:\n\n\nlock_1_start_2020 <- as.Date(\"2020-03-16\")\nlock_1_end_2020 <- as.Date(\"2020-05-11\")\n\nlock_2_start_2021 <- as.Date(\"2020-12-22\")\nlock_2_end_2021 <- as.Date(\"2021-03-01\")\n\n\n\nEbenfalls müssen die erste und letzte Kalenderwoche der Untersuchungsfrist definiert werden. Diese werden bei wochenweisen Analysen ausgeklammert da sie i.d.R. unvollstaendig sind (das ist ein späterer Arbeitsschritt). Geht wie oben vor. Tipp: der Befehl week() liefert euch die Kalenderwoche.\nFerienzeiten können einen grossen Einfluss auf das Besucheraufkommen haben. Die relevanten Ferienzeiträume (in meinem Beispiel ab 2019, je nach dem müsst ihr das anpassen) muüsen daher bekannt sein. Zur Definition der Ferien kann z.B. folgend vorgegangen werden:\n\n\n# (https://www.schulferien.org/schweiz/ferien/2020/)\nFruehlingsferien_2019_start <- as.Date(\"2019-04-13\")\nFruehlingsferien_2019_ende <- as.Date(\"2019-04-28\")\nSommerferien_2019_start <- as.Date(\"2019-07-6\")\nSommerferien_2019_ende <- as.Date(\"2019-08-18\")\nHerbstferien_2019_start <- as.Date(\"2019-10-05\")\nHerbstferien_2019_ende <- as.Date(\"2019-10-20\")\nWinterferien_2019_start <- as.Date(\"2019-12-21\")\nWinterferien_2019_ende <- as.Date(\"2020-01-02\")\n\nFruehlingsferien_2020_start <- as.Date(\"2020-04-11\")\nFruehlingsferien_2020_ende <- as.Date(\"2020-04-26\")\nSommerferien_2020_start <- as.Date(\"2020-07-11\")\nSommerferien_2020_ende <- as.Date(\"2020-08-16\")\nHerbstferien_2020_start <- as.Date(\"2020-10-03\")\nHerbstferien_2020_ende <- as.Date(\"2020-10-18\")\nWinterferien_2020_start <- as.Date(\"2020-12-19\")\nWinterferien_2020_ende <- as.Date(\"2021-01-03\")\n\nFruehlingsferien_2021_start <- as.Date(\"2021-04-24\")\nFruehlingsferien_2021_ende <- as.Date(\"2021-05-09\")\nSommerferien_2021_start <- as.Date(\"2021-07-17\")\n\n\n\nNun sind alle Vorbereitungen gemacht, die Projektstruktur aufgebaut und die eigentliche Arbeit kann beginnen.\n\n\n\n",
    "preview": "fallstudien/BE_S_4_Projektierung/the-r-project-for-statistical-computing.png",
    "last_modified": "2021-10-08T15:33:59+02:00",
    "input_file": {},
    "preview_width": 797,
    "preview_height": 298
  }
]
